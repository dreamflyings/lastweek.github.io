<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="Yizhou Shan">
  <link rel="shortcut icon" href="../../../img/favicon.ico">
  <title>NMP - Yizhou Shan's Home Page</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>
  <link href='https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../../../css/highlight.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "NMP";
    var mkdocs_page_input_path = "lego/paper/nmp.md";
    var mkdocs_page_url = "/lego/paper/nmp/";
  </script>
  
  <script src="../../../js/jquery-2.1.1.min.js"></script>
  <script src="../../../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../../../js/highlight.pack.js"></script> 
  
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-143772066-1', 'auto');
      ga('send', 'pageview');
  </script>
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../../.." class="icon icon-home"> Yizhou Shan's Home Page</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	  
          
		  
  <ul class="" href="../../..">
    <li class="toctree-l1">
  <a class="" href="../../..">Home</a>
  </li></ul>
          
		  
  <p class="caption">Notes</p>
  <ul class="">
          <li class="toctree-l1">
            
  <a class="" href="../../../notes/cache_coherence/">Cache Coherence</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../../notes/benchmark/">Benchmarks</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../../notes/paper_perf_shadows/">Perf Shadows</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../../misc/cheatsheet/">Cheatsheet</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../../notes/linux-articles/">Linux Articles</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../../notes/proc/">Linux Special Files</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../../notes/rmap/">Linux Reverse Mmap (rmap)</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../../notes/trace/">Linux Trace/Profile</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../../notes/cgroup-swap/">Linux Cgroup and Swap</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../../notes/userfaultfd/">Linux Userfaultfd</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../../notes/xperf/">Linux User/kern Cross Perf</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../../notes/kvm-basic/">Linux KVM</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../../misc/essential/">Essential</a>
        </li>
  </ul>

          
		  
  <p class="caption">FPGA</p>
  <ul class="">
          <li class="toctree-l1">
            
  <a class="" href="../../../notes/paper_fpga/">FPGA Papers</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../../fpga/vivado/">Vivado Practice</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../../fpga/bitstream/">Bitstream Explained</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../../fpga/pr/">Partial Reconfiguration Explained</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../../fpga/hls_axi/">HLS: Usage of AXI-Stream</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../../fpga/hls_axi/">HLS: High-performance AXI-MM</a>
        </li>
  </ul>

          
		  
  <p class="caption">LegoOS</p>
  <ul class="current">
          <li class="toctree-l1">
            
  <a class="" href="/lego/kernel/kconfig">Kernel</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="/lego/syscall/facts">Syscall</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="/lego/pcache/config">Pcache</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="/lego/driver/pci">Driver</a>
        </li>
          <li class="toctree-l1 current">
            
  <a class="current" href="/lego/paper/nmp">Paper</a>
  <ul class="subnav">
        <li class="toctree-l2 current 1">
            
  <a class="current" href="./">NMP</a>
  <ul class="subnav">
      
  <li class="toctree-l2 current">
  
    <a class="current"  href="#near-memory-processing">Near Memory Processing</a>
  
  
  </li>

  </ul>
        </li>
        <li class="toctree-l2 1">
            
  <a class="" href="../processor_oom/">Processor OOM</a>
        </li>
        <li class="toctree-l2 1">
            
  <a class="" href="../genz/">Gen-Z</a>
        </li>
        <li class="toctree-l2 1">
            
  <a class="" href="../replication/">Replication</a>
        </li>
        <li class="toctree-l2 1">
            
  <a class="" href="../related/">Related</a>
        </li>
  </ul>
        </li>
  </ul>

          
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../..">Yizhou Shan's Home Page</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../..">Docs</a> &raquo;</li>
    
      
        
          <li>LegoOS &raquo;</li>
        
      
        
          <li>Paper &raquo;</li>
        
      
    
    <li>NMP</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="near-memory-processing">Near Memory Processing<a class="headerlink" href="#near-memory-processing" title="Permanent link">&para;</a></h1>
<ul>
<li><mark>NMP: Near Memory Processing</mark></li>
<li>
<p><mark>NDC: Near Data Computing</mark></p>
</li>
<li>
<p><code class="codehilite"><span class="n">PRIME</span><span class="o">:</span> <span class="n">A</span> <span class="n">Novel</span> <span class="n">Processing</span><span class="o">-</span><span class="k">in</span><span class="o">-</span><span class="n">memory</span> <span class="n">Architecture</span> <span class="k">for</span> <span class="n">Neural</span> <span class="n">Network</span><span class="n">Computation</span> <span class="k">in</span> <span class="n">ReRAM</span><span class="o">-</span><span class="n">based</span> <span class="n">Main</span> <span class="n">Memory</span><span class="o">,</span> <span class="n">ISCA</span><span class="err">&#39;</span><span class="mi">16</span></code></p>
<ul>
<li>High-performance
acceleration of NN requires high memory bandwidth since
the <mark>PUs are hungry for fetching the synaptic weights [17]</mark>. To
address this challenge, recent special-purpose chip designs
have adopted large on-chip memory to store the synaptic
weights. For example, DaDianNao [18] employed a large
on-chip eDRAM for both high bandwidth and data locality;
TrueNorth utilized an SRAM crossbar memory for synapses
in each core [19].</li>
</ul>
</li>
<li><mark>DianNao</mark> and <mark>DaDianNao</mark><ul>
<li>&hellip; <strong>memory bandwidth requirements</strong> of two important
layer types: convolutional layers with private kernels
(used in DNNs) and classifier layers used in both CNNs and
DNNs. For these types of layers, the total number of required
synapses can be massive, in the millions of parameters, or
even tens or hundreds thereof.</li>
<li>providing sufficient eDRAM capacity to hold
all <strong>synapse</strong> on the combined eDRAM of all chips will
save on <code class="codehilite">off-chip DRAM accesses</code>, which are particularly
costly energy-wise</li>
<li><mark>Synapses</mark>. In a perceptron layer, all synapses are usually
unique, and thus there is no reuse within the layer. On the
other hand, the synapses are reused across network invocations,
i.e., for each new input data (also called “input row”)
presented to the neural network. So a sufficiently large L2
could store all network synapses and take advantage of that
locality. For DNNs with private kernels, this is not possible
as the total number of synapses are in the tens or hundreds
of millions (the largest network to date has a billion
synapses [26]). However, for both CNNs and DNNs with
shared kernels, the total number of synapses range in the
millions, which is within the reach of an L2 cache. In Figure
6, see CLASS1 - Tiled+L2, we emulate the case where reuse
across network invocations is possible by considering only
the perceptron layer; as a result, the total bandwidth requirements
are now drastically reduced.</li>
<li>So, ML workloads do need large memory bandwidth, and need a lot memory. But how about <strong>temporary working set size</strong>? It&rsquo;s the best if it has a reasonable working set size that can fit the cache.</li>
</ul>
</li>
<li><mark>TPU</mark><ul>
<li>Each model needs between 5M and 100M weights (9<sup>th</sup>
column of Table 1), which can take a lot of time and energy to
access. To amortize the access costs, <strong>the same weights are reused
across a batch of independent examples during inference or
training</strong>, which improves performance.</li>
<li>The weights for the matrix unit are staged through an onchip
<strong>Weight FIFO</strong> that reads from an <strong>off-chip 8 GiB DRAM
called Weight Memory</strong> (for inference, weights are read-only; 8
GiB supports many simultaneously active models). The weight
FIFO is four tiles deep. The intermediate results are held in the <strong>24
MiB on-chip Unified Buffer</strong>, which can serve as inputs to the Matrix Unit.</li>
<li><mark>In virtual cache model, we actually can assign those weights to some designated sets, thus avoid conflicting with other data, which means we can sustain those weights in cache!</mark></li>
</ul>
</li>
</ul>
<p>To conclude:<br />
<code class="codehilite">a)</code> ML needs to use weight/synapses during computation, and those data will be reused repeatly across different stages. Besides, output from last stage serves the input of next stage, so buffering the <code class="codehilite">intermediate data</code> is important. Most ML accelerators use some kind of <code class="codehilite">on-chip memory</code> (<em>Weighted FIFO, Unified Cache in TPU</em>) to buffer those data. This fits the <code class="codehilite">HBM+Disaggregated Memory</code> model: HBM is the on-chip memory, while disaggregated memory is the off-chip memory. <code class="codehilite">b)</code> Combined with virtual cache, we could assign special virtual addresses to weight data, so they stay in some designated cache sets. Kernel can avoid allocating conflict virtual addresses later. Thus we can retain these weight data in virtual cache easily.</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../processor_oom/" class="btn btn-neutral float-right" title="Processor OOM">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../../driver/ib/" class="btn btn-neutral" title="Infiniband"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../../driver/ib/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../processor_oom/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '../../..';</script>
    <script src="../../../js/theme.js"></script>
      <script src="../../../search/require.js"></script>
      <script src="../../../search/search.js"></script>

</body>
</html>
