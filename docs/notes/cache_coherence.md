# Cache Coherence

A general collection of resources on cache coherence.
I started this when I was having a hard time optimizing lock delegation.
This note is not about acadamic new ideas, but rather for
a concrete understanding of current cache coherence implementations.

## Summary and Thoughs

- The textbooks tough us the basic concept of MESI. And realizations
  like snoop and directory. But what usually missing is the implementation
  details when it comes to: 1) conflicts, 2) no single shared bus.
- Modern processors have Network-on-Chip (NoC). Cores, cache slices,
  and memory controllers are connected via an on-chip network.
  The model is no different from a datacenter cluster connected by real network.
- Cache requests generated by MESI protocols should appear _atomic_ to cores.
  Given the distributed nature of all resources, those cache requests
  will have to be implemented like __distributed transactions__.
- For example, the MESIF is the cache coherence protocol used by Intel.
  When a read is made to an invalid line, the corresponding cache
  will perform a _cache read transaction_ to read the data from
  either other caches or memory. This transaction consists multiple
  steps such as: send requests, collect responses, send ACKs.
- Those transactions will conflict if multiple reads and writes
  happen at the same time. Someone has to resolve it.
  It can be resolved by different cache controllers, or by a single
  serialization point like home agent.
- Just like you can have many ways to implement transactions
  for distributed systems, there are also many ways to do
  cache coherence transactions. And there are many.
- Atomic Read-Modify-Write (RMW) instructions will make cache coherence
  implementations even more complex. Those instructions include
  `read-and-inc`, `test-and-set`, and `lock; `-prefixed.
  I think, there will some "lock the bus", or "locked state" at the
  home agent per cache line. Having atomic RMW instructions
  will add more complexity to the overall transaction desgin.
- While reading Intel related cache coherence diagrams/transactions,
  you might find many different descriptions. Don't panic. They are
  just different implementations proposed by Intel. Different
  implementations will have different trade-offs and performance,
  you can check [Frank's post](https://frankdenneman.nl/2016/07/11/numa-deep-dive-part-3-cache-coherency/)
  for more details.
- Directory-based cache coherence procotol and implementation will
  be the future for multicore machines. Because it incurs much less
  coherence traffic than snoop-based ones, thus more scalable.
  The trend is confirmed by recent Intel UPI directory-based approach.
  Related readings:
  [1]: [Why On-Chip Cache Coherence Is Here to Stay](http://www.cis.upenn.edu/acg/papers/cacm12_why_coherence.pdf)
  [2]: [QPI 1.1 Invovled](https://www.realworldtech.com/qpi-evolved/3/)

Left questions:
- Do cache coherence implementations ensure __fairness__ among cores?

## References

- [The Architecture of the Nehalem Processor and Nehalem-EP SMP Platforms](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.455.4198&rep=rep1&type=pdf), chapter 5.2 Cache-Coherence Protocol for Multi-Processors.
    - This serves an entry-level description about how x86 MESIF works.
    - Also this is a very good paper about general x86 microarchitectures.
- [NUMA Deep Dive Part 3: Cache Coherency](https://frankdenneman.nl/2016/07/11/numa-deep-dive-part-3-cache-coherency/)
    - By far the BEST blog I've seen on the topic of Intel snoop models! Frank's other articles are also amazing.
    - Intel is using MESIF cache coherence protocol, but it has multiple cache coherence implementations.
      The first one is `Source Snoop` (or `Early Snoop`), which is more like a traditional snoop-based
      cache coherence implementation. Upon miss, the caching agent will broadcast to other agents.
      The second one is `Home Snoop`, which is more like a directory-based cache coherence implementation.
      Upon miss, the caching agent will contact home agent, and then the home agent will send requests
      to other caching agents who have the requested cache line.
      There are other implementations like Cluster-on-Die.
      Intel UPI gets rid of all this complexity, it is only using directory-based, in the hope to reduce
      cache coherence traffic, which make sense.
    - Related: [Broadwell EP Snoop Models](https://software.intel.com/en-us/articles/intel-xeon-processor-e5-2600-v4-product-family-technical-overview)
    - Related: [Skylay UPI](https://software.intel.com/en-us/articles/intel-xeon-processor-scalable-family-technical-overview)
- [__MESIF: A Two-Hop Cache Coherency Protocol for Point-to-Point Interconnects (2009)__](https://researchspace.auckland.ac.nz/bitstream/handle/2292/11594/MESIF-2009.pdf?sequence=6)
    - A MUST read.
    - This paper has the most extensive description of the MESIF protocol implementation.
      It has many __timing diagrams__ than describe how cache requests actually proceed.
      Those diagrams can help us understand what is needed to finish a cache request.
    - Their [slides](https://parlab.eecs.berkeley.edu/sites/all/parlab/files/20091029-goodman-ssccp.pdf)
      has more timing diagrams.
    - But do note: the implementation described by this paper is different from
      what [Intel QPI](https://www.intel.ca/content/dam/doc/white-paper/quick-path-interconnect-introduction-paper.pdf)
      has in products. The difference is discussed at chapter 4. MESIF and QPI, namely,
      other caching agents will send responses to Home agent rather than to requesting agent.
      QPI relies on Home agent to solve conflict.
    - Also note: this is just one of the possible implementations to realize MESIF protocol.
      There could be many other ways, e.g., QPI source snooping, QPI home snooping.
      But all of them share the essential and general concepts and ideas.
- [Why On-Chip Cache Coherence Is Here to Stay](http://www.cis.upenn.edu/acg/papers/cacm12_why_coherence.pdf)
    - This paper discusses why cache coherence can scale. A nice read.
    - R1: Coherence’s interconnection network traffic per miss scales
          when precisely tracking sharers. (Okay increased directory bits,
	  what about those storage cost? See R2).
    - R2: Hierarchy combined with inclusion enables efficient scaling
          of the storage cost for exact encoding of sharers.
    - R3: private evictions should send explict messages to shared cache
          to enable precise tracking. Thus the recall (_back invalidation_) traffic can be
	  reduced when shared cache is evicting (assume inclusion cache).
    - R4: Latencies of cache request can be amotized. 
- [Appendix I: Large-Scale Multiprocessors and Scientific Applications](https://www.elsevier.com/books-and-journals/book-companion/9780128119051),
  chapter 7 Implementing Cache Coherence.
    - This is probably some most insightful discussion about real implementation of cache coherence.
      With the distributed nature and Network-on-Chip, implementing cache coherence in modern
      processors is no different than implementing a distributed transaction protocol.
    - Cache activities like read miss or write miss have multi-step operations, but they
      need to appear as "atomic" to users. Put in another way, misses are like transactions,
      they have multiple steps but they must be atomic. They can be retried.
    - Having directory for cache coherence will make implementation easier. Because
      the place (e.g., L3) where directory resides can serve as the serialization point.
      They can solve write races.
    - `Home directory controller` and `cache controller` will exchange messages like a set of distributed machines.
      In fact, with NoC, they are actually distributed system.
- [An Introduction to the Intel® QuickPath Interconnect](https://www.intel.ca/content/dam/doc/white-paper/quick-path-interconnect-introduction-paper.pdf),
  page 15 MESIF.
      - It explains the `Home Snoop` and `Source Snoop` used by Intel.
      - Based on their explanation, it seems both `Home Snoop` and `Source Snoop` are using a combination of
        snoop and directory. The Processor#4 (pg 17 and 18) maintains the directory.
      - And this is a perfect demonstration of the details described in [Appendix I: Large-Scale Multiprocessors and Scientific Applications](https://www.elsevier.com/books-and-journals/book-companion/9780128119051).
      - Related patent: [Extending a cache coherency snoop broadcast protocol with directory information](https://patents.google.com/patent/US20150081977)
- AMD HyperTransport Assit for Cache Coherence
    - [Slide](https://www.hotchips.org/wp-content/uploads/hc_archives/hc14/3_Tue/28_AMD_Hammer_MP_HC_v8.pdf)
    - [Slide](http://www.hotchips.org/wp-content/uploads/hc_archives/hc21/2_mon/HC21.24.100.ServerSystemsI-Epub/HC21.24.110.Conway-AMD-Magny-Cours.pdf)

## Misc Small Facts

- Intel Caching Agent (Cbox) is per core (or per LLC slice). Intel Home Agent is per memory controller.
    - Starting from Intel UPI, Caching Agent and Home Agent are combined as CHA.
- A good [discussion](https://www.realworldtech.com/qpi-evolved/3/) about why QPI gradually drop `Source Snoop` and solely use `Home Snoop`.
    - The motivation is scalability. It turns out the new UPI only supports directory-based protocol.
    - This makes sense because 1) inter socket bandwidth is precious, 2) snoop will consume a lot bandwidth.
- Intel UPI is using directory-based home snoop coherency protocol
    - [Intel® Xeon® Processor Scalable Family Technical Overview](https://software.intel.com/en-us/articles/intel-xeon-processor-scalable-family-technical-overview)
- To provide sufficient bandwidth, shared caches are typically interleaved
  by addresses with banks physically distibuted across the chip.

--  
Yizhou Shan  
Created: Jun 28, 2019  
Last Updated: Jun 29, 2019
