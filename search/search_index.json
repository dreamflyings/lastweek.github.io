{
    "docs": [
        {
            "location": "/", 
            "text": "My name is \nYizhou Shan\n. I\nm a second-year Ph.D. student at \nPurdue ECE\n,\nadvised by Prof. \nYiying Zhang\n. Our lab is \nWuklab.io\n. Yes, the \nMonkey King\n Lab.\nPlease find my CV \nhere\n.\n\n\nWhat\ns up\n\n\n\n\nWill join VMware Research for 2018 summer intern.\n\n\n\n\nResearch\n\n\nMy research interests span Operating System, Distributed Systems,\nand Non-Volatile Memory. I like hacking kernel and no doubt Linux is my\nfavorite open-source project.\n\n\nContact\n\n\n465 Northwestern Ave\n\nPurdue University\n\nWest Lafayette, IN 47907\n\nOffice: EE 345  \n\n\nEmail: \n\n\nConferences and Workshops\n\n\n\n\nDistributed Shared Persistent Memory\n, NVMW\n18\n\n\nDisaggregated Operating System\n, HPTS\n17\n\n\nDistributed Shared Persistent Memory\n, SoCC\n17\n\n\n\n\nPosters\n\n\n\n\nLego: A Distributed, Decomposed OS for Resource Disaggregation\n, SOSP\n17\n\n\nDisaggregated Operating System\n, SoCC\n17\n\n\n\n\nSocial\n\n\n\n\nGithub\n\n\nInstagram", 
            "title": "Home"
        }, 
        {
            "location": "/#whats-up", 
            "text": "Will join VMware Research for 2018 summer intern.", 
            "title": "What's up"
        }, 
        {
            "location": "/#research", 
            "text": "My research interests span Operating System, Distributed Systems,\nand Non-Volatile Memory. I like hacking kernel and no doubt Linux is my\nfavorite open-source project.", 
            "title": "Research"
        }, 
        {
            "location": "/#contact", 
            "text": "465 Northwestern Ave \nPurdue University \nWest Lafayette, IN 47907 \nOffice: EE 345    Email:", 
            "title": "Contact"
        }, 
        {
            "location": "/#conferences-and-workshops", 
            "text": "Distributed Shared Persistent Memory , NVMW 18  Disaggregated Operating System , HPTS 17  Distributed Shared Persistent Memory , SoCC 17", 
            "title": "Conferences and Workshops"
        }, 
        {
            "location": "/#posters", 
            "text": "Lego: A Distributed, Decomposed OS for Resource Disaggregation , SOSP 17  Disaggregated Operating System , SoCC 17", 
            "title": "Posters"
        }, 
        {
            "location": "/#social", 
            "text": "Github  Instagram", 
            "title": "Social"
        }, 
        {
            "location": "/misc/cheatsheet/", 
            "text": "cheatsheet\n\n\nvirsh\n\n\n\n\nPass commands to QEMU in the virsh bash:\n\n1\n# qemu-monitor-command guest_os_id --hmp \ninfo cpus\n\n\n\n\n\n\n\n\nMarkdown\n\n\n\n\nEmoji cheatsheet\n\n\n\n\ntmux\n\n\n\n\nInstall \ntmux-plugins\n, it makes your terminal bling bling.\n\n\n\n\nbash\n\n\n\n\nShow current git branch in PS1:\n\n1\n2\n3\n4\n5\nparse_git_branch\n()\n \n{\n\n     git branch \n2\n /dev/null \n|\n sed -e \n/^[^*]/d\n -e \ns/* \\(.*\\)/ git:(\\1)/\n\n\n}\n\n\n\nPS1\n=\n\\[\\e[32m\\][\\u@\\h: \\W\\e[33m\\]\\$(parse_git_branch)\\[\\033[32m\\]]\\[\\e[00m\\] \n$\n \n\n\n\n\n\n\n\n\nQEMU\n\n\n\n\nRun standalone kernel:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n# Create a new directory to store the serial output from printk().\n\n\nOUTPUT_DIR\n=\ntest-output\n\n\nif\n \n[\n -e \n$OUTPUT_DIR\n \n]\n;\n \nthen\n\n        \nif\n \n[\n -f \n$OUTPUT_DIR\n \n]\n;\n \nthen\n\n                \necho\n \nERROR: \n$OUTPUT_DIR\n is not a directly\n\n                \nexit\n \n1\n\n        \nfi\n\n\nelse\n\n        mkdir -p \n$OUTPUT_DIR\n\n\nfi\n\n\n\nKERNEL\n=\narch/x86_64/boot/bzImage\n\n\nKERNEL_PARAM\n=\nconsole=ttyS0 earlyprintk=serial,ttyS0,115200\n\n\nSERIAL\n=\n-serial file:\n$OUTPUT_DIR\n/ttyS0 -serial file:\n$OUTPUT_DIR\n/ttyS1\n\n\n\n# -cpu Haswell,+tsc,+sse,+xsave,+aes,+avx,+erms,+pdpe1gb,+pge \\\n\n\n# Above -cpu option may not work with some kernels.\n\nqemu-system-x86_64 -s  \n\\\n\n        -nographic \n\\\n\n        -kernel \n$KERNEL\n -append \n$KERNEL_PARAM\n \n\\\n\n        -no-reboot \n\\\n\n        -d int,cpu_reset -D \n$OUTPUT_DIR\n/qemu.log \n\\\n\n        \n$SERIAL\n \n\\\n\n        -m 16G \n\\\n\n        -monitor stdio \n\\\n\n        -smp \ncpus\n=\n24\n,cores\n=\n12\n,threads\n=\n2\n,sockets\n=\n2\n \n\\\n\n        -numa node,cpus\n=\n0\n-11,mem\n=\n8G,nodeid\n=\n0\n \n\\\n\n        -numa node,cpus\n=\n12\n-23,mem\n=\n8G,nodeid\n=\n1\n\n\n\n\n\n\n\n\nInstall CentOS on Dell PowerEdge\n\n\n\n\nEnable \nSR-IOV\n for future usage\n\n\nPress \nF11 Boot Manager\n during boot\n\n\nFind \nIntegrated Devices\n\n\nEnable \nSR-IOV Global Enable\n\n\n\n\n\n\nPartition\n\n\n/boot\n: e.g, 50GB\n\n\nswap\n: e.g, 4G\n\n\n/\n: all left\n\n\n\n\n\n\nDon\nt forget to enable Network during installation.\n\n\nChange SSH port\n\n\nDisable \nfirewalld\n\n\nsystemctl stop firewalld\n\n\nsystemctl disable firewalld\n\n\n\n\n\n\nIf SELinux is enabled\n\n\nyum install policycoreutils-python\n\n\nsemanage port -a -t ssh_port_t -p tcp #PORTNUMBER\n\n\n\n\n\n\nChange \n/etc/ssh/sshd_config\n\n\nsystemctl restart sshd\n\n\n\n\n\n\n\n\nAvoid Typing SSH Password\n\n\n\n\nGenerate keys: \nssh-keygen -t rsa\n\n\nCopy to remote: \nssh-copy-id -i ~/.ssh/id_rsa.pub username@remotehost -p 22", 
            "title": "Cheatsheet"
        }, 
        {
            "location": "/misc/cheatsheet/#cheatsheet", 
            "text": "", 
            "title": "cheatsheet"
        }, 
        {
            "location": "/misc/cheatsheet/#virsh", 
            "text": "Pass commands to QEMU in the virsh bash: 1 # qemu-monitor-command guest_os_id --hmp  info cpus", 
            "title": "virsh"
        }, 
        {
            "location": "/misc/cheatsheet/#markdown", 
            "text": "Emoji cheatsheet", 
            "title": "Markdown"
        }, 
        {
            "location": "/misc/cheatsheet/#tmux", 
            "text": "Install  tmux-plugins , it makes your terminal bling bling.", 
            "title": "tmux"
        }, 
        {
            "location": "/misc/cheatsheet/#bash", 
            "text": "Show current git branch in PS1: 1\n2\n3\n4\n5 parse_git_branch ()   { \n     git branch  2  /dev/null  |  sed -e  /^[^*]/d  -e  s/* \\(.*\\)/ git:(\\1)/  }  PS1 = \\[\\e[32m\\][\\u@\\h: \\W\\e[33m\\]\\$(parse_git_branch)\\[\\033[32m\\]]\\[\\e[00m\\]  $", 
            "title": "bash"
        }, 
        {
            "location": "/misc/cheatsheet/#qemu", 
            "text": "Run standalone kernel:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28 # Create a new directory to store the serial output from printk().  OUTPUT_DIR = test-output  if   [  -e  $OUTPUT_DIR   ] ;   then \n         if   [  -f  $OUTPUT_DIR   ] ;   then \n                 echo   ERROR:  $OUTPUT_DIR  is not a directly \n                 exit   1 \n         fi  else \n        mkdir -p  $OUTPUT_DIR  fi  KERNEL = arch/x86_64/boot/bzImage  KERNEL_PARAM = console=ttyS0 earlyprintk=serial,ttyS0,115200  SERIAL = -serial file: $OUTPUT_DIR /ttyS0 -serial file: $OUTPUT_DIR /ttyS1  # -cpu Haswell,+tsc,+sse,+xsave,+aes,+avx,+erms,+pdpe1gb,+pge \\  # Above -cpu option may not work with some kernels. \nqemu-system-x86_64 -s   \\ \n        -nographic  \\ \n        -kernel  $KERNEL  -append  $KERNEL_PARAM   \\ \n        -no-reboot  \\ \n        -d int,cpu_reset -D  $OUTPUT_DIR /qemu.log  \\ \n         $SERIAL   \\ \n        -m 16G  \\ \n        -monitor stdio  \\ \n        -smp  cpus = 24 ,cores = 12 ,threads = 2 ,sockets = 2   \\ \n        -numa node,cpus = 0 -11,mem = 8G,nodeid = 0   \\ \n        -numa node,cpus = 12 -23,mem = 8G,nodeid = 1", 
            "title": "QEMU"
        }, 
        {
            "location": "/misc/cheatsheet/#install-centos-on-dell-poweredge", 
            "text": "Enable  SR-IOV  for future usage  Press  F11 Boot Manager  during boot  Find  Integrated Devices  Enable  SR-IOV Global Enable    Partition  /boot : e.g, 50GB  swap : e.g, 4G  / : all left    Don t forget to enable Network during installation.  Change SSH port  Disable  firewalld  systemctl stop firewalld  systemctl disable firewalld    If SELinux is enabled  yum install policycoreutils-python  semanage port -a -t ssh_port_t -p tcp #PORTNUMBER    Change  /etc/ssh/sshd_config  systemctl restart sshd", 
            "title": "Install CentOS on Dell PowerEdge"
        }, 
        {
            "location": "/misc/cheatsheet/#avoid-typing-ssh-password", 
            "text": "Generate keys:  ssh-keygen -t rsa  Copy to remote:  ssh-copy-id -i ~/.ssh/id_rsa.pub username@remotehost -p 22", 
            "title": "Avoid Typing SSH Password"
        }, 
        {
            "location": "/misc/jasmine/", 
            "text": "Cool and good-to-know stuff:\n\n\n\n\n\n\nServeless\n\n\n\n\nAWS Lambda\n\n\nGoogle Cloud Function\n\n\nAzure Functions\n\n\n\n\n\n\n\n\nSDS\n\n\n\n\nTidalScale\n\n\nScaleMP\n\n\n\n\n\n\n\n\nApache Crail\n\n\n\n\n\n\nRedis Lab\n\n\n\n\n\n\nJournaling of journal\n\n\n\n\n\n\nConcurrent Data Structures\n\n\n\n\nNUMA-aware data structures\n\n\nlinearizability\n\n\nlock-free skip list\n\n\nblog", 
            "title": "Jasmine"
        }, 
        {
            "location": "/lego/log/TODO/", 
            "text": "TODO\n\n\n\n\n\n\nvDSO\n: if later we find applications are using \ngettimeofday\n, \ntime\n, and \ngetcpu\n a lot, and it truly hurt performance, then we should consider adding this in the processor side. (Check Processor Loader document for code that needs to be patched). (02/27/18)\n\n\n\n\n\n\nVA randomization\n: our loader does not add any randomization. For security reasons, we probably want to add this.\n\n\n\n\n\n\nVM Organization\n: multiple vm choice at M side, on a per-vma basis.\n\n\n\n\n\n\nfork\n:\n \ndup\n \nfree\n \npool\n: duplicate the free VA pool at both P and M.\n\n\n\n\n\n\npcache\n: send each page\ns type back. something like PcacheAnon, PcacheFile. So the pcache_evict/do_exit routine can be optimized.\n\n\n\n\n\n\nmm alloc\n: don\nt use the kmalloc to get a new mm_struct. This is a hot data structure, use get_free_page instead maybe. Like task_struct.\n\n\n\n\n\n\nfork_dup_pcache\n: have real vm_flags to guide write-protect. Get vm ranges from memory to optimize the duplication.\n\n\n\n\n\n\nP side mm sem\n: check if we need the sem in P side. pgfault need read, fork and others need W. Even though M side also serialize this, but  out ops are divided.\n\n\n\n\n\n\nmprotect\n: it is empty now. We assume applications are well-written. But does any of them rely on this COW feature?", 
            "title": "TODO"
        }, 
        {
            "location": "/lego/log/TODO/#todo", 
            "text": "vDSO : if later we find applications are using  gettimeofday ,  time , and  getcpu  a lot, and it truly hurt performance, then we should consider adding this in the processor side. (Check Processor Loader document for code that needs to be patched). (02/27/18)    VA randomization : our loader does not add any randomization. For security reasons, we probably want to add this.    VM Organization : multiple vm choice at M side, on a per-vma basis.    fork :   dup   free   pool : duplicate the free VA pool at both P and M.    pcache : send each page s type back. something like PcacheAnon, PcacheFile. So the pcache_evict/do_exit routine can be optimized.    mm alloc : don t use the kmalloc to get a new mm_struct. This is a hot data structure, use get_free_page instead maybe. Like task_struct.    fork_dup_pcache : have real vm_flags to guide write-protect. Get vm ranges from memory to optimize the duplication.    P side mm sem : check if we need the sem in P side. pgfault need read, fork and others need W. Even though M side also serialize this, but  out ops are divided.    mprotect : it is empty now. We assume applications are well-written. But does any of them rely on this COW feature?", 
            "title": "TODO"
        }, 
        {
            "location": "/lego/log/log-02-2018/", 
            "text": "Feb 2018\n\n\n\n\n02/28 Wed\n\n\n\n\npatch fork, and cow handler\n\n\ndebug pcache, while running python hello world\n\n\nadd vDSO, gettimeofday\n\n\n\n\nSo, it is end of the day. After adding wp handler, I now have the whole picture of pcache activities, and the interactions between them. The reclaim, zap, move, copy, add, operations needs to be carefully synchronized. Also the refcount etc. I feel the ground rule is we need to make sure a PCM that a function is currently using, can not suddenly become invalid due to other operations. This has to be synced by: refcount, lock, flags. Oh well, mm is hard with SMP, but also fun.\n\n\nWe are very close to have a fully working OS.\n\n\nI did not have time to look into the python hello world bug issue. It is a very serious one. It may also rule out some root bugs.\n\n\n\n\n02/27 Tue\n\n\nSpent two days on CS527 source project, implemented a small SSHD and SSD client. And we have to inject exactly five bugs, or vulnerabilities into the systems. Lol, it is really hard to intentionally plant BUGs!\n\n\nAnyway, back to Lego. Since others are having a hard time compile program statically, I will try to add dynamic loader today.\n\n\nThe interpreter: \n/lib64/ld-linux-x86-64.so.2\n.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\nLinux seq.c maps (no randomization):\n00400000-00401000 r-xp 00000000 fd:00 18752683                           /root/ys/LegoOS/usr/a.out\n00600000-00601000 r--p 00000000 fd:00 18752683                           /root/ys/LegoOS/usr/a.out\n00601000-00602000 rw-p 00001000 fd:00 18752683                           /root/ys/LegoOS/usr/a.out\n00602000-00604000 rw-p 00000000 00:00 0                                  [heap]\n7ffff7a18000-7ffff7bd0000 r-xp 00000000 fd:00 55051990                   /usr/lib64/libc-2.17.so\n7ffff7bd0000-7ffff7dd0000 ---p 001b8000 fd:00 55051990                   /usr/lib64/libc-2.17.so\n7ffff7dd0000-7ffff7dd4000 r--p 001b8000 fd:00 55051990                   /usr/lib64/libc-2.17.so\n7ffff7dd4000-7ffff7dd6000 rw-p 001bc000 fd:00 55051990                   /usr/lib64/libc-2.17.so\n7ffff7dd6000-7ffff7ddb000 rw-p 00000000 00:00 0\n\n7ffff7ddb000-7ffff7dfc000 r-xp 00000000 fd:00 55051983                   /usr/lib64/ld-2.17.so\n\n7ffff7fde000-7ffff7fe1000 rw-p 00000000 00:00 0\n7ffff7ff9000-7ffff7ffa000 rw-p 00000000 00:00 0\n7ffff7ffa000-7ffff7ffc000 r-xp 00000000 00:00 0                          [vdso]\n\n7ffff7ffc000-7ffff7ffd000 r--p 00021000 fd:00 55051983                   /usr/lib64/ld-2.17.so\n\n7ffff7ffd000-7ffff7ffe000 rw-p 00022000 fd:00 55051983                   /usr/lib64/ld-2.17.so\n\n7ffff7ffe000-7ffff7fff000 rw-p 00000000 00:00 0\n\n7ffffffde000-7ffffffff000 rw-p 00000000 00:00 0                          [stack]\n\nffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]\n\n\n\n\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\nlego\n \nafter\n \nloading\n\n\n00400000\n-\n00401000\n \nr\n-\nxp\n \n00000000\n \n/\nroot\n/\nys\n/\nLegoOS\n/\nusr\n/\na\n.\nout\n\n\n00600000\n-\n00602000\n \nrw\n-\np\n \n00000000\n \n/\nroot\n/\nys\n/\nLegoOS\n/\nusr\n/\na\n.\nout\n\n\n00602000\n-\n00604000\n \nrw\n-\np\n \n00000000\n \n[\nheap\n]\n\n\n7ff\nff7ddb000\n-\n7ff\nff7dfc000\n \nr\n-\nxp\n \n00000000\n \n/\nlib64\n/\nld\n-\nlinux\n-\nx86\n-\n64.\nso\n.2\n\n\n7ff\nff7ffc000\n-\n7ff\nff7ffe000\n \nrw\n-\np\n \n00021000\n \n/\nlib64\n/\nld\n-\nlinux\n-\nx86\n-\n64.\nso\n.2\n\n\n7ff\nff7ffe000\n-\n7ff\nff7fff000\n \nrw\n-\np\n \n00000000\n\n\n7ff\nffffde000\n-\n7ff\nffffff000\n \nrw\n-\np\n \n00000000\n \n[\nstack\n]\n\n\n\n\n[\n \n2066.379224\n]\n \n****\n    \nFinish\n \ndump\n \nfinal\n \nmm\n\n\n[\n \n2066.426023\n]\n \nhandle_p2m_execve\n()\n:\n \nreply_status\n:\n \nOKAY\n,\n \nnew_ip\n:\n \n0x7ffff7ddc170\n,\n \nnew_sp\n:\n \n0x7fffffffede0\n\n\n[\n \n2066.628949\n]\n \nhandle_p2m_pcache_miss\n()\n \ncpu\n \n4\n \nI\n \nnid\n:\n0\n \npid\n:\n32\n \ntgid\n:\n32\n \nflags\n:\n150\n \nvaddr\n:\n0x7ffff7ddc170\n\n\n[\n \n2066.732034\n]\n \nhandle_p2m_pcache_miss\n()\n \ncpu\n \n4\n \nO\n \nnid\n:\n0\n \npid\n:\n32\n \ntgid\n:\n32\n \nflags\n:\n150\n \nvaddr\n:\n0x7ffff7ddc170\n\n\n[\n \n2066.934947\n]\n \nhandle_p2m_pcache_miss\n()\n \ncpu\n \n4\n \nI\n \nnid\n:\n0\n \npid\n:\n32\n \ntgid\n:\n32\n \nflags\n:\n51\n \nvaddr\n:\n0x7fffffffedd8\n\n\n[\n \n2067.036978\n]\n \nhandle_p2m_pcache_miss\n()\n \ncpu\n \n4\n \nO\n \nnid\n:\n0\n \npid\n:\n32\n \ntgid\n:\n32\n \nflags\n:\n51\n \nvaddr\n:\n0x7fffffffedd8\n\n\n[\n \n2067.238842\n]\n \nhandle_p2m_pcache_miss\n()\n \ncpu\n \n4\n \nI\n \nnid\n:\n0\n \npid\n:\n32\n \ntgid\n:\n32\n \nflags\n:\n50\n \nvaddr\n:\n0x7ffff7ffce00\n\n\n[\n \n2067.340880\n]\n \nhandle_p2m_pcache_miss\n()\n \ncpu\n \n4\n \nO\n \nnid\n:\n0\n \npid\n:\n32\n \ntgid\n:\n32\n \nflags\n:\n50\n \nvaddr\n:\n0x7ffff7ffce00\n\n\n[\n \n2067.542747\n]\n \nhandle_p2m_pcache_miss\n()\n \ncpu\n \n4\n \nI\n \nnid\n:\n0\n \npid\n:\n32\n \ntgid\n:\n32\n \nflags\n:\n51\n \nvaddr\n:\n0x7ffff7ffd9a8\n\n\n[\n \n2067.644774\n]\n \nhandle_p2m_pcache_miss\n()\n \ncpu\n \n4\n \nO\n \nnid\n:\n0\n \npid\n:\n32\n \ntgid\n:\n32\n \nflags\n:\n51\n \nvaddr\n:\n0x7ffff7ffd9a8\n\n\n[\n \n2067.846640\n]\n \nhandle_p2m_pcache_miss\n()\n \ncpu\n \n4\n \nI\n \nnid\n:\n0\n \npid\n:\n32\n \ntgid\n:\n32\n \nflags\n:\n50\n \nvaddr\n:\n0x7ffff7ddb8e0\n\n\n[\n \n2067.948679\n]\n \nhandle_p2m_pcache_miss\n()\n \ncpu\n \n4\n \nO\n \nnid\n:\n0\n \npid\n:\n32\n \ntgid\n:\n32\n \nflags\n:\n50\n \nvaddr\n:\n0x7ffff7ddb8e0\n\n\n[\n \n2068.355424\n]\n \n------------\n[\n \ncut\n \nhere\n \n]\n------------\n\n\n[\n \n2068.408568\n]\n \nWARNING\n:\n \nCPU\n:\n \n4\n \nPID\n:\n \n31\n \nat\n \nmanagers\n/\nmemory\n/\nhandle_pcache\n/\nfault\n.\nc\n:\n54\n \nhandle_p2m_pcache_miss\n+\n0x29d\n/\n0x380\n\n\n[\n \n2068.532327\n]\n \nsrc_nid\n:\n0\n,\npid\n:\n32\n,\nvaddr\n:\n0x7ffff7e0e000\n\n\n[\n \n2068.588487\n]\n \nCPU\n:\n \n4\n \nPID\n:\n \n31\n \nComm\n:\n \nmc\n-\nmanager\n \n4.0.0\n-\nlego\n-\nys\n+\n \n#\n100\n\n\n[\n \n2068.659207\n]\n \nStack\n:\n\n\n\n\n\n\n\n1\n2\n3\n4\n[root@wuklab13: lib64] $ ll ld-*\n-rwxr-xr-x 1 root root 164112 Nov 30 13:53 ld-2.17.so\nlrwxrwxrwx 1 root root     10 Jan  8 12:34 ld-linux-x86-64.so.2 -\n ld-2.17.so\n[root@wuklab13: lib64]\n\n\n\n\n\n\nIt turns out there is a bug in mmap code: forgot to increment the file ref count when a file-backed vma is created. Some put_file in loader accidentally free the ld-linux file. Bug fixed, dyloader works like a charm.\n\n\n\n\n02/24 Sat\n\n\nWell. PhDs do not have weekends.\nAnyway, it is Saturday after all, relaxed a little bit. I was looking into the pcache issue.\nAlso added our own kernel version strace.\n\n\n\n\n02/23 Fri\n\n\nSolved FPU BUG\n\n\ncurrent\n is fine. I should not compare the old implementation with the new per-cpu current. I forgot that the kernel stack is switched in the \n__switch_to_asm\n. This means in \n__switch_to()\n, we are actually using the \nnext_p\ns kernel stack. So there is small time frame, where \ncurrent_thread_info()\n points to \nnext_p\n, while \ncurrent_task\n is still \nprev_p\n. Since interrupts are disabled during context switch, we are good with this mismatch.\n\n\nRule out current, the only thing left is \nfpu__copy\n warning, which happens during \ncopy_process()\n. One weird thing is this function has been called multiple times before it showed a warning. System itself use this function to create a lot background threads, which are fine. Only when it was triggered by \nsys_clone\n then we have the warning:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n[\n \n3213.055639\n]\n \nCPU\n:\n \n6\n \nPID\n:\n \n17\n \nsys_clone\n+\n0x0\n/\n0x30\n\n\n[\n \n3213.056584\n]\n \nnew\n \ntask_struct\n:\n \nffff88083e4c9838\n\n\n[\n \n3213.057530\n]\n \narch_dup_task_struct\n \ncpu6\n \ndst\n:\nffff88083e4c9838\n \n17\n \nword_count\n-\nseq\n \nsrc\n:\nffff88083e457838\n \n17\n \nword_count\n-\nseq\n\n\n[\n \n3213.059536\n]\n \nTRAP\n \ndo_general_protection\n \nin\n \nCPU6\n,\n \nerror_code\n:\n \n0\n \ncurrent\n:\nffff88083e457838\n \n17\n \nword_count\n-\nseq\n\n\n[\n \n3213.061289\n]\n \nfixup_exception\n \npid\n(\n17\n)\n \ncpu\n(\n6\n)\n \ninsn\n:\n0xffffffff81009a21\n(\nfpu__copy\n+\n0x81\n/\n0x260\n)\n \nfixup\n:\n0xffffffff8105d9b2\n(\n__fixup_text_start\n+\n0xc2\n/\n0x322\n)\n \nhandler\n:\nex_handler_default\n+\n0x0\n/\n0x20\n\n\n[\n \n3213.064114\n]\n \n------------\n[\n \ncut\n \nhere\n \n]\n------------\n\n\n[\n \n3213.065040\n]\n \nWARNING\n:\n \nCPU\n:\n \n6\n \nPID\n:\n \n17\n \nat\n \n.\n/\narch\n/\nx86\n/\ninclude\n/\nasm\n/\nfpu\n/\ninternal\n.\nh\n:\n354\n \nfpu__copy\n+\n0xc3\n/\n0x260\n\n\n[\n \n3213.066760\n]\n \nCPU\n:\n \n6\n \nPID\n:\n \n17\n \nComm\n:\n \nword_count\n-\nseq\n \n4.0.0\n-\nlego\n+\n \n#\n6\n\n\n[\n \n3213.067855\n]\n \nStack\n:\n\n\n[\n \n3213.068424\n]\n \nffff88083e4c7dd0\n \nffffffff810124b5\n \nffff88083e4c9bf8\n \nffff88083e4c9c38\n\n\n[\n \n3213.070133\n]\n \nffff88083e4c9838\n \n00007ff\nff7ffd700\n \nffff88083e4c7de0\n \nffffffff8101258f\n\n\n[\n \n3213.071775\n]\n \nffff88083e4c7e08\n \nffffffff81009a63\n \nffff88083e457838\n \nffff88083e4c9838\n\n\n[\n \n3213.073419\n]\n \nffff88083e457838\n \nffff88083e4c7e40\n \nffffffff81000ebb\n \nffff88083e457838\n\n\n[\n \n3213.075057\n]\n \nffff880800000011\n \nffff88083e457a68\n \n00000000003\nd0f00\n \nffff88083e457838\n\n\n[\n \n3213.076703\n]\n \nCall\n \nTrace\n:\n\n\n[\n \n3213.077295\n]\n \nTSK\n\n\n[\n \n3213.077828\n]\n \n[\nffffffff810124c1\n]\n \n__warn\n.\nconstprop\n.0\n+\n0x91\n/\n0xd0\n\n\n[\n \n3213.078855\n]\n \n[\nffffffff8101258f\n]\n \nwarn_slowpath_null\n+\n0xf\n/\n0x20\n\n\n[\n \n3213.081653\n]\n \n[\nffffffff81009a63\n]\n \nfpu__copy\n+\n0xc3\n/\n0x260\n\n\n[\n \n3213.082543\n]\n \n[\nffffffff81000ebb\n]\n \narch_dup_task_struct\n+\n0x7b\n/\n0x90\n\n\n[\n \n3213.083667\n]\n \n[\nffffffff8101d32e\n]\n \ncopy_process\n+\n0x14e\n/\n0x10e0\n\n\n[\n \n3213.084618\n]\n \n[\nffffffff8103a3c6\n]\n \n?\n \nn_tty_write\n+\n0x166\n/\n0x3c0\n\n\n[\n \n3213.085564\n]\n \n[\nffffffff8101e2e6\n]\n \ndo_fork\n+\n0x26\n/\n0x140\n\n\n[\n \n3213.086439\n]\n \n[\nffffffff8101e4a0\n]\n \n?\n \nsys_vfork\n+\n0x40\n/\n0x40\n\n\n[\n \n3213.087333\n]\n \n[\nffffffff8101e4a0\n]\n \n?\n \nsys_vfork\n+\n0x40\n/\n0x40\n\n\n[\n \n3213.088232\n]\n \n[\nffffffff8101e4c9\n]\n \nsys_clone\n+\n0x29\n/\n0x30\n\n\n[\n \n3213.089109\n]\n \n[\nffffffff8100e719\n]\n \ndo_syscall_64\n+\n0x69\n/\n0xf0\n\n\n[\n \n3213.090030\n]\n \n[\nffffffff8100d5ec\n]\n \nentry_SYSCALL64_slow_path\n+\n0x25\n/\n0x25\n\n\n[\n \n3213.091078\n]\n \nEOT\n\n\n[\n \n3213.091580\n]\n \n---\n[\n \nend\n \ntrace\n \n0000000000000000\n \n]\n---\n\n\n[\n \n3213.093250\n]\n \nTRAP\n \ndo_general_protection\n \nin\n \nCPU7\n,\n \nerror_code\n:\n \n0\n \ncurrent\n:\nffff88083fd0f008\n \n0\n \nswapper\n/\n7\n\n\n[\n \n3213.096526\n]\n \nfixup_exception\n \npid\n(\n0\n)\n \ncpu\n(\n7\n)\n \ninsn\n:\n0xffffffff81000c62\n(\n__switch_to\n+\n0x452\n/\n0x630\n)\n \nfixup\n:\n0xffffffff8105d922\n(\n__fixup_text_start\n+\n0x32\n/\n0x322\n)\n \nhandler\n:\nex_handler_default\n+\n0x0\n/\n0x20\n\n\n[\n \n3213.101241\n]\n \n------------\n[\n \ncut\n \nhere\n \n]\n------------\n\n\n[\n \n3213.103285\n]\n \nWARNING\n:\n \nCPU\n:\n \n7\n \nPID\n:\n \n0\n \nat\n \n.\n/\narch\n/\nx86\n/\ninclude\n/\nasm\n/\nfpu\n/\ninternal\n.\nh\n:\n369\n \n__switch_to\n+\n0x47e\n/\n0x630\n\n\n\n\n\n\nSo, dig into \nfpu__copy()\n, find out why it fails at this certain point. Glad I have something to dig into. \n\n\nThe instruction leads to GP is:\n\n1\nffffffff8100b0f5\n:\n       \n48\n \n0f\n \nae\n \n27\n             \nxsave64\n \n(\n%\nrdi\n)\n\n\n\n\n\n\nwhich is generated by:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n#define XSTATE_XSAVE(st, lmask, hmask, err)                             \\\n\n\n        asm volatile(ALTERNATIVE_2(XSAVE,                               \\\n\n\n                                   XSAVEOPT, X86_FEATURE_XSAVEOPT,      \\\n\n\n                                   XSAVES,   X86_FEATURE_XSAVES)        \\\n\n\n                     \n\\n\n                                               \\\n\n\n                     \nxor %[err], %[err]\\n\n                             \\\n\n\n                     \n3:\\n\n                                             \\\n\n\n                     \n.pushsection .fixup,\\\nax\\\n\\n\n                     \\\n\n\n                     \n4: movl $-2, %[err]\\n\n                            \\\n\n\n                     \njmp 3b\\n\n                                         \\\n\n\n                     \n.popsection\\n\n                                    \\\n\n\n                     _ASM_EXTABLE(661b, 4b)                             \\\n\n\n                     : [err] \n=r\n (err)                                 \\\n\n\n                     : \nD\n (st), \nm\n (*st), \na\n (lmask), \nd\n (hmask)    \\\n\n\n                     : \nmemory\n)\n\n\nstatic\n \ninline\n \nvoid\n \ncopy_xregs_to_kernel\n(\nstruct\n \nxregs_state\n \n*\nxstate\n)\n\n\n{\n\n        \nu64\n \nmask\n \n=\n \n-\n1\n;\n\n        \nu32\n \nlmask\n \n=\n \nmask\n;\n\n        \nu32\n \nhmask\n \n=\n \nmask\n \n \n32\n;\n\n        \nint\n \nerr\n;\n\n\n        \nWARN_ON\n(\n!\nalternatives_patched\n);\n\n\n        \nXSTATE_XSAVE\n(\nxstate\n,\n \nlmask\n,\n \nhmask\n,\n \nerr\n);\n\n\n        \n/* We should never fault when copying to a kernel buffer: */\n\n        \nWARN_ON_FPU\n(\nerr\n);\n\n\n}\n\n\n\n\n\n\nFrom SDM on \nXSAVE\n: \nUse of a destination operand not aligned to 64-byte boundary (in either 64-bit or 32-bit modes) results in a general-protection (#GP) exception. In 64-bit mode, the upper 32 bits of RDX and RAX are ignored.\n\n\n%rdi\n is \nstruct xregs_state *xstate\n in above code. Thus, check if \nxstate\n if 64-bytes aligned. Of course, it is not:\n\n1\n[10894.999997] copy_xregs_to_kernel CPU6 xstate: ffff88083e4c8c38\n\n\n\n\n\nHehe. Criminal identified. But why? The xstate structure is already marked as \n__attribute__(aliged 64)\n in the code. \nIt is the task_struct\n, which is \nNOT\n 0x40 aligned. But god why? Because we currently use \nkmalloc\n to allocate new task_struct, whose minimum alignment is \n8 bytes\n. Anyway, use \n__alloc_pages\n instead.\n\n\nSuch an deeply hidden bug. Took me almost a month to find out.\n\n\nIB\n\n\nSeen this during boot (at both P and M, although lego continue running correctly):\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n[\n54017.712533\n]\n \n***\n    \nNodeID\n    \nHostname\n    \nLID\n    \nQPN\n\n\n[\n54017.770776\n]\n \n***\n    \n-------------------------------------\n\n\n[\n54017.834220\n]\n \n***\n         \n0\n    \nwuklab12\n     \n13\n     \n72\n\n\n[\n54017.892462\n]\n \n***\n         \n1\n    \nwuklab14\n     \n16\n     \n72\n \n---\n\n\n[\n54017.955906\n]\n \n***\n         \n2\n    \nwuklab16\n     \n20\n     \n74\n\n\n[\n54018.014149\n]\n \n***\n\n\n[\n54074.552844\n]\n \n***\n  \nStart\n \nestablish\n \nconnection\n \n(\nmynodeid\n:\n \n1\n)\n\n\n[\n54102.554407\n]\n \nib_process_mad\n \nmad_ifc\n \nfails\n\n\n[\n54130.960691\n]\n \n***\n  \nrecvpollcq\n \nruns\n \non\n \nCPU2\n\n\n[\n54131.070918\n]\n \n***\n  \nSuccessfully\n \nbuilt\n \nQP\n \nfor\n \nnode\n  \n0\n \n[\nLID\n:\n \n13\n \nQPN\n:\n \n72\n]\n\n\n[\n54131.152936\n]\n \n***\n  \nSuccessfully\n \nbuilt\n \nQP\n \nfor\n \nnode\n  \n2\n \n[\nLID\n:\n \n20\n \nQPN\n:\n \n74\n]\n\n\n[\n54161.228245\n]\n \n***\n  \nFIT\n \nlayer\n \nready\n \nto\n \ngo\n!\n\n\n[\n54161.272034\n]\n \n***\n\n\n\n\n\nAnother one:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n[\n \n1966.930409\n]\n \n***\n\n\n[\n \n1966.951210\n]\n \n***\n  \nFIT_initial_timeout_s\n:\n   \n30\n\n\n[\n \n1967.002168\n]\n \n***\n  \nFIT_local_id\n:\n            \n0\n\n\n[\n \n1967.052087\n]\n \n***\n\n\n[\n \n1967.072887\n]\n \n***\n    \nNodeID\n    \nHostname\n    \nLID\n    \nQPN\n\n\n[\n \n1967.131126\n]\n \n***\n    \n-------------------------------------\n\n\n[\n \n1967.194567\n]\n \n***\n         \n0\n    \nwuklab12\n     \n13\n     \n72\n \n---\n\n\n[\n \n1967.258005\n]\n \n***\n         \n1\n    \nwuklab14\n     \n16\n     \n72\n\n\n[\n \n1967.316244\n]\n \n***\n         \n2\n    \nwuklab16\n     \n20\n     \n74\n\n\n[\n \n1967.374484\n]\n \n***\n\n\n[\n \n2032.926448\n]\n \n***\n  \nStart\n \nestablish\n \nconnection\n \n(\nmynodeid\n:\n \n0\n)\n\n\n[\n \n2032.996068\n]\n \nFail\n \nto\n \nmodify\n \nqp\n[\n6\n]\n\n\n[\n \n2033.032572\n]\n \nFail\n \nto\n \ndo\n \nclient_init_ctx\n\n\n[\n \n2033.077287\n]\n \nclient_establish_conn\n:\n \nctx\n           \n(\nnull\n)\n \nfail\n \nto\n \ninit_interface\n\n\n[\n \n2033.164646\n]\n \nibapi_establish_conn\n:\n \nctx\n           \n(\nnull\n)\n \nfail\n \nto\n \ninit_interface\n\n\n[\n \n2033.250967\n]\n \n***\n\n\n[\n \n2035.620167\n]\n \nBUG\n:\n \nunable\n \nto\n \nhandle\n \nkernel\n \nNULL\n \npointer\n \ndereference\n \nat\n \n0000000000000004\n\n\n[\n \n2035.713763\n]\n \nIP\n:\n \n[\nffffffff8105c589\n]\n \nclient_send_reply_with_rdma_write_with_imm\n+\n0x69\n/\n0x3b0\n\n\n[\n \n2035.812562\n]\n \nPGD\n \n0\n\n\n[\n \n2035.836482\n]\n \nOops\n:\n \n0002\n \n[\n#\n1\n]\n \nSMP\n \nPROCESSOR\n\n\n[\n \n2035.884321\n]\n \nCPU\n:\n \n0\n \nPID\n:\n \n1\n \nComm\n:\n \nkernel_init\n \n4.0.0\n-\nlego\n-\nys\n+\n \n#\n253\n\n\n[\n \n2035.955041\n]\n \nRIP\n:\n \n0010\n:\n[\nffffffff8105c589\n]\n  \n[\nffffffff8105c589\n]\n \nclient_send_reply_with_rdma_write_with_imm\n+\n0x69\n/\n0x3b0\n\n\n...\n\n\n[\n \n2037.313267\n]\n \nTSK\n\n\n[\n \n2037.336146\n]\n \n[\nffffffff8105a377\n]\n \nibapi_send_reply_timeout\n+\n0x57\n/\n0x70\n\n\n[\n \n2037.411025\n]\n \n[\nffffffff81033d24\n]\n \n?\n \nnet_send_reply_timeout\n+\n0x94\n/\n0x132\n\n\n[\n \n2037.486944\n]\n \n[\nffffffff81033d24\n]\n \nnet_send_reply_timeout\n+\n0x94\n/\n0x132\n\n\n\n\n\n\npcache\n\n\nRunning word_count-pthread, with 100MB dataset, finally got some reasonable bug:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n[\n54211.243181\n]\n \npcache_evict_line\n()\n:\n \npset\n:\n \nffff88207f86e3c0\n,\n \nfor\n \nuva\n:\n \n0x7ffff1b8f000\n\n\n[\n54211.385654\n]\n \npcache\n:\nffff88207f86e3a8\n \nmapcount\n:\n8\n \nrefcount\n:\n0\n \nflags\n:()\n\n\n[\n54211.510447\n]\n \npcache\n \ndumped\n \nbecause\n:\n \nPCACHE_BUG_ON_PCM\n(\n!\nPcacheLocked\n(\npcm\n))\n\n\n[\n54212.080336\n]\n \nBUG\n:\n \nfailure\n \nat\n \nmanagers\n/\nprocessor\n/\npcache\n/\nevict\n.\nc\n:\n240\n/\npcache_evict_line\n()\n!\n\n\n[\n54212.664785\n]\n \nKernel\n \nPanic\n \n-\n \nnot\n \nsyncing\n:\n \nBUG\n!\n\n\n[\n54212.715742\n]\n \nCPU\n:\n \n8\n \nPID\n:\n \n81\n \nComm\n:\n \nword_count\n-\npthr\n \n4.0.0\n-\nlego\n-\nys\n+\n \n#\n252\n\n\n...\n\n\n[\n54213.391706\n]\n \nTSK\n\n\n[\n54213.414584\n]\n \n[\nffffffff81024180\n]\n \npanic\n+\n0xc2\n/\n0xeb\n\n\n[\n54213.524818\n]\n \n[\nffffffff8101b81c\n]\n \n?\n \ntask_tick_rt\n+\n0x2c\n/\n0xd0\n\n\n[\n54213.589295\n]\n \n[\nffffffff81018f75\n]\n \n?\n \nscheduler_tick\n+\n0x55\n/\n0x60\n\n\n[\n54213.655850\n]\n \n[\nffffffff81016625\n]\n \n?\n \ntick_handle_periodic\n+\n0x45\n/\n0x70\n\n\n[\n54213.728647\n]\n \n[\nffffffff81006634\n]\n \n?\n \napic_timer_interrupt\n+\n0x54\n/\n0x90\n\n\n[\n54213.801443\n]\n \n[\nffffffff8100e22a\n]\n \n?\n \nsmp__apic_timer_interrupt\n+\n0x6a\n/\n0x70\n\n\n[\n54213.879439\n]\n \n[\nffffffff8101256d\n]\n \n?\n \nprintk\n+\n0x11d\n/\n0x1b0\n\n\n[\n54214.103027\n]\n \n[\nffffffff8102ecf4\n]\n \npcache_evict_line\n+\n0x134\n/\n0x220\n\n\n[\n54214.172703\n]\n \n[\nffffffff8102c6ae\n]\n \npcache_alloc\n+\n0x22e\n/\n0x2e0\n\n\n[\n54214.237179\n]\n \n[\nffffffff8102be0a\n]\n \ncommon_do_fill_page\n+\n0x2a\n/\n0x1f0\n\n\n[\n54214.307895\n]\n \n[\nffffffff8102baf0\n]\n \n?\n \nmove_page_tables\n+\n0x4c0\n/\n0x4c0\n\n\n[\n54214.378612\n]\n \n[\nffffffff8102c172\n]\n \npcache_handle_fault\n+\n0x1a2\n/\n0x3a0\n\n\n[\n54214.450367\n]\n \n[\nffffffff8100fc02\n]\n \ndo_page_fault\n+\n0xa2\n/\n0x1a0\n\n\n[\n54214.514843\n]\n \n[\nffffffff8100d85f\n]\n \npage_fault\n+\n0x1f\n/\n0x30\n\n\n[\n54214.575161\n]\n \n[\nffffffff81034842\n]\n \n?\n \ncopy_user_enhanced_fast_string\n+\n0x2\n/\n0x10\n\n\n[\n54214.657316\n]\n \n[\nffffffff81032368\n]\n \n?\n \nseq_read\n+\n0x248\n/\n0x360\n\n\n[\n54214.719714\n]\n \n[\nffffffff810307af\n]\n \nsys_read\n+\n0x3f\n/\n0xc0\n\n\n[\n54214.777949\n]\n \n[\nffffffff81030770\n]\n \n?\n \nsweep_pset_lru\n+\n0x220\n/\n0x220\n\n\n[\n54214.846587\n]\n \n[\nffffffff8100e619\n]\n \ndo_syscall_64\n+\n0x69\n/\n0xf0\n\n\n[\n54214.910022\n]\n \n[\nffffffff8100d4ec\n]\n \nentry_SYSCALL64_slow_path\n+\n0x25\n/\n0x25\n\n\n[\n54214.985939\n]\n \nEOT\n\n\n\n\n\n\nAnother one:\n\n1\n2\n3\n[\n  \n735.393244\n]\n \npcache_evict_line\n()\n:\n \npset\n:\n \nffff88207f86e3c0\n,\n \nfor\n \nuva\n:\n \n0x7ffff1b8fd90\n\n\n[\n  \n735.537804\n]\n \npcache\n:\nffff88207f86e3a8\n \nmapcount\n:\n8\n \nrefcount\n:\n0\n \nflags\n:()\n\n\n[\n  \n735.663642\n]\n \npcache\n \ndumped\n \nbecause\n:\n \nPCACHE_BUG_ON_PCM\n(\n!\nPcacheLocked\n(\npcm\n))\n\n\n\n\n\n\nDo note this happens after computation. This happens when phoenix create a lot threads to sort the results.\n\n\nBoth bug happen to the same set, same user page. The pcache is clearly corrupted: \nmapcount\n:\n8\n,\n \nrefcount\n:\n0\n,\n \nflags\n:().\n\n\nCome back after dinner.\nRemember to check altenative, cause the XSAVE above should be XSAVEOPT. Make sure it does not override other memory. Also, check linker script. Do not forget to link any sections.\n\n\nAnother several bug logs in wuklab13 and wuklab15: \n022318-*\n. I\nm really tired today after fixing the FPU bug. But I\nm also pretty confident pcache is something I\nm able to debug. Even thought it is hard in SMP case.\n\n\nAnyway, I gonna call for the day.\n\n\n\n\n02/22 Thur\n\n\n\n\ncontext switch fpu\n\n\nsignal compat check, all good.\n\n\n make \ncurrent\n use percpu current_task, so all code in Lego is consistent.\n\n\nchecked \nentry_SYSCALL-64\n again, which looks good to me.\n\n\nThe only concern is \nrsp_scratch\n and \ncurrent_top_of_stack\n, which are per-cpu variables. If these per-cpu is setup wrong, then we are doomed.\n\n\nAlso check if per-cpu is all cleared up?\n\n\ntry big syscall lock\n\n\ndoes x86 has to use different kernel stacks? Interrupt is using different stack in Linux, has to do so???\n\n\ncheck current is correct. compare with old implementation.\n\n\n\n\nFirst of all, FPU is definitely functional for now.\nSince I replaced the current macro today, I add some code to check if this current matches our old implementation:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\nstatic __always_inline struct task_struct *get_current(void)                                                           \n{                                                                                                                      \n        return this_cpu_read_stable(current_task);                                                                     \n}\n\n//#define current get_current()\n\n#define current                                                 \\\n({                                                              \\\n        struct task_struct *old = current_thread_info()-\ntask;  \\\n        struct task_struct *new = get_current();                \\\n                                                                \\\n        if (old != new) {                                       \\\n                printk(\n%s:%d() cpu:%d old:%pS %d %s new:%pS %d %s\\n\n,  \\\n                        __func__, __LINE__, smp_processor_id(), old, old-\npid, old-\ncomm, \\\n                        new, new-\npid, new-\ncomm);              \\\n                BUG();                                          \\\n        }                                                       \\\n        get_current();                                          \\\n})\n\n\n\n\n\nCombined with some FPU warning, it is now like this:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n[\n \n3273.748819\n]\n \nCPU\n:\n5\n \nPID\n:\n32\n   \nsys_clone\n+\n0x0\n/\n0x30\n\n\n[\n \n3273.800808\n]\n \nalloc_task_struct_node\n:\n \nsize\n:\n740\n \nffff88107e831838\n\n\n[\n \n3273.869451\n]\n \narch_dup_task_struct\n()\n \nCPU5\n \ncurrent\n:\n32\n \nnew\n:\n \nffff88107e831838\n \nold\n:\n \nffff88107e827838\n \n32\n\n\n[\n \n3273.975533\n]\n \n------------\n[\n \ncut\n \nhere\n \n]\n------------\n\n\n[\n \n3274.030651\n]\n \nWARNING\n:\n \nCPU\n:\n \n5\n \nPID\n:\n \n32\n \nat\n \n.\n/\narch\n/\nx86\n/\ninclude\n/\nasm\n/\nfpu\n/\ninternal\n.\nh\n:\n354\n \nfpu__copy\n+\n0xe2\n/\n0x310\n\n\n[\n \n3274.140895\n]\n \nCPU\n:\n \n5\n \nPID\n:\n \n32\n \nComm\n:\n \nword_count\n-\npthr\n \n4.0.0\n-\nlego\n-\nys\n-\ngdbe6dbe\n-\ndirty\n \n#\n249\n\n\n[\n \n3274.231377\n]\n \nStack\n:\n\n\n[\n \n3274.255298\n]\n \nffff88107e82fd68\n \nffffffff81016dbf\n \n00000000ff\nffffff\n \n0000000000000000\n\n\n[\n \n3274.342659\n]\n \n00000000ff\nffffff\n \n0000000000000000\n \nffff88107e831bf8\n \nffff88107e831c38\n\n\n[\n \n3274.430021\n]\n \nffff88107e831838\n \n000000207f\ne64000\n \nffff88107e82fd78\n \nffffffff810170af\n\n\n[\n \n3274.517382\n]\n \nffff88107e82fdc0\n \nffffffff8100b052\n \n0000000000000020\n \nffff88107e831838\n\n\n[\n \n3274.604745\n]\n \nffff88107e827838\n \nffff88107e827838\n \nffff88107e831838\n \nffff88107e827838\n\n\n[\n \n3274.692106\n]\n \nCall\n \nTrace\n:\n\n\n[\n \n3274.721229\n]\n \nTSK\n\n\n[\n \n3274.744109\n]\n \n[\nffffffff81016dd8\n]\n \n__warn\n.\nconstprop\n.0\n+\n0xe8\n/\n0x3b0\n\n\n[\n \n3274.813790\n]\n \n[\nffffffff810170af\n]\n \nwarn_slowpath_null\n+\n0xf\n/\n0x20\n\n\n[\n \n3274.881391\n]\n \n[\nffffffff8100b052\n]\n \nfpu__copy\n+\n0xe2\n/\n0x310\n\n\n[\n \n3274.941713\n]\n \n[\nffffffff810012e4\n]\n \narch_dup_task_struct\n+\n0x84\n/\n0x120\n\n\n[\n \n3275.013475\n]\n \n[\nffffffff81022c10\n]\n \ncopy_process\n+\n0x160\n/\n0x1e60\n\n\n[\n \n3275.078996\n]\n \n[\nffffffff81024936\n]\n \ndo_fork\n+\n0x26\n/\n0x140\n\n\n[\n \n3275.137238\n]\n \n[\nffffffff81024af0\n]\n \n?\n \nsys_vfork\n+\n0x40\n/\n0x40\n\n\n[\n \n3275.198599\n]\n \n[\nffffffff81024af0\n]\n \n?\n \nsys_vfork\n+\n0x40\n/\n0x40\n\n\n[\n \n3275.259960\n]\n \n[\nffffffff81024b19\n]\n \nsys_clone\n+\n0x29\n/\n0x30\n\n\n[\n \n3275.319242\n]\n \n[\nffffffff81012314\n]\n \ndo_syscall_64\n+\n0x84\n/\n0x240\n\n\n[\n \n3275.383723\n]\n \n[\nffffffff8101106c\n]\n \nentry_SYSCALL64_slow_path\n+\n0x25\n/\n0x25\n\n\n[\n \n3275.459645\n]\n \nEOT\n\n\n[\n \n3275.482526\n]\n \n---\n[\n \nend\n \ntrace\n \n0000000000000000\n \n]\n---\n\n\n[\n \n3275.537648\n]\n \nwake_up_new_task\n \nCPU5\n \ntask\n:\nffff88107e831838\n,\n \ndest_cpu\n:\n6\n \ncurrent\n:\n32\n\n\n[\n \n3275.623970\n]\n \nSMP\n \nIPI\n:\n \nreschedule_interrupt\n()\n \nCPU\n(\n6\n)\n \nPID\n(\n0\n)\n\n\n[\n \n3275.739412\n]\n \ndo_general_protection\n:\n186\n()\n \ncpu\n:\n6\n \nold\n:\n0xffff88107e831838\n \n33\n \nword_count\n-\npthr\n \nnew\n:\n0xffff88107fcaf008\n \n0\n \nswapper\n/\n6\n\n\n\n\n[\n \n3275.871493\n]\n \n------------\n[\n \ncut\n \nhere\n \n]\n------------\n\n\n[\n \n3275.926614\n]\n \nBUG\n:\n \nfailure\n \nat\n \narch\n/\nx86\n/\nkernel\n/\ntraps\n.\nc\n:\n186\n/\ndo_general_protection\n()\n!\n\n\n[\n \n3276.015018\n]\n \nKernel\n \nPanic\n \n-\n \nnot\n \nsyncing\n:\n \nBUG\n!\n\n\n[\n \n3276.065978\n]\n \npanic\n:\n107\n()\n \ncpu\n:\n6\n \nold\n:\n0xffff88107e831838\n \n33\n \nword_count\n-\npthr\n \nnew\n:\n0xffff88107fcaf008\n \n0\n \nswapper\n/\n6\n\n\n\n\n\n\nBased on the switch code:\n\n1\n2\n3\n4\n5\n6\n7\n__switch_to\n(\nstruct\n \ntask_struct\n \n*\nprev_p\n,\n \nstruct\n \ntask_struct\n \n*\nnext_p\n)\n\n\n{\n\n        \nthis_cpu_write\n(\ncurrent_task\n,\n \nnext_p\n);\n\n\n        \n/* Reload sp0 This changes current_thread_info(). */\n\n        \nload_sp0\n(\ntss\n,\n \nnext\n);\n\n\n}\n\n\n\n\n\n\nBased on log line 30, \nload_sp0()\n already happened, which means \nthis_cpu_write(..)\n happened too. If \nthis_cpu_write(..)\n happened, then log line 30\ns new should have been updated to \n0xffff88107e831838\n. Something wrong with percpu?\n\n\n\n\n02/21 Wed\n\n\n\n\nirq_regs, old code, check\n\n\nsignal frame, and fpu hook together Done\n\n\nin_interrupt()\n, it is empty, TODO\n\n\ncheck arch/x86/Makefile, it introduce a lot FPU flags.\n\n\nadded more than 4K lines today. Damn FPU. Ugh go home sleep.\n\n\n\n\n\n\n02/20 Tue Cloudy\n\n\nNot too many Sunny days recently. Well, continue yesterday\ns work. I don\nt think I can easily find out why so many \n/proc/memoinfo\n open happened. Instead, I\nm trying to enable the \nflush_thread\n in P\ns exec code.\n\n\nDuring the way, I found some issue related to \n__ARCH_HAS_SA_RESTORER\n in signal code. I need to check if these x86 macros are defined, but lego does not port them.\n\n\nWell, it turns out flush_thread does not make too much difference. Next I\nm going to try to disable \nexit_thread\n, which uses \nfpu__drop()\n.\n\n\nHmm, disable \nexit_thread\n also does not work.\n\n\n\n\n02/19 Mon Rainy\n\n\nIt is another week. I can not deny I\nm a little tired about the bug. Tried so many possible solutions, but none of them work. Well, today I first need to test the vma changes (pgoff and anon_vma) thing. Especially the vma merge and split.\n\n\nThis morning I fixed a bug in kernel_init process: make kernel_init able to run all possible CPUs. Because the first user process is forked from kernel_init, it is quite important that it gets the right cpu affinity:\n\n1\n2\n3\n4\n5\n6\nstatic\n \nint\n \nkernel_init\n(\nvoid\n \n*\nunused\n)\n\n\n{\n\n        \n...\n\n        \nset_cpus_allowed_ptr\n(\ncurrent\n,\n \ncpu_possible_mask\n);\n\n        \n...\n\n\n}\n\n\n\n\n\n\nWell, interestingly, the unmodified word_count-pthread succeed with 50MB dataset\n with or without any DEBUG option! Amazing! I need to find out why the cpus_allowed becomes 0 at the beginning of kernel_init. Because \ninit_task\n actually has:\n\n1\n2\n    \n.\ncpus_allowed\n   \n=\n \nCPU_MASK_ALL\n,\n\n    \n.\nnr_cpus_allowed\n=\n \nNR_CPUS\n,\n\n\n\n\n\n\nThings to do next:\n\n\n\n\ncheck why the cpus_allowed changed\n\n\ncheck why word_count-pthread open \n/dev/../cpu\n so many times. Anything wrong with our \ncopy_files\n, or open, close?\n\n\nhere is an idea, to verify if FPU code is correct, run some scientific benchmarks.\n\n\n\n\nOkay, findings:\n\n\n\n\n\n\ncpus_allowd is fine, it is reset inside \nsched_init()\n, when it tries make the \ninit_task\n as the \nidle\n thread. Thus it is reasonable to set cpus_allowed again at \nkernel_init\n thread. And it should NOTHING to do with the bug.\n\n\n\n\n\n\nabout the second, check the following log:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n[\n11838.364543\n]\n \nSTDOUT\n:\n \n---\n[\n\n\nWordcount\n:\n \nRunning\n...\n\n\n]\n---\n\n\n[\n11838.422886\n]\n \nSTDOUT\n:\n \n---\n[\n\n\n\n\n]\n---\n\n\n[\n11838.463445\n]\n \nSYSC_open\n(\ncpu5\n \npid\n:\n32\n)\n:\n \nf_name\n:\n \n/\nroot\n/\nys\n/\nphoenix\n/\nphoenix\n-\n2.0\n/\ntests\n/\nword_count\n/\nword_count_datafiles\n/\nword_50MB\n.\ntxt\n,\n \nflags\n:\n \n0\n,\n \nmode\n:\n \n900\n\n\n[\n11838.619460\n]\n \nSYSC_open\n(\ncpu5\n \npid\n:\n32\n)\n:\n \nfd\n:\n \n3\n\n\n[\n11838.667406\n]\n \nSYSC_open\n(\ncpu5\n \npid\n:\n32\n)\n:\n \nf_name\n:\n \n/\nsys\n/\ndevices\n/\nsystem\n/\ncpu\n/\nonline\n,\n \nflags\n:\n \n80000\n,\n \nmode\n:\n \n0\n\n\n[\n11838.773351\n]\n \nSYSC_open\n(\ncpu5\n \npid\n:\n32\n)\n:\n \nfd\n:\n \n4\n\n\n[\n11838.821239\n]\n \nseq_file\n:\n\n  \ndest_uva\n:\n \n00007ff\nfffffc8d0\n,\n \nnr_chars\n:\n \n5\n\n  \nstring\n:\n \n[\n0\n-\n23\n\n\n]\n\n\n[\n11838.913791\n]\n \nSYSC_close\n(\ncpu5\n \npid\n:\n32\n)\n:\n \nfd\n:\n \n4\n\n\n[\n11838.962622\n]\n \nSYSC_close\n()\n:\n \n[\n4\n]\n \n-\n \n[\n/\nsys\n/\ndevices\n/\nsystem\n/\ncpu\n/\nonline\n]\n\n\n[\n11840.223255\n]\n \nSTDOUT\n:\n \n---\n[\n\n\nWord\n \nCount\n:\n \nComputation\n \nCompleted\n \n1.555581\n \nsec\n\n\n\n]\n---\n\n\n[\n11840.309678\n]\n \nSYSC_open\n(\ncpu5\n \npid\n:\n32\n)\n:\n \nf_name\n:\n \n/\nsys\n/\ndevices\n/\nsystem\n/\ncpu\n/\nonline\n,\n \nflags\n:\n \n80000\n,\n \nmode\n:\n \n0\n\n\n[\n11840.415754\n]\n \nSYSC_open\n(\ncpu5\n \npid\n:\n32\n)\n:\n \nfd\n:\n \n4\n\n\n[\n11840.463593\n]\n \nseq_file\n:\n\n  \ndest_uva\n:\n \n00007ff\nfffffc8a0\n,\n \nnr_chars\n:\n \n5\n\n  \nstring\n:\n \n[\n0\n-\n23\n\n\n]\n\n\n[\n11840.556147\n]\n \nSYSC_close\n(\ncpu5\n \npid\n:\n32\n)\n:\n \nfd\n:\n \n4\n\n\n[\n11840.605024\n]\n \nSYSC_close\n()\n:\n \n[\n4\n]\n \n-\n \n[\n/\nsys\n/\ndevices\n/\nsystem\n/\ncpu\n/\nonline\n]\n\n\n[\n11840.677821\n]\n \nSTDOUT\n:\n \n---\n[\n\n\nTHe\n \nnumber\n \nof\n \nprocessors\n \nis\n \n24\n\n\n\n\u00f4\n\n\n]\n---\n\n\n[\n11840.753769\n]\n \nSYSC_open\n(\ncpu7\n \npid\n:\n80\n)\n:\n \nf_name\n:\n \n/\nproc\n/\nmeminfo\n,\n \nflags\n:\n \n80000\n,\n \nmode\n:\n \n1\nb6\n\n\n[\n11840.844212\n]\n \nSYSC_open\n(\ncpu19\n \npid\n:\n92\n)\n:\n \nf_name\n:\n \n/\nproc\n/\nmeminfo\n,\n \nflags\n:\n \n80000\n,\n \nmode\n:\n \n1\nb6\n\n\n[\n11840.935728\n]\n \nSYSC_open\n(\ncpu7\n \npid\n:\n80\n)\n:\n \nfd\n:\n \n4\n\n\n[\n11840.983567\n]\n \nSYSC_open\n(\ncpu19\n \npid\n:\n92\n)\n:\n \nfd\n:\n \n5\n\n\n[\n11841.032444\n]\n \nseq_file\n:\n\n  \ndest_uva\n:\n \n00007ff\nff444c000\n,\n \nnr_chars\n:\n \n172\n\n  \nstring\n:\n \n[\nMemTotal\n:\n       \n115355128\n \nkB\n\n\nMemFree\n:\n        \n115355128\n \nkB\n\n\nMemAvailable\n:\n   \n115355128\n \nkB\n\n\nDirectMap4k\n:\n        \n5812\n \nkB\n\n\nDirectMap2M\n:\n     \n1861632\n \nkB\n\n\nDirectMap1G\n:\n    \n134217728\n \nkB\n\n\n]\n\n\n[\n11841.305953\n]\n \nseq_file\n:\n\n  \ndest_uva\n:\n \n00007ff\nff444b000\n,\n \nnr_chars\n:\n \n172\n\n  \nstring\n:\n \n[\nMemTotal\n:\n       \n115355128\n \nkB\n\n\nMemFree\n:\n        \n115355128\n \nkB\n\n\nMemAvailable\n:\n   \n115355128\n \nkB\n\n\nDirectMap4k\n:\n        \n5812\n \nkB\n\n\nDirectMap2M\n:\n     \n1861632\n \nkB\n\n\nDirectMap1G\n:\n    \n134217728\n \nkB\n\n\n]\n\n\n[\n11841.579460\n]\n \nSYSC_close\n(\ncpu7\n \npid\n:\n80\n)\n:\n \nfd\n:\n \n4\n\n\n[\n11841.628339\n]\n \nSYSC_close\n(\ncpu19\n \npid\n:\n92\n)\n:\n \nfd\n:\n \n5\n\n\n[\n11841.678257\n]\n \nSYSC_close\n()\n:\n \n[\n4\n]\n \n-\n \n[\n/\nproc\n/\nmeminfo\n]\n\n\n[\n11841.733375\n]\n \nSYSC_close\n()\n:\n \n[\n5\n]\n \n-\n \n[\n/\nproc\n/\nmeminfo\n]\n\n\n[\n11841.788493\n]\n \nSYSC_open\n(\ncpu18\n \npid\n:\n91\n)\n:\n \nf_name\n:\n \n/\nproc\n/\nmeminfo\n,\n \nflags\n:\n \n80000\n,\n \nmode\n:\n \n1\nb6\n\n\n[\n11841.880008\n]\n \nSYSC_open\n(\ncpu6\n \npid\n:\n102\n)\n:\n \nf_name\n:\n \n/\nproc\n/\nmeminfo\n,\n \nflags\n:\n \n80000\n,\n \nmode\n:\n \n1\nb6\n\n\n[\n11841.971523\n]\n \nSYSC_open\n(\ncpu12\n \npid\n:\n85\n)\n:\n \nf_name\n:\n \n/\nproc\n/\nmeminfo\n,\n \nflags\n:\n \n80000\n,\n \nmode\n:\n \n1\nb6\n\n\n[\n11842.063040\n]\n \nSYSC_open\n(\ncpu0\n \npid\n:\n97\n)\n:\n \nf_name\n:\n \n/\nproc\n/\nmeminfo\n,\n \nflags\n:\n \n80000\n,\n \nmode\n:\n \n1\nb6\n\n\n[\n11842.153516\n]\n \nSYSC_open\n(\ncpu14\n \npid\n:\n87\n)\n:\n \nf_name\n:\n \n/\nproc\n/\nmeminfo\n,\n \nflags\n:\n \n80000\n,\n \nmode\n:\n \n1\nb6\n\n\n[\n11842.245032\n]\n \nSYSC_open\n(\ncpu16\n \npid\n:\n89\n)\n:\n \nf_name\n:\n \n/\nproc\n/\nmeminfo\n,\n \nflags\n:\n \n80000\n,\n \nmode\n:\n \n1\nb6\n\n\n[\n11842.336548\n]\n \nSYSC_open\n(\ncpu4\n \npid\n:\n100\n)\n:\n \nf_name\n:\n \n/\nproc\n/\nmeminfo\n,\n \nflags\n:\n \n80000\n,\n \nmode\n:\n \n1\nb6\n\n\n[\n11842.428064\n]\n \nSYSC_open\n(\ncpu16\n \npid\n:\n89\n)\n:\n \nfd\n:\n \n9\n\n\n[\n11842.476942\n]\n \nSYSC_open\n(\ncpu4\n \npid\n:\n100\n)\n:\n \nfd\n:\n \n10\n\n\n[\n11842.526860\n]\n \nseq_file\n:\n\n  \ndest_uva\n:\n \n00007ff\nff444c000\n,\n \nnr_chars\n:\n \n172\n\n  \nstring\n:\n \n[\nMemTotal\n:\n       \n115355128\n \nkB\n\n\nMemFree\n:\n        \n115355128\n \nkB\n\n\nMemAvailable\n:\n   \n115355128\n \nkB\n\n\nDirectMap4k\n:\n        \n5812\n \nkB\n\n\nDirectMap2M\n:\n     \n1861632\n \nkB\n\n\nDirectMap1G\n:\n    \n134217728\n \nkB\n\n\n]\n\n\n[\n11842.800368\n]\n \nseq_file\n:\n\n  \ndest_uva\n:\n \n00007ff\nff444b000\n,\n \nnr_chars\n:\n \n172\n\n  \nstring\n:\n \n[\nMemTotal\n:\n       \n115355128\n \nkB\n\n\nMemFree\n:\n        \n115355128\n \nkB\n\n\nMemAvailable\n:\n   \n115355128\n \nkB\n\n\nDirectMap4k\n:\n        \n5812\n \nkB\n\n\nDirectMap2M\n:\n     \n1861632\n \nkB\n\n\nDirectMap1G\n:\n    \n134217728\n \nkB\n\n\n]\n\n\n[\n11843.073877\n]\n \nSYSC_close\n(\ncpu16\n \npid\n:\n89\n)\n:\n \nfd\n:\n \n9\n\n\n\n\n\n\n\n\n\n\nHowever, in a normal Linux exeution:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\nstrace\n \n-\nC\n \n-\no\n \nstrace_2\n \n.\n/\nword_count\n-\npthread\n \n.\n/\nword_count_datafiles\n/\nword_50MB\n.\ntxt\n\n\n\n%\n \ntime\n     \nseconds\n  \nusecs\n/\ncall\n     \ncalls\n    \nerrors\n \nsyscall\n\n\n------\n \n-----------\n \n-----------\n \n---------\n \n---------\n \n----------------\n\n \n86.41\n    \n0.052074\n        \n1736\n        \n30\n           \nfutex\n\n  \n6.89\n    \n0.004151\n          \n67\n        \n62\n           \nmunmap\n\n  \n2.47\n    \n0.001490\n          \n17\n        \n88\n           \nmmap\n\n  \n2.12\n    \n0.001278\n          \n14\n        \n93\n           \nclone\n\n  \n1.51\n    \n0.000912\n          \n14\n        \n64\n           \nmprotect\n\n  \n0.19\n    \n0.000117\n           \n7\n        \n16\n           \nwrite\n\n\n  \n0.15\n    \n0.000092\n          \n46\n         \n2\n           \nopen\n\n\n\n\n$\n \ncat\n \nstrace_2\n \n|\n \ngrep\n \nopen\n\n\n  \nopen\n(\n./word_count_datafiles/word_50MB.txt\n,\n \nO_RDONLY\n)\n \n=\n \n3\n\n\n  \nopen\n(\n/sys/devices/system/cpu/online\n,\n \nO_RDONLY\n|\nO_CLOEXEC\n)\n \n=\n \n4\n\n\n\n\n\n\n\n\n\n\nIt opened the \n/proc/meminfo\n for way too many times. In the normal Linux execution, this should not happen. Is it because our meminfo is faked, so glibs is complaining? But why it does not open meminfo while running in Linux? Or does our entry assembly messed up some stuff in stack, so the return path changed?\n\n\n\n\n\n\noh, about the FPU. It reminds our \nflush_thread\n function actually has an issue before. When I enabled this function during loading in P, the P will crash. Within \nflush_thread\n, there is a \nfpu_clear\n!!! So, check this tomorrow! (12:00am, need to go home)\n\n\n\n\n\n\n\n\n02/18 Sun Sunny\n\n\nIt is a nice day. Yesterday I\nve changed one line of code in mmap code path: change anonymous vma\ns pgoff from some value to 0. The result is I got several succeed work-count-pthread(bind to one core) testing. However, it still fail with unmodified word-count-pthread.\n\n\nIt brings me to inspect pgoff manipulation code and all mmap.c code. We ported everything from linux without almost zero modification. That means we ported all those useless \nanon_vma\n and pgoff code, which is used a lot by vma_merge, vma_split code. The thing is: our memory manager, our vma code do not need such \nanon_vma\n structure, and do not maintain pgoff. Thus, I\nm a little bit worried linux code may doing some crazy behind our back: mess vma and pages, then pcache miss gets some wrong pages\n\n\nWell. Lego does not use \nanon_vma\n, and pgoff should only be used by file-backed vma. So, I decided to remove \nanon_vma\n from our code, and make sure pgoff is used properly. Of course, the goal is to make vma_merge, split,\ncopy, do the things we intended.\n\n\nLesson learned.\n\n\n\n\n02/17 Sat Snowy\n\n\nFixed the bss bug. It comes from loader. We did not implement the \nlego_clear_user\n function, so some part of bss is non-zero.\n\n\nBad news is word_count-pthread still fail at same fpu instruction. Have to look into memory code more.\n\n\nThis is actually a fun debugging story. We should always add TODO or XXX or some warnings to unfinished code, no matter what. Lesson learned.\n\n\n\n\n02/16 Fri Cloudy\n\n\nYilun found a major loader bug yesterday: the \n.bss\n section variables are not 0, in the \niozone\n benchmark. I did not encounter this issue before with simple test program. This is pretty serious.\n\n\n\n\n02/15 Thur Rainy\n\n\nToday is Chinese New Year.\n\n\nLine 7 and 8 show the uva belong to the same page. Need to revisit \nget_arg_pages\n etc functions.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n[  108.393991] handle_p2m_execve(): pid:22,argc:2,envc:2,file:/root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread\n[  108.395255]     argc[0] (len: 65):  /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread\n[  108.396329]     argc[1] (len: 82):  /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_100MB.txt\n[  108.397530]     envc[0] (len:  7):  HOME=/\n[  108.398069]     envc[1] (len: 11):  TERM=linux\n[  108.398640] __bprm_mm_init vma: ffff88083effe6b8\n\n[  108.399226] faultin_page vma: ffff88083effe6b8 uva: 0x7fffffffefed\n\n[  108.399949] faultin_page vma: ffff88083effe6b8 uva: 0x7fffffffef94\n\n\n\n\n\n\nWell, this is 100% fine. I wrote this loader code long time ago and need some time to pickup. So, after I read the loader code, especially the \ncopy_strings\n function, I found this is okay. Because copy_strings will be invoked three times, so the \nfaultin_page\n basically will be invoked at least three times. That is why it went to that pte fault handling code.\n\n\nAlthough actually I think \ncopy_strings\n should \nnot\n use \nfaultin_page\n, instead, it should use \nget_user_pages\n, which will walk through the pgtable first, then went to \nhandle_lego_mm_fault\n.\n\n\n\n\n02/14 Wed Rainy\n\n\nHmm, tried to make kmalloc behave as kzalloc, and bind all threads to one core, still gave the same old bug:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n  42731a:       f3 0f 6f 16             movdqu (%rsi),%xmm2\n\n\n  [93182.657376] word_count-pthr[85] general protection ip:42731a sp:7fffe3ffed28 error:0\n  [93182.747959] CPU: 8 PID: 85 Comm: word_count-pthr 4.0.0-lego+ #170\n  [93182.820758] RIP: 0033:[\n000000000042731a\n]  [\n000000000042731a\n] 0x42731a\n  [93182.901878] RSP: 002b:00007fffe3ffed28  EFLAGS: 00010283\n  [93182.965317] RAX: 000000000000001f RBX: 00007ffff001b010 RCX: 0000000000000005\n  [93183.050596] RDX: 0000000000000000 RSI: 5345485355420045 RDI: 00007ffff294791f\n  [93183.135876] RBP: 00007ffff294791f R08: 000000000000ffff R09: 0000000000000008\n  [93183.221156] R10: fffffffffffff048 R11: 00000000004acfc0 R12: 0000000000001cde\n  [93183.306435] R13: 00000000006e4a8c R14: 0000000000001cd7 R15: 0000000000001cda\n  [93183.391716] FS:  00007fffe3fff700(0000) GS:ffff88107fc80000(0000) knlGS:0000000000000000\n  [93183.488434] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n  [93183.557075] CR2: 00007ffff27a4000 CR3: 000000107e924000 CR4: 00000000000406a0\n\n\n\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n  427377:       66 0f 6f 17             movdqa (%rdi),%xmm2\n\n\n  [93180.527248] word_count-pthr[93]: segfault at 0x0 ip 0000000000427377 sp 00007fffdfff6d28 error 4\n  [93180.630314] CPU: 8 PID: 93 Comm: word_count-pthr 4.0.0-lego+ #170\n  [93180.703114] RIP: 0033:[\n0000000000427377\n]  [\n0000000000427377\n] 0x427377\n  [93180.784234] RSP: 002b:00007fffdfff6d28  EFLAGS: 00010297\n  [93180.847674] RAX: 0000000000000000 RBX: 000000000073c4c0 RCX: 000000000000000d\n  [93180.932953] RDX: 000000000000ffff RSI: 00007ffff4999070 RDI: 0000000000000000\n  [93181.018233] RBP: 00007ffff499907d R08: 000000000000ffff R09: 0000000000000000\n  [93181.103513] R10: 0000000000427760 R11: 00007ffff49982c0 R12: 0000000000000118\n  [93181.188791] R13: 00000000006e4aac R14: 0000000000000116 R15: 0000000000000117\n  [93181.274072] FS:  00007fffdfff7700(0000) GS:ffff88107fc80000(0000) knlGS:0000000000000000\n  [93181.370790] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n  [93181.439430] CR2: 0000000000000000 CR3: 000000107e924000 CR4: 00000000000406a0\n\n\n\n\n\n\nTried several ways to ensure memory safety. It still failed even if I enabled all of them. So, I guess the memory safety is ensured? Still some other things?\n\n\n\n\nforce \nalloc_pages\n to use \n__GFP_ZERO\n\n\nmake \nkmalloc\n behave as \nkzalloc\n\n\nmake \nkfree\n empty\n\n\n\n\nI also suspect \nmunmap\n may free extra wrong pgtable entries. Although I\nve went through all the code and checked, but in addition to the above things, I\nm going to:\n\n\n\n\nmake munmap dummy (no p2m_munmap, return 0 directly)\n\n\n\n\nFailed.\n\n\nNext, I\nm going to:\n\n\n\n\nadd checksum for every page transferred across network.\n\n\nadd warning for unnormal cases\n\n\n\n\nBang! I found something while running P+M:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n[\n  \n115.727597\n]\n \nMemory\n-\ncomponent\n \nmanager\n \nis\n \nup\n \nand\n \nrunning\n.\n\n\n[\n  \n116.691723\n]\n \nhandle_p2m_fork\n()\n:\n \nnid\n:\n0\n,\npid\n:\n22\n,\ntgid\n:\n22\n,\nparent_tgid\n:\n1\n\n\n[\n  \n116.697038\n]\n \nhandle_p2m_fork\n()\n:\n \nreply\n:\n \n0\n:\nOKAY\n\n\n[\n  \n116.791088\n]\n \nhandle_p2m_execve\n()\n:\n \npid\n:\n22\n,\nargc\n:\n2\n,\nenvc\n:\n2\n,\nfile\n:\n/\nroot\n/\nys\n/\nphoenix\n/\nphoenix\n-\n2.0\n/\ntests\n/\nword_count\n/\nword_count\n-\npthread\n\n\n[\n  \n116.792357\n]\n     \nargc\n[\n0\n]\n \n(\nlen\n:\n \n65\n)\n:\n  \n/\nroot\n/\nys\n/\nphoenix\n/\nphoenix\n-\n2.0\n/\ntests\n/\nword_count\n/\nword_count\n-\npthread\n\n\n[\n  \n116.793439\n]\n     \nargc\n[\n1\n]\n \n(\nlen\n:\n \n82\n)\n:\n  \n/\nroot\n/\nys\n/\nphoenix\n/\nphoenix\n-\n2.0\n/\ntests\n/\nword_count\n/\nword_count_datafiles\n/\nword_100MB\n.\ntxt\n\n\n[\n  \n116.794653\n]\n     \nenvc\n[\n0\n]\n \n(\nlen\n:\n  \n7\n)\n:\n  \nHOME\n=/\n\n\n[\n  \n116.795196\n]\n     \nenvc\n[\n1\n]\n \n(\nlen\n:\n \n11\n)\n:\n  \nTERM\n=\nlinux\n\n\n[\n  \n116.795772\n]\n \n__bprm_mm_init\n \nvma\n:\n \nffff88083effe6b8\n\n\n[\n  \n116.796209\n]\n \nfaultin_page\n \nvma\n:\n \nffff88083effe6b8\n\n\n[\n  \n116.796729\n]\n \nfaultin_page\n \nvma\n:\n \nffff88083effe6b8\n\n\n[\n  \n116.797150\n]\n \nhandle_pte_fault\n \nvma\n:\n \nffff88083effe6b8\n \nentry\n:\n \n0xffff88083e8c1067\n\n\n[\n  \n116.798044\n]\n \npte\n:\nffff88083e8c0ff0\n \npfn\n:\n0x8083e8c1\n \nflags\n:(\npresent\n|\nwritable\n|\nuser\n|\naccessed\n|\ndirty\n|\nsoftw4\n|\npkey0\n|\npkey1\n|\npkey2\n|\npkey3\n|\nnx\n|\n0x3ff800000000000\n)\n\n\n[\n  \n116.799462\n]\n \n------------\n[\n \ncut\n \nhere\n \n]\n------------\n\n\n[\n  \n116.800049\n]\n \nWARNING\n:\n \nCPU\n:\n \n4\n \nPID\n:\n \n15\n \nat\n \nmanagers\n/\nmemory\n/\nvm\n/\nfault\n.\nc\n:\n148\n \nhandle_lego_mm_fault\n+\n0x4d8\n/\n0x550\n\n\n[\n  \n116.801148\n]\n \nCPU\n:\n \n4\n \nPID\n:\n \n15\n \nComm\n:\n \nmc\n-\nmanager\n \n4.0.0\n-\nlego\n+\n \n#\n78\n\n\n[\n  \n116.801818\n]\n \nStack\n:\n\n\n[\n  \n116.802179\n]\n \nffff88083e893c50\n \nffffffff8100e827\n \n00007ff\nfffffef94\n \nffff88083effe6b8\n\n\n[\n  \n116.803283\n]\n \nffff88083e894008\n \nffff88083e8c1067\n \nffff88083e893c60\n \nffffffff8100e91f\n\n\n[\n  \n116.804387\n]\n \nffff88083e893cf0\n \nffffffff8102b008\n \n0000000000000031\n \nffff88083e893cf0\n\n\n[\n  \n116.805488\n]\n \n00000000000002\n96\n \n00003ff\nfffe00000\n \nffff800000000067\n \nffff88083e893d50\n\n\n[\n  \n116.806590\n]\n \nffff880000000001\n \nffffffff81066798\n \nffff88083effe6b8\n \nffff88083e893d50\n\n\n[\n  \n116.807691\n]\n \nCall\n \nTrace\n:\n\n\n[\n  \n116.808087\n]\n \nTSK\n\n\n[\n  \n116.808448\n]\n \n[\nffffffff8100e836\n]\n \n__warn\n.\nconstprop\n.0\n+\n0xa6\n/\n0x100\n\n\n[\n  \n116.809126\n]\n \n[\nffffffff8100e91f\n]\n \nwarn_slowpath_null\n+\n0xf\n/\n0x20\n\n\n[\n  \n116.809802\n]\n \n[\nffffffff8102b008\n]\n \nhandle_lego_mm_fault\n+\n0x4d8\n/\n0x550\n\n\n[\n  \n116.810505\n]\n \n[\nffffffff8102cfe3\n]\n \nfaultin_page\n+\n0x43\n/\n0xb0\n\n\n[\n  \n116.811131\n]\n \n[\nffffffff8102dab1\n]\n \ncopy_strings\n.\nisra\n.1\n+\n0xe1\n/\n0x130\n\n\n[\n  \n116.811819\n]\n \n[\nffffffff8102dd1e\n]\n \nexec_loader\n+\n0x21e\n/\n0x350\n\n\n[\n  \n116.812457\n]\n \n[\nffffffff8102680a\n]\n \nhandle_p2m_execve\n+\n0x1aa\n/\n0x290\n\n\n\n\n\n\nThis is a temporary stack vma that loader created for saving argv and envp. So, this vma was created here:\n\n\n1\n2\n3\n4\n5\n6\nstatic\n \nint\n \n__bprm_mm_init\n(\nstruct\n \nlego_binprm\n \n*\nbprm\n)\n\n\n{\n\n        \n...\n\n        \nbprm\n-\nvma\n \n=\n \nvma\n \n=\n \nkzalloc\n(\nsizeof\n(\n*\nvma\n),\n \nGFP_KERNEL\n);\n\n        \n...\n\n\n}\n\n\n\n\n\n\n\nAnd then \ncopy_strings\n will call \nfaultin_page\n to populate a page for a specific user virtual adddress:\n\n\n1\n2\n3\n4\n5\n6\n7\nint\n \nfaultin_page\n(\nstruct\n \nvm_area_struct\n \n*\nvma\n,\n \nunsigned\n \nlong\n \nstart\n,\n\n                 \nunsigned\n \nlong\n \nflags\n,\n \nunsigned\n \nlong\n \n*\nkvaddr\n)\n\n\n{\n\n        \n...\n\n        \nret\n \n=\n \nhandle_lego_mm_fault\n(\nvma\n,\n \nstart\n,\n \nflags\n,\n \nkvaddr\n);\n\n        \n...\n\n\n}\n\n\n\n\n\n\n\nEventually, the \nhandle_lego_mm_fault\n will call \nhandle_pte_fault\n:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\nstatic\n \nint\n \nhandle_pte_fault\n(\nstruct\n \nvm_area_struct\n \n*\nvma\n,\n \nunsigned\n \nlong\n \naddress\n,\n\n                            \nunsigned\n \nint\n \nflags\n,\n \npte_t\n \n*\npte\n,\n \npmd_t\n \n*\npmd\n,\n\n                            \nunsigned\n \nlong\n \n*\nmapping_flags\n)\n\n\n{\n\n        \n...\n\n        \nif\n \n(\n!\npte_present\n(\nentry\n))\n \n{\n\n                \n...\n\n        \n}\n\n\n        \npr_info\n(\n%s vma: %p entry: %#lx\n\\n\n,\n \nFUNC\n,\n \nvma\n,\n \nentry\n.\npte\n);\n\n        \ndump_pte\n(\npte\n,\n \nNULL\n);\n\n        \nWARN_ON_ONCE\n(\n1\n);\n\n        \n...\n\n\n}\n\n\n\n\n\n\n\nApparently, pte is wrong! But I don\nt have time today. Continue tomorrow.\nHmm forgot that we are saving kernel virtual addresses in the pte. Just take a quick look at the lego_pud_alloc things, seems will have some issues. I defenitly need to check all these stuff tomorrow. I\nve not touch this part for too long!\n\n\n\n\n02/13 Tue Sunny\n\n\nChecking our SLOB allocator today. So I found Yutong\ns code is using \nset_page_private\n when slob get a new page from buddy. This private field is only intended to be used by buddy to record the \norder\n. This mixed usage will confuse buddy and create bug.\n\n\nEven though I removed the \nset_page_private\n(\npage\n,\n \n0\n)\n after \nfree_page\n, word_count-pthread still fails. Damn.\n\n\n\n\n02/12 Mon Cloudy\n\n\nAdd this commit \n4cb3a8b6a943c90714fd9bb5e5465ee315f0aa30\n:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n    memory: Use kzalloc instead of kmalloc in __bprm_mm_init (loader)\n\n    This was an potentionl bug that was not triggered previously.\n    It is simply because kmalloc\ned vma contains some garbage area,\n    while later in the pgfault code, we use\n            if (vma-\nvm_ops \n vma-\nvm_ops-\nfault)\n                    ...\n    to check if it is an file-backed fault.\n\n    Fortunately the vma-\nvm_ops happens to have some leftover value.\n    So this bug was triggered.\n\n    This actually reminds me that this is a series of potential bugs!\n    Even though before I\nve added things like force GFP_ZERO in all\n    physical page allocation, I missed the kmalloc\ns case!\n\n\n\n\n\nThe story is:\n\n\nI patched the stop_machine code today, and tried to run code with P+M on VM, everything works fine. However, when I tried to run the new code with P+M+S on physical machine, M crashed at a very weird point:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n[ 7791.998168] handle_p2m_execve(): pid:81,argc:2,envc:2,file:/root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread\n[ 7792.129312] BUG: unable to handle kernel NULL pointer dereference at 0000000000000031\n[ 7792.222889] IP: [\nffffffff8102c180\n] handle_lego_mm_fault+0x160/0x4b0\n[ 7792.299842] PGD 0\n[ 7792.323760] Oops: 0000 [#1] PREEMPT SMP MEMORY\n[ 7792.376794] CPU: 4 PID: 79 Comm: mc-manager 4.0.0-lego+ #29\n\n[ 7792.443349] RIP: .. [\nffffffff8102c180\n] handle_lego_mm_fault+0x160/0x4b0\n\n......\n....\n[ 7793.750506] Call Trace:\n[ 7793.779623] \nTSK\n\n\n[ 7793.802501] [\nffffffff810053f4\n] ? apic_timer_interrupt+0x54/0x90\n\n[ 7793.875295] [\nffffffff8102e469\n] faultin_page+0x9/0x70\n\n[ 7793.936649] [\nffffffff8102ef01\n] copy_strings.isra.1+0xe1/0x130\n\n[ 7794.007362] [\nffffffff8102f11e\n] exec_loader+0x1ce/0x340\n\n[ 7794.070796] [\nffffffff81027def\n] handle_p2m_execve+0x12f/0x200\n\n[ 7794.140469] [\nffffffff810274fb\n] mc_manager+0x1ab/0x2b0\n[ 7794.202864] [\nffffffff81027350\n] ? bitmap_fill+0x33/0x33\n[ 7794.266298] [\nffffffff8101c6b7\n] kthread+0x107/0x130\n[ 7794.325572] [\nffffffff8101c5b0\n] ? __kthread_parkme+0x90/0x90\n[ 7794.394205] [\nffffffff8100b462\n] ret_from_fork+0x22/0x30\n\n\n\n\n\nSo faulting source code is:\n\n1\n2\n3\n4\n5\n6\n7\n8\nstatic\n \nint\n \nhandle_pte_fault\n(\nstruct\n \nvm_area_struct\n \n*\nvma\n,\n \nunsigned\n \nlong\n \naddress\n,\n\n                            \nunsigned\n \nint\n \nflags\n,\n \npte_t\n \n*\npte\n,\n \npmd_t\n \n*\npmd\n)\n\n\n{\n\n    \n....\n\n\n        \nif\n \n(\nvma\n-\nvm_ops\n \n \nvma\n-\nvm_ops\n-\nfault\n)\n\n\n                \nreturn\n \ndo_linear_fault\n(\nvma\n,\n \naddress\n,\n \nflags\n,\n\n\n                                       \npte\n,\n \npmd\n,\n \nentry\n)\n\n    \n....\n\n\n\n\n\n\nSomething wrong with \nvma\n? At this loader stage, this vma is a temporaty stack vma created for saving \nargv\n and \nenvp\n. So I look back into the code that created this vma:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\nmanagers\n/\nmemory\n/\nloader\n/\ncore\n.\nc\n:\n\n\nstatic\n \nint\n \n__bprm_mm_init\n(\nstruct\n \nlego_binprm\n \n*\nbprm\n)\n\n\n{\n\n        \nint\n \nerr\n;\n\n        \nstruct\n \nvm_area_struct\n \n*\nvma\n \n=\n \nNULL\n;\n\n        \nstruct\n \nlego_mm_struct\n \n*\nmm\n \n=\n \nbprm\n-\nmm\n;\n\n\n\n        \nbprm\n-\nvma\n \n=\n \nvma\n \n=\n \nkmalloc\n(\nsizeof\n(\n*\nvma\n),\n \nGFP_KERNEL\n);\n\n\n        \nif\n \n(\n!\nvma\n)\n\n                \nreturn\n \n-\nENOMEM\n;\n\n\n\n\n\n\nThe code after this does NOT do necessary cleanup. The \nvm_ops\n happens to have some garbage value from last user. So it is not 0, so the above \nvma-\nvm_ops\n is true, and it will try to read \nvma-\nvm_ops-\nfault\n. And that, my friend, is where garbage turns into crash.\n\n\nThis presents a series of potential bugs. Ugh, \nmemory safety\n!\n\n\n\n\n02/09 Fri Cloudy\n\n\nTried to modify Phoneix code: replace \nrealloc\n with \nmalloc+mempcy\n. Thus the \nmremap\n syscall is avoided, but it still has general protection fault. Same with yesterday, corrupted at \n__strcmp_sse42\n, with corrupted \nRSI\n or \nRDI\n. So I guess it is not about \nmremap\n itself at all. I will follow yesterday\ns checking list.\n\n\n\n\n02/08 Thur Cloudy\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n00000000004272d0 \n__strcmp_sse42\n:\n\n  4272d0:       89 f1                   mov    %esi,%ecx\n  4272d2:       89 f8                   mov    %edi,%eax\n  4272d4:       48 83 e1 3f             and    $0x3f,%rcx\n  4272d8:       48 83 e0 3f             and    $0x3f,%rax\n  4272dc:       83 f9 30                cmp    $0x30,%ecx\n  4272df:       77 3f                   ja     427320 \n__strcmp_sse42+0x50\n\n  4272e1:       83 f8 30                cmp    $0x30,%eax\n  4272e4:       77 3a                   ja     427320 \n__strcmp_sse42+0x50\n\n  4272e6:       f3 0f 6f 0f             movdqu (%rdi),%xmm1\n\n* 4272ea:       f3 0f 6f 16             movdqu (%rsi),%xmm2\n\n  4272ee:       66 0f ef c0             pxor   %xmm0,%xmm0\n  4272f2:       66 0f 74 c1             pcmpeqb %xmm1,%xmm0\n  4272f6:       66 0f 74 ca             pcmpeqb %xmm2,%xmm1\n  4272fa:       66 0f f8 c8             psubb  %xmm0,%xmm1\n  4272fe:       66 0f d7 d1             pmovmskb %xmm1,%edx\n  427302:       81 ea ff ff 00 00       sub    $0xffff,%edx\n  427308:       0f 85 42 0d 00 00       jne    428050 \n__strcmp_sse42+0xd80\n\n  42730e:       48 83 c6 10             add    $0x10,%rsi\n  427312:       48 83 c7 10             add    $0x10,%rdi\n  427316:       66 2e 0f 1f 84 00 00    nopw   %cs:0x0(%rax,%rax,1)\n  42731d:       00 00 00  \n  427320:       48 83 e6 f0             and    $0xfffffffffffffff0,%rsi\n  427324:       48 83 e7 f0             and    $0xfffffffffffffff0,%rdi\n  427328:       ba ff ff 00 00          mov    $0xffff,%edx\n  42732d:       45 31 c0                xor    %r8d,%r8d\n  427330:       83 e1 0f                and    $0xf,%ecx\n  427333:       83 e0 0f                and    $0xf,%eax\n  427336:       66 0f ef c0             pxor   %xmm0,%xmm0\n  42733a:       39 c1                   cmp    %eax,%ecx\n  42733c:       74 32                   je     427370 \n__strcmp_sse42+0xa0\n\n  42733e:       77 07                   ja     427347 \n__strcmp_sse42+0x77\n\n  427340:       41 89 d0                mov    %edx,%r8d\n  427343:       91                      xchg   %eax,%ecx\n  427344:       48 87 f7                xchg   %rsi,%rdi\n\n* 427347:       66 0f 6f 17             movdqa (%rdi),%xmm2\n\n  (RDI: 0000000000000000)\n\n\n\n\n\n\nFrustrating! What is wrong with multithread program? Because of broken FPU-switch code? of inappropriate TLB flush? of IB corrupts memory? of what? ugh?\n\n\nI\nm done with this random guess and frustrated general protection or segfault, I need to first make sure underlying kernel is 100%  percent correct, this is a checking list:\n\n\n\n\nfpu save/restore\n\n\nalways fail at some XMM instruction\n\n\nalways with corrupted RDI or RSI\n\n\n\n\n\n\nswitch_to_asm\n\n\n%gs and %fs\n\n\nswitch_mm (pgd)\n\n\nstack frame\n\n\n\n\n\n\nset_arch_tls (%fs)\n\n\nglibc\ns way of using per thread data\n\n\n\n\n\n\nsome cpu may miss tlb flush\n\n\nkernel entry/exit assembly\n\n\ncurrent_task macro\n\n\nstack_stratch\n\n\nper-cpu data in entry.S\n\n\n\n\n\n\nfutex\n\n\nclear_tid\n\n\nset_tid\n\n\nshared mm\n\n\nrobust list\n\n\n\n\n\n\ninterrupts\n\n\nvector array\n\n\nAPIC setup\n\n\nIO-APIC\n\n\ntimer interrupt\n\n\n\n\n\n\ncpu_init and Trampoline\n\n\nfaked kernel version\n\n\nP side pgfault handling code (SMP)\n\n\nand M side pgfault handling (SMP)\n\n\nmremap, munmap\n\n\ncheck pgtable boundary\n\n\n\n\n\n\nIn all, check SMP implications\n\n\n\n\nIs there any code, that is solely used to test if the underlying kernel has appropriate behaviors? Like glibc test code?\n\n\nHow to protect kernel virtual memory? Any existing solutions in Linux?\n\n\nWhat is the implication of multiple CPU entering kernel at the same time? How can it corrupt user pages? Maybe: kernel entry code, per-cpu data in entry code, fpu code, switch_to, scheduler.\n\n\nWhy it always fail at those FPU code i.e. the strcmp function? I failed to compile without those sse, any solution? How it hurt performance?\n\n\n\n\n02/07 Wed Cloudy\n\n\n20\n:\n07\n\nPushed a small patch on mremap issue. Hope it will work. mremap really makes the whole thing very interesting, will be a very good research finding on combing virtual cache and operating system. Need to go gym with a friend, will be back on debugging late tonight.\n\n\n9\n:\n30\n\nHave two meetings to do today, and an security class, won\nt have too much time coding during daytime.\n\n\n\n\n02/06 Tue Sunny\n\n\nWell. We\nve ruled out both \nsmp_call_function\n and \nworkqueue\n yesterday with Yiying\ns help. But the multi-thread word-count still fails \n:-(\n Single thread word-count just finished 4GB dataset (with 8GB pcache). So what could be still wrong with multithread one????\n\n\n\n\nchill\n\n\ncheck exit code\n\n\n(Checked)\n check pcache\ns usage of task_struct, should always use the group_leader\n\n\ncheck cpu boot code and check the switch code again\n\n\nI believe pinpoint the issue in multithread word-count can solve a lot issues, it must be some thread creation, removal, schedule things.\n\n\nHow about adding a lock for ibapi, make it sequential? Sweet, I tried, finally it is \na bug that we are able to debug\n.\n\n\n\n\n22\n:\n39\n\nDone for today. I\nm trying to patch \nmove_pte\n and \npcache_move_pte\n. Although in theory we defenitly need to patch it, I keep thinking the code before should not trigger any serious bus or memory corruption. Ugh. Maybe it is concurrent \nmremap\n that one of them remap from A to B, while another one remap from C to A. It is possible. But my dead brain can not think of this anymore. I\nm going to hit the gym and do some squats.\n\n\n17\n:\n01\n\nCriminal found: \nmremap()\n and \nvirtual cache\n did the crime. Interesting, I have not seen any research paper, tech-reports, writeup, code about this, not even the OVC paper, which, by the way, I think they must consider this case. Otherwise, a mremap will simply crash its virtual cache. Many thanks went to my smoke-and-think time.\n\n\n15\n:\n14\n\nSomething new came up! After adding a spinlock for ibapi, this showed up (I tried one more time after this, which does not show up). We are lucky to catch this. At least I know where to look at. Also, this is defenitly triggered by \nmremap\n. It is seems it is overlapped \nmremap()\n. One thing I did not know is which thread trigger this bug, the sweep thread? Cause mremap related pcache rmap functions do not use \nrmap_get_locked_pte\n.\n\n\n1\n2\n3\n4\n5\n6\n7\n[ 3826.048774] normal_p2s_open(): f_name: word_100MB.txt, mode: 04400, flags: 0\n[ 3827.891622] SYSC_mremap(cpu18): move: [0x7fffe5788000 - 0x7fffe5806000] -\n [0x7fffe531b000 - 0x7fffe5399000]\n[ 3828.178643] SYSC_mremap(cpu14): move: [0x7fffe5941000 - 0x7fffe5980000] -\n [0x7fffe57c7000 - 0x7fffe5806000]\n\n****    ERROR: mismatched PTE and rmap\n****    rmap-\nowner_process: word_count-pthr uva: 0x7fffe57c8000 ptep: ffff88107efe0e40, rmap-\npage_table: ffff88107efe0e40\n****    pcache_pfn: 0x1257c8, pte_pfn: 0x125942\n\n\n\n\n\n\n14\n:\n00\n \n\n\nword_count-pthread\n: 100MB dataset\n\npcache\n: 8GB, 8-way\n\nvictim\n: 8 entries\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n[ 1294.845313] STDOUT: ---[\nWordcount: Running...\n]---\n[ 1294.903661] STDOUT: ---[\n\no;\n]---\n[ 1294.946301] normal_p2s_open(): f_name: /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_100MB.txt, mode: 04400, flags: 0\n[ 1295.100517] SYSC_close(): [4] -\n [/sys/devices/system/cpu/online]\n[ 1295.594658] word_count-pthr[59] general protection ip:4272ea sp:7ffff1b8ed28 error:0\n[ 1295.685236] CPU: 10 PID: 59 Comm: word_count-pthr 4.0.0-lego+ #113\n[ 1295.759070] RIP: 0033:[\n00000000004272ea\n]  [\n00000000004272ea\n] 0x4272ea\n[ 1295.840184] RSP: 002b:00007ffff1b8ed28  EFLAGS: 00010283\n[ 1295.903621] RAX: 000000000000000f RBX: 00007fffe5a3d010 RCX: 0000000000000001\n[ 1295.988893] RDX: 0000000000000000 RSI: 4854005942004441 RDI: 00007ffff1c1e80f\n[ 1296.074166] RBP: 00007ffff1c1e80f R08: 0000000000000000 R09: 0000000000000010\n[ 1296.211435] R10: 0000000000427ce0 R11: 00007ffff1bbb3ba R12: 0000000000001de4\n[ 1296.296711] R13: 00000000006e4a80 R14: 0000000000001d9e R15: 0000000000001dc1\n[ 1296.433978] FS:  00007ffff1b8f700(0000) GS:ffff88107fca0000(0000) knlGS:0000000000000000\n[ 1296.582686] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[ 1296.963297] CR2: 00007ffff1c1e000 CR3: 000000207fd8a000 CR4: 00000000000406a0\n\n\n\n\nSo what is this \nip\n:\n4272\nea\n, let us objdump the binary:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n0000000000425e60 \nstrcmp\n:\n  425e60:       48 8d 05 69 14 00 00    lea    0x1469(%rip),%rax        # 4272d0 \n__strcmp_sse42\n\n  425e67:       f7 05 5f b8 2b 00 00    testl  $0x100000,0x2bb85f(%rip)        # 6e16d0 \n_dl_x86_cpu_features+0x10\n\n  425e6e:       00 10 00\n  425e71:       75 1a                   jne    425e8d \nstrcmp+0x2d\n\n  425e73:       48 8d 05 46 b0 00 00    lea    0xb046(%rip),%rax        # 430ec0 \n__strcmp_ssse3\n\n  425e7a:       f7 05 4c b8 2b 00 00    testl  $0x200,0x2bb84c(%rip)        # 6e16d0 \n_dl_x86_cpu_features+0x10\n\n  425e81:       02 00 00\n  425e84:       75 07                   jne    425e8d \nstrcmp+0x2d\n\n  425e86:       48 8d 05 03 00 00 00    lea    0x3(%rip),%rax        # 425e90 \n__GI_strcmp\n\n  425e8d:       c3                      retq\n  425e8e:       66 90                   xchg   %ax,%ax\n .. ..\n .. ..\n00000000004272d0 \n__strcmp_sse42\n:\n  4272d0:       89 f1                   mov    %esi,%ecx\n  4272d2:       89 f8                   mov    %edi,%eax\n  4272d4:       48 83 e1 3f             and    $0x3f,%rcx\n  4272d8:       48 83 e0 3f             and    $0x3f,%rax\n  4272dc:       83 f9 30                cmp    $0x30,%ecx\n  4272df:       77 3f                   ja     427320 \n__strcmp_sse42+0x50\n\n  4272e1:       83 f8 30                cmp    $0x30,%eax\n  4272e4:       77 3a                   ja     427320 \n__strcmp_sse42+0x50\n\n  4272e6:       f3 0f 6f 0f             movdqu (%rdi),%xmm1\n* 4272ea:       f3 0f 6f 16             movdqu (%rsi),%xmm2\n  4272ee:       66 0f ef c0             pxor   %xmm0,%xmm0\n\n\n\n\nYou can see \n%rsi\n has some garbage value \nRSI\n:\n \n4854005942004441\n. Something went wrong. Will it be our FPU? I\nm not quite sure. If FPU code has error, why single-thread one succeed? Why it only shows up at multithread ones?\n\n\n\n\n02/05 Mon Sunny\n\n\nFrom yesterday\ns testing of Phoenix, it looks like something is wrong in \nsmp_call_functions()\n. They are invoked through \ntlb flush\n, which was further invoked by \nmremap\n, or \nmunmap\n. The warning from smp is:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n[\n \n1260.586696\n]\n \nWARNING\n:\n \nCPU\n:\n \n0\n \nPID\n:\n \n73\n \nat\n \nkernel\n/\nsmp\n.\nc\n:\n129\n \ngeneric_smp_call_function_single_interrupt\n+\n0xb8\n/\n0x160\n\n\n[\n \n1260.705251\n]\n \nCPU\n:\n \n0\n \nPID\n:\n \n73\n \nComm\n:\n \nword_count\n-\npthr\n \n4.0.0\n-\nlego\n+\n \n#\n99\n\n\n[\n \n1260.777008\n]\n \nStack\n:\n\n\n[\n \n1260.800927\n]\n \nffff88207fdffef8\n \nffffffff8100ec67\n \nffff88107fc00000\n \nffff88107fc00000\n\n\n[\n \n1260.888283\n]\n \nffffffff8100d410\n \nffff88207fe23df0\n \nffff88207fdfff08\n \nffffffff8100ed5f\n\n\n[\n \n1260.975639\n]\n \nffff88207fdfff38\n \nffffffff8100fe68\n \n00007ff\nfe58c3010\n \n0000000000000f\n96\n\n\n[\n \n1261.062995\n]\n \n000000000000f\n960\n \n0000000000000f\n95\n \nffff88207fdfff48\n \nffffffff810020dd\n\n\n[\n \n1261.150351\n]\n \n00007ff\nff58869c1\n \nffffffff8100b2e9\n \n0000000000000f\n96\n \n0000000000000f\n95\n\n\n[\n \n1261.237707\n]\n \nCall\n \nTrace\n:\n\n\n[\n \n1261.266825\n]\n \nTSK\n\n\n[\n \n1261.289704\n]\n \n[\nffffffff8100ec76\n]\n \n__warn\n.\nconstprop\n.0\n+\n0xa6\n/\n0x100\n\n\n[\n \n1261.359381\n]\n \n[\nffffffff8100d410\n]\n \n?\n \npgd_free\n+\n0x90\n/\n0x90\n\n\n[\n \n1261.419699\n]\n \n[\nffffffff8100ed5f\n]\n \nwarn_slowpath_null\n+\n0xf\n/\n0x20\n\n\n[\n \n1261.487295\n]\n \n[\nffffffff8100fe68\n]\n \ngeneric_smp_call_function_single_interrupt\n+\n0xb8\n/\n0x160\n\n\n[\n \n1261.581931\n]\n \n[\nffffffff810020dd\n]\n \ncall_function_interrupt\n+\n0x1d\n/\n0x20\n\n\n[\n \n1261.655767\n]\n \n[\nffffffff8100b2e9\n]\n \nsmp__call_function_interrupt\n+\n0x69\n/\n0x70\n\n\n\n\n\n\n\nSo I decided to look into smp.c a little bit to find out if there is something wrong (I wrote it long time ago). The warning itself is true, it means some inconsistent behavior.. I saw \nalloc_percpu\n stuff during \ncall_function_init\n, hence probably I also need to check percpu code a little code cause I\nm not sure if I port all the functionalities.\n\n\nIn all, today\ns task, check \npercpu\n and \nsmp_call_function\n code. Esp, \npercpu\n code, they are crucial and very hard to relate real bugs to it.\n\n\nWell\n things changed. I found a more serious bug: something about \ncpuhotplug\n, even though lego is not using it. \ncpuhotplug\n is a set of implict callbacks to all different subsystems who want to do some initialization work on each \noffline-\nonline\n cpu.\n\n\nLet us dig into how secondary cpu boots:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\nTrampoline\n..\n \nsetup\n \n64\nbit\n \nmode\n\n\nstart_secondary\n()\n\n  \nsmp_callin\n()\n\n        \nnotify_cpu_starting\n()\n\n              \n...\n\n              \nwhile\n \n(\nst\n-\nstate\n \n \ntarget\n)\n \n{\n\n                      \nst\n-\nstate\n++\n;\n\n                      \ncpuhp_invoke_callback\n(\ncpu\n,\n \nst\n-\nstate\n,\n \ntrue\n,\n \nNULL\n);\n\n              \n}\n\n          \ncpuhp_invoke_callback\n()\n\n\n\n\n\n\nSee? There will be some callbacks! What are those callbacks exactly? Well, they are predefined at the \nkernel/cpu.c\n. To save the trouble of reading code, I just print what functions are executed, the log is:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n[    0.118235] cpuhp_invoke_callback(): 136  CPU:0  page_writeback_cpu_online+0x0/0x20\n\n[    0.368478] cpuhp_invoke_callback(): 136  CPU:1  smpboot_create_threads+0x0/0x90\n[    0.370196] cpuhp_invoke_callback(): 136  CPU:1  perf_event_init_cpu+0x0/0xa0\n[    0.370403] cpuhp_invoke_callback(): 136  CPU:1  workqueue_prepare_cpu+0x0/0x80\n[    0.371112] cpuhp_invoke_callback(): 136  CPU:1  hrtimers_prepare_cpu+0x0/0x60\n[    0.371339] cpuhp_invoke_callback(): 136  CPU:1  smpcfd_prepare_cpu+0x0/0x80\n[    0.371584] cpuhp_invoke_callback(): 136  CPU:1  relay_prepare_cpu+0x0/0xe0\n[    0.371794] cpuhp_invoke_callback(): 136  CPU:1  rcutree_prepare_cpu+0x0/0x170\n[    0.372333] cpuhp_invoke_callback(): 136  CPU:1  notify_prepare+0x0/0xa0\n[    0.372744] cpuhp_invoke_callback(): 136  CPU:1  bringup_cpu+0x0/0x100\n[    0.008000] cpuhp_invoke_callback(): 136  CPU:1  sched_cpu_starting+0x0/0x60\n[    0.926124] cpuhp_invoke_callback(): 136  CPU:1  smpboot_unpark_threads+0x0/0x90\n[    0.926124] cpuhp_invoke_callback(): 136  CPU:1  perf_event_init_cpu+0x0/0xa0\n[    0.927028] cpuhp_invoke_callback(): 136  CPU:1  workqueue_online_cpu+0x0/0x2a0\n[    0.927768] cpuhp_invoke_callback(): 136  CPU:1  rcutree_online_cpu+0x0/0x70\n[    0.928045] cpuhp_invoke_callback(): 136  CPU:1  notify_online+0x0/0x20\n[    0.928256] cpuhp_invoke_callback(): 136  CPU:1  page_writeback_cpu_online+0x0/0x20\n[    0.928527] cpuhp_invoke_callback(): 136  CPU:1  sched_cpu_activate+0x0/0x190\n\n[    0.929084] cpuhp_invoke_callback(): 136  CPU:2  smpboot_create_threads+0x0/0x90\n[    0.930240] cpuhp_invoke_callback(): 136  CPU:2  perf_event_init_cpu+0x0/0xa0\n[    0.930434] cpuhp_invoke_callback(): 136  CPU:2  workqueue_prepare_cpu+0x0/0x80\n[    0.931070] cpuhp_invoke_callback(): 136  CPU:2  hrtimers_prepare_cpu+0x0/0x60\n[    0.931264] cpuhp_invoke_callback(): 136  CPU:2  smpcfd_prepare_cpu+0x0/0x80\n[    0.931464] cpuhp_invoke_callback(): 136  CPU:2  relay_prepare_cpu+0x0/0xe0\n[    0.931649] cpuhp_invoke_callback(): 136  CPU:2  rcutree_prepare_cpu+0x0/0x170\n[    0.932245] cpuhp_invoke_callback(): 136  CPU:2  notify_prepare+0x0/0xa0\n[    0.932475] cpuhp_invoke_callback(): 136  CPU:2  bringup_cpu+0x0/0x100\n[    0.008000] cpuhp_invoke_callback(): 136  CPU:2  sched_cpu_starting+0x0/0x60\n[    1.005023] cpuhp_invoke_callback(): 136  CPU:2  smpboot_unpark_threads+0x0/0x90\n[    1.005065] cpuhp_invoke_callback(): 136  CPU:2  perf_event_init_cpu+0x0/0xa0\n[    1.005408] cpuhp_invoke_callback(): 136  CPU:2  workqueue_online_cpu+0x0/0x2a0\n[    1.005729] cpuhp_invoke_callback(): 136  CPU:2  rcutree_online_cpu+0x0/0x70\n[    1.006029] cpuhp_invoke_callback(): 136  CPU:2  notify_online+0x0/0x20\n[    1.006206] cpuhp_invoke_callback(): 136  CPU:2  page_writeback_cpu_online+0x0/0x20\n[    1.006549] cpuhp_invoke_callback(): 136  CPU:2  sched_cpu_activate+0x0/0x190\n\n\n\n\n\nInteresting! Currently, Lego need to add the \nsmpboot_create_threads()\n, \nworkqueue_prepare_cpu()\n, \nworkqueue_prepare_cpu()\n, \nbringup_cpu()\n, \nsmpboot_unpark_threads()\n, \nworkqueue_online_cpu()\n.\n\n\nThis hidden things is really hard to find and not easy to track during boot. Especially during boot, they should do something like \nfor_each_online_cpu\n and init one by one. But I guess, after adding support of cpu hotplug, code kind of merged. Some stuff will be executed whenever a cpu has been teardown or bought up. And bang, why not use the same set of hotplug during boot, right?\nWell.", 
            "title": "Feb 2018"
        }, 
        {
            "location": "/lego/log/log-02-2018/#feb-2018", 
            "text": "", 
            "title": "Feb 2018"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0228-wed", 
            "text": "patch fork, and cow handler  debug pcache, while running python hello world  add vDSO, gettimeofday   So, it is end of the day. After adding wp handler, I now have the whole picture of pcache activities, and the interactions between them. The reclaim, zap, move, copy, add, operations needs to be carefully synchronized. Also the refcount etc. I feel the ground rule is we need to make sure a PCM that a function is currently using, can not suddenly become invalid due to other operations. This has to be synced by: refcount, lock, flags. Oh well, mm is hard with SMP, but also fun.  We are very close to have a fully working OS.  I did not have time to look into the python hello world bug issue. It is a very serious one. It may also rule out some root bugs.", 
            "title": "02/28 Wed"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0227-tue", 
            "text": "Spent two days on CS527 source project, implemented a small SSHD and SSD client. And we have to inject exactly five bugs, or vulnerabilities into the systems. Lol, it is really hard to intentionally plant BUGs!  Anyway, back to Lego. Since others are having a hard time compile program statically, I will try to add dynamic loader today.  The interpreter:  /lib64/ld-linux-x86-64.so.2 .   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19 Linux seq.c maps (no randomization):\n00400000-00401000 r-xp 00000000 fd:00 18752683                           /root/ys/LegoOS/usr/a.out\n00600000-00601000 r--p 00000000 fd:00 18752683                           /root/ys/LegoOS/usr/a.out\n00601000-00602000 rw-p 00001000 fd:00 18752683                           /root/ys/LegoOS/usr/a.out\n00602000-00604000 rw-p 00000000 00:00 0                                  [heap]\n7ffff7a18000-7ffff7bd0000 r-xp 00000000 fd:00 55051990                   /usr/lib64/libc-2.17.so\n7ffff7bd0000-7ffff7dd0000 ---p 001b8000 fd:00 55051990                   /usr/lib64/libc-2.17.so\n7ffff7dd0000-7ffff7dd4000 r--p 001b8000 fd:00 55051990                   /usr/lib64/libc-2.17.so\n7ffff7dd4000-7ffff7dd6000 rw-p 001bc000 fd:00 55051990                   /usr/lib64/libc-2.17.so\n7ffff7dd6000-7ffff7ddb000 rw-p 00000000 00:00 0 7ffff7ddb000-7ffff7dfc000 r-xp 00000000 fd:00 55051983                   /usr/lib64/ld-2.17.so 7ffff7fde000-7ffff7fe1000 rw-p 00000000 00:00 0\n7ffff7ff9000-7ffff7ffa000 rw-p 00000000 00:00 0\n7ffff7ffa000-7ffff7ffc000 r-xp 00000000 00:00 0                          [vdso] 7ffff7ffc000-7ffff7ffd000 r--p 00021000 fd:00 55051983                   /usr/lib64/ld-2.17.so 7ffff7ffd000-7ffff7ffe000 rw-p 00022000 fd:00 55051983                   /usr/lib64/ld-2.17.so 7ffff7ffe000-7ffff7fff000 rw-p 00000000 00:00 0 7ffffffde000-7ffffffff000 rw-p 00000000 00:00 0                          [stack] ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]    1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27 lego   after   loading  00400000 - 00401000   r - xp   00000000   / root / ys / LegoOS / usr / a . out  00600000 - 00602000   rw - p   00000000   / root / ys / LegoOS / usr / a . out  00602000 - 00604000   rw - p   00000000   [ heap ]  7ff ff7ddb000 - 7ff ff7dfc000   r - xp   00000000   / lib64 / ld - linux - x86 - 64. so .2  7ff ff7ffc000 - 7ff ff7ffe000   rw - p   00021000   / lib64 / ld - linux - x86 - 64. so .2  7ff ff7ffe000 - 7ff ff7fff000   rw - p   00000000  7ff ffffde000 - 7ff ffffff000   rw - p   00000000   [ stack ]  [   2066.379224 ]   ****      Finish   dump   final   mm  [   2066.426023 ]   handle_p2m_execve () :   reply_status :   OKAY ,   new_ip :   0x7ffff7ddc170 ,   new_sp :   0x7fffffffede0  [   2066.628949 ]   handle_p2m_pcache_miss ()   cpu   4   I   nid : 0   pid : 32   tgid : 32   flags : 150   vaddr : 0x7ffff7ddc170  [   2066.732034 ]   handle_p2m_pcache_miss ()   cpu   4   O   nid : 0   pid : 32   tgid : 32   flags : 150   vaddr : 0x7ffff7ddc170  [   2066.934947 ]   handle_p2m_pcache_miss ()   cpu   4   I   nid : 0   pid : 32   tgid : 32   flags : 51   vaddr : 0x7fffffffedd8  [   2067.036978 ]   handle_p2m_pcache_miss ()   cpu   4   O   nid : 0   pid : 32   tgid : 32   flags : 51   vaddr : 0x7fffffffedd8  [   2067.238842 ]   handle_p2m_pcache_miss ()   cpu   4   I   nid : 0   pid : 32   tgid : 32   flags : 50   vaddr : 0x7ffff7ffce00  [   2067.340880 ]   handle_p2m_pcache_miss ()   cpu   4   O   nid : 0   pid : 32   tgid : 32   flags : 50   vaddr : 0x7ffff7ffce00  [   2067.542747 ]   handle_p2m_pcache_miss ()   cpu   4   I   nid : 0   pid : 32   tgid : 32   flags : 51   vaddr : 0x7ffff7ffd9a8  [   2067.644774 ]   handle_p2m_pcache_miss ()   cpu   4   O   nid : 0   pid : 32   tgid : 32   flags : 51   vaddr : 0x7ffff7ffd9a8  [   2067.846640 ]   handle_p2m_pcache_miss ()   cpu   4   I   nid : 0   pid : 32   tgid : 32   flags : 50   vaddr : 0x7ffff7ddb8e0  [   2067.948679 ]   handle_p2m_pcache_miss ()   cpu   4   O   nid : 0   pid : 32   tgid : 32   flags : 50   vaddr : 0x7ffff7ddb8e0  [   2068.355424 ]   ------------ [   cut   here   ] ------------  [   2068.408568 ]   WARNING :   CPU :   4   PID :   31   at   managers / memory / handle_pcache / fault . c : 54   handle_p2m_pcache_miss + 0x29d / 0x380  [   2068.532327 ]   src_nid : 0 , pid : 32 , vaddr : 0x7ffff7e0e000  [   2068.588487 ]   CPU :   4   PID :   31   Comm :   mc - manager   4.0.0 - lego - ys +   # 100  [   2068.659207 ]   Stack :    1\n2\n3\n4 [root@wuklab13: lib64] $ ll ld-*\n-rwxr-xr-x 1 root root 164112 Nov 30 13:53 ld-2.17.so\nlrwxrwxrwx 1 root root     10 Jan  8 12:34 ld-linux-x86-64.so.2 -  ld-2.17.so\n[root@wuklab13: lib64]   It turns out there is a bug in mmap code: forgot to increment the file ref count when a file-backed vma is created. Some put_file in loader accidentally free the ld-linux file. Bug fixed, dyloader works like a charm.", 
            "title": "02/27 Tue"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0224-sat", 
            "text": "Well. PhDs do not have weekends.\nAnyway, it is Saturday after all, relaxed a little bit. I was looking into the pcache issue.\nAlso added our own kernel version strace.", 
            "title": "02/24 Sat"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0223-fri", 
            "text": "", 
            "title": "02/23 Fri"
        }, 
        {
            "location": "/lego/log/log-02-2018/#solved-fpu-bug", 
            "text": "current  is fine. I should not compare the old implementation with the new per-cpu current. I forgot that the kernel stack is switched in the  __switch_to_asm . This means in  __switch_to() , we are actually using the  next_p s kernel stack. So there is small time frame, where  current_thread_info()  points to  next_p , while  current_task  is still  prev_p . Since interrupts are disabled during context switch, we are good with this mismatch.  Rule out current, the only thing left is  fpu__copy  warning, which happens during  copy_process() . One weird thing is this function has been called multiple times before it showed a warning. System itself use this function to create a lot background threads, which are fine. Only when it was triggered by  sys_clone  then we have the warning:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34 [   3213.055639 ]   CPU :   6   PID :   17   sys_clone + 0x0 / 0x30  [   3213.056584 ]   new   task_struct :   ffff88083e4c9838  [   3213.057530 ]   arch_dup_task_struct   cpu6   dst : ffff88083e4c9838   17   word_count - seq   src : ffff88083e457838   17   word_count - seq  [   3213.059536 ]   TRAP   do_general_protection   in   CPU6 ,   error_code :   0   current : ffff88083e457838   17   word_count - seq  [   3213.061289 ]   fixup_exception   pid ( 17 )   cpu ( 6 )   insn : 0xffffffff81009a21 ( fpu__copy + 0x81 / 0x260 )   fixup : 0xffffffff8105d9b2 ( __fixup_text_start + 0xc2 / 0x322 )   handler : ex_handler_default + 0x0 / 0x20  [   3213.064114 ]   ------------ [   cut   here   ] ------------  [   3213.065040 ]   WARNING :   CPU :   6   PID :   17   at   . / arch / x86 / include / asm / fpu / internal . h : 354   fpu__copy + 0xc3 / 0x260  [   3213.066760 ]   CPU :   6   PID :   17   Comm :   word_count - seq   4.0.0 - lego +   # 6  [   3213.067855 ]   Stack :  [   3213.068424 ]   ffff88083e4c7dd0   ffffffff810124b5   ffff88083e4c9bf8   ffff88083e4c9c38  [   3213.070133 ]   ffff88083e4c9838   00007ff ff7ffd700   ffff88083e4c7de0   ffffffff8101258f  [   3213.071775 ]   ffff88083e4c7e08   ffffffff81009a63   ffff88083e457838   ffff88083e4c9838  [   3213.073419 ]   ffff88083e457838   ffff88083e4c7e40   ffffffff81000ebb   ffff88083e457838  [   3213.075057 ]   ffff880800000011   ffff88083e457a68   00000000003 d0f00   ffff88083e457838  [   3213.076703 ]   Call   Trace :  [   3213.077295 ]   TSK  [   3213.077828 ]   [ ffffffff810124c1 ]   __warn . constprop .0 + 0x91 / 0xd0  [   3213.078855 ]   [ ffffffff8101258f ]   warn_slowpath_null + 0xf / 0x20  [   3213.081653 ]   [ ffffffff81009a63 ]   fpu__copy + 0xc3 / 0x260  [   3213.082543 ]   [ ffffffff81000ebb ]   arch_dup_task_struct + 0x7b / 0x90  [   3213.083667 ]   [ ffffffff8101d32e ]   copy_process + 0x14e / 0x10e0  [   3213.084618 ]   [ ffffffff8103a3c6 ]   ?   n_tty_write + 0x166 / 0x3c0  [   3213.085564 ]   [ ffffffff8101e2e6 ]   do_fork + 0x26 / 0x140  [   3213.086439 ]   [ ffffffff8101e4a0 ]   ?   sys_vfork + 0x40 / 0x40  [   3213.087333 ]   [ ffffffff8101e4a0 ]   ?   sys_vfork + 0x40 / 0x40  [   3213.088232 ]   [ ffffffff8101e4c9 ]   sys_clone + 0x29 / 0x30  [   3213.089109 ]   [ ffffffff8100e719 ]   do_syscall_64 + 0x69 / 0xf0  [   3213.090030 ]   [ ffffffff8100d5ec ]   entry_SYSCALL64_slow_path + 0x25 / 0x25  [   3213.091078 ]   EOT  [   3213.091580 ]   --- [   end   trace   0000000000000000   ] ---  [   3213.093250 ]   TRAP   do_general_protection   in   CPU7 ,   error_code :   0   current : ffff88083fd0f008   0   swapper / 7  [   3213.096526 ]   fixup_exception   pid ( 0 )   cpu ( 7 )   insn : 0xffffffff81000c62 ( __switch_to + 0x452 / 0x630 )   fixup : 0xffffffff8105d922 ( __fixup_text_start + 0x32 / 0x322 )   handler : ex_handler_default + 0x0 / 0x20  [   3213.101241 ]   ------------ [   cut   here   ] ------------  [   3213.103285 ]   WARNING :   CPU :   7   PID :   0   at   . / arch / x86 / include / asm / fpu / internal . h : 369   __switch_to + 0x47e / 0x630    So, dig into  fpu__copy() , find out why it fails at this certain point. Glad I have something to dig into.   The instruction leads to GP is: 1 ffffffff8100b0f5 :         48   0f   ae   27               xsave64   ( % rdi )    which is generated by:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29 #define XSTATE_XSAVE(st, lmask, hmask, err)                             \\          asm volatile(ALTERNATIVE_2(XSAVE,                               \\                                     XSAVEOPT, X86_FEATURE_XSAVEOPT,      \\                                     XSAVES,   X86_FEATURE_XSAVES)        \\                        \\n                                                \\                        xor %[err], %[err]\\n                              \\                        3:\\n                                              \\                        .pushsection .fixup,\\ ax\\ \\n                      \\                        4: movl $-2, %[err]\\n                             \\                        jmp 3b\\n                                          \\                        .popsection\\n                                     \\                       _ASM_EXTABLE(661b, 4b)                             \\                       : [err]  =r  (err)                                 \\                       :  D  (st),  m  (*st),  a  (lmask),  d  (hmask)    \\                       :  memory )  static   inline   void   copy_xregs_to_kernel ( struct   xregs_state   * xstate )  { \n         u64   mask   =   - 1 ; \n         u32   lmask   =   mask ; \n         u32   hmask   =   mask     32 ; \n         int   err ; \n\n         WARN_ON ( ! alternatives_patched ); \n\n         XSTATE_XSAVE ( xstate ,   lmask ,   hmask ,   err ); \n\n         /* We should never fault when copying to a kernel buffer: */ \n         WARN_ON_FPU ( err );  }    From SDM on  XSAVE :  Use of a destination operand not aligned to 64-byte boundary (in either 64-bit or 32-bit modes) results in a general-protection (#GP) exception. In 64-bit mode, the upper 32 bits of RDX and RAX are ignored.  %rdi  is  struct xregs_state *xstate  in above code. Thus, check if  xstate  if 64-bytes aligned. Of course, it is not: 1 [10894.999997] copy_xregs_to_kernel CPU6 xstate: ffff88083e4c8c38   Hehe. Criminal identified. But why? The xstate structure is already marked as  __attribute__(aliged 64)  in the code.  It is the task_struct , which is  NOT  0x40 aligned. But god why? Because we currently use  kmalloc  to allocate new task_struct, whose minimum alignment is  8 bytes . Anyway, use  __alloc_pages  instead.  Such an deeply hidden bug. Took me almost a month to find out.", 
            "title": "Solved FPU BUG"
        }, 
        {
            "location": "/lego/log/log-02-2018/#ib", 
            "text": "Seen this during boot (at both P and M, although lego continue running correctly):  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 [ 54017.712533 ]   ***      NodeID      Hostname      LID      QPN  [ 54017.770776 ]   ***      -------------------------------------  [ 54017.834220 ]   ***           0      wuklab12       13       72  [ 54017.892462 ]   ***           1      wuklab14       16       72   ---  [ 54017.955906 ]   ***           2      wuklab16       20       74  [ 54018.014149 ]   ***  [ 54074.552844 ]   ***    Start   establish   connection   ( mynodeid :   1 )  [ 54102.554407 ]   ib_process_mad   mad_ifc   fails  [ 54130.960691 ]   ***    recvpollcq   runs   on   CPU2  [ 54131.070918 ]   ***    Successfully   built   QP   for   node    0   [ LID :   13   QPN :   72 ]  [ 54131.152936 ]   ***    Successfully   built   QP   for   node    2   [ LID :   20   QPN :   74 ]  [ 54161.228245 ]   ***    FIT   layer   ready   to   go !  [ 54161.272034 ]   ***   \nAnother one:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27 [   1966.930409 ]   ***  [   1966.951210 ]   ***    FIT_initial_timeout_s :     30  [   1967.002168 ]   ***    FIT_local_id :              0  [   1967.052087 ]   ***  [   1967.072887 ]   ***      NodeID      Hostname      LID      QPN  [   1967.131126 ]   ***      -------------------------------------  [   1967.194567 ]   ***           0      wuklab12       13       72   ---  [   1967.258005 ]   ***           1      wuklab14       16       72  [   1967.316244 ]   ***           2      wuklab16       20       74  [   1967.374484 ]   ***  [   2032.926448 ]   ***    Start   establish   connection   ( mynodeid :   0 )  [   2032.996068 ]   Fail   to   modify   qp [ 6 ]  [   2033.032572 ]   Fail   to   do   client_init_ctx  [   2033.077287 ]   client_establish_conn :   ctx             ( null )   fail   to   init_interface  [   2033.164646 ]   ibapi_establish_conn :   ctx             ( null )   fail   to   init_interface  [   2033.250967 ]   ***  [   2035.620167 ]   BUG :   unable   to   handle   kernel   NULL   pointer   dereference   at   0000000000000004  [   2035.713763 ]   IP :   [ ffffffff8105c589 ]   client_send_reply_with_rdma_write_with_imm + 0x69 / 0x3b0  [   2035.812562 ]   PGD   0  [   2035.836482 ]   Oops :   0002   [ # 1 ]   SMP   PROCESSOR  [   2035.884321 ]   CPU :   0   PID :   1   Comm :   kernel_init   4.0.0 - lego - ys +   # 253  [   2035.955041 ]   RIP :   0010 : [ ffffffff8105c589 ]    [ ffffffff8105c589 ]   client_send_reply_with_rdma_write_with_imm + 0x69 / 0x3b0  ...  [   2037.313267 ]   TSK  [   2037.336146 ]   [ ffffffff8105a377 ]   ibapi_send_reply_timeout + 0x57 / 0x70  [   2037.411025 ]   [ ffffffff81033d24 ]   ?   net_send_reply_timeout + 0x94 / 0x132  [   2037.486944 ]   [ ffffffff81033d24 ]   net_send_reply_timeout + 0x94 / 0x132", 
            "title": "IB"
        }, 
        {
            "location": "/lego/log/log-02-2018/#pcache", 
            "text": "Running word_count-pthread, with 100MB dataset, finally got some reasonable bug:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29 [ 54211.243181 ]   pcache_evict_line () :   pset :   ffff88207f86e3c0 ,   for   uva :   0x7ffff1b8f000  [ 54211.385654 ]   pcache : ffff88207f86e3a8   mapcount : 8   refcount : 0   flags :()  [ 54211.510447 ]   pcache   dumped   because :   PCACHE_BUG_ON_PCM ( ! PcacheLocked ( pcm ))  [ 54212.080336 ]   BUG :   failure   at   managers / processor / pcache / evict . c : 240 / pcache_evict_line () !  [ 54212.664785 ]   Kernel   Panic   -   not   syncing :   BUG !  [ 54212.715742 ]   CPU :   8   PID :   81   Comm :   word_count - pthr   4.0.0 - lego - ys +   # 252  ...  [ 54213.391706 ]   TSK  [ 54213.414584 ]   [ ffffffff81024180 ]   panic + 0xc2 / 0xeb  [ 54213.524818 ]   [ ffffffff8101b81c ]   ?   task_tick_rt + 0x2c / 0xd0  [ 54213.589295 ]   [ ffffffff81018f75 ]   ?   scheduler_tick + 0x55 / 0x60  [ 54213.655850 ]   [ ffffffff81016625 ]   ?   tick_handle_periodic + 0x45 / 0x70  [ 54213.728647 ]   [ ffffffff81006634 ]   ?   apic_timer_interrupt + 0x54 / 0x90  [ 54213.801443 ]   [ ffffffff8100e22a ]   ?   smp__apic_timer_interrupt + 0x6a / 0x70  [ 54213.879439 ]   [ ffffffff8101256d ]   ?   printk + 0x11d / 0x1b0  [ 54214.103027 ]   [ ffffffff8102ecf4 ]   pcache_evict_line + 0x134 / 0x220  [ 54214.172703 ]   [ ffffffff8102c6ae ]   pcache_alloc + 0x22e / 0x2e0  [ 54214.237179 ]   [ ffffffff8102be0a ]   common_do_fill_page + 0x2a / 0x1f0  [ 54214.307895 ]   [ ffffffff8102baf0 ]   ?   move_page_tables + 0x4c0 / 0x4c0  [ 54214.378612 ]   [ ffffffff8102c172 ]   pcache_handle_fault + 0x1a2 / 0x3a0  [ 54214.450367 ]   [ ffffffff8100fc02 ]   do_page_fault + 0xa2 / 0x1a0  [ 54214.514843 ]   [ ffffffff8100d85f ]   page_fault + 0x1f / 0x30  [ 54214.575161 ]   [ ffffffff81034842 ]   ?   copy_user_enhanced_fast_string + 0x2 / 0x10  [ 54214.657316 ]   [ ffffffff81032368 ]   ?   seq_read + 0x248 / 0x360  [ 54214.719714 ]   [ ffffffff810307af ]   sys_read + 0x3f / 0xc0  [ 54214.777949 ]   [ ffffffff81030770 ]   ?   sweep_pset_lru + 0x220 / 0x220  [ 54214.846587 ]   [ ffffffff8100e619 ]   do_syscall_64 + 0x69 / 0xf0  [ 54214.910022 ]   [ ffffffff8100d4ec ]   entry_SYSCALL64_slow_path + 0x25 / 0x25  [ 54214.985939 ]   EOT    Another one: 1\n2\n3 [    735.393244 ]   pcache_evict_line () :   pset :   ffff88207f86e3c0 ,   for   uva :   0x7ffff1b8fd90  [    735.537804 ]   pcache : ffff88207f86e3a8   mapcount : 8   refcount : 0   flags :()  [    735.663642 ]   pcache   dumped   because :   PCACHE_BUG_ON_PCM ( ! PcacheLocked ( pcm ))    Do note this happens after computation. This happens when phoenix create a lot threads to sort the results.  Both bug happen to the same set, same user page. The pcache is clearly corrupted:  mapcount : 8 ,   refcount : 0 ,   flags :().  Come back after dinner.\nRemember to check altenative, cause the XSAVE above should be XSAVEOPT. Make sure it does not override other memory. Also, check linker script. Do not forget to link any sections.  Another several bug logs in wuklab13 and wuklab15:  022318-* . I m really tired today after fixing the FPU bug. But I m also pretty confident pcache is something I m able to debug. Even thought it is hard in SMP case.  Anyway, I gonna call for the day.", 
            "title": "pcache"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0222-thur", 
            "text": "context switch fpu  signal compat check, all good.   make  current  use percpu current_task, so all code in Lego is consistent.  checked  entry_SYSCALL-64  again, which looks good to me.  The only concern is  rsp_scratch  and  current_top_of_stack , which are per-cpu variables. If these per-cpu is setup wrong, then we are doomed.  Also check if per-cpu is all cleared up?  try big syscall lock  does x86 has to use different kernel stacks? Interrupt is using different stack in Linux, has to do so???  check current is correct. compare with old implementation.   First of all, FPU is definitely functional for now.\nSince I replaced the current macro today, I add some code to check if this current matches our old implementation:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20 static __always_inline struct task_struct *get_current(void)                                                           \n{                                                                                                                      \n        return this_cpu_read_stable(current_task);                                                                     \n}\n\n//#define current get_current()\n\n#define current                                                 \\\n({                                                              \\\n        struct task_struct *old = current_thread_info()- task;  \\\n        struct task_struct *new = get_current();                \\\n                                                                \\\n        if (old != new) {                                       \\\n                printk( %s:%d() cpu:%d old:%pS %d %s new:%pS %d %s\\n ,  \\\n                        __func__, __LINE__, smp_processor_id(), old, old- pid, old- comm, \\\n                        new, new- pid, new- comm);              \\\n                BUG();                                          \\\n        }                                                       \\\n        get_current();                                          \\\n})   Combined with some FPU warning, it is now like this:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35 [   3273.748819 ]   CPU : 5   PID : 32     sys_clone + 0x0 / 0x30  [   3273.800808 ]   alloc_task_struct_node :   size : 740   ffff88107e831838  [   3273.869451 ]   arch_dup_task_struct ()   CPU5   current : 32   new :   ffff88107e831838   old :   ffff88107e827838   32  [   3273.975533 ]   ------------ [   cut   here   ] ------------  [   3274.030651 ]   WARNING :   CPU :   5   PID :   32   at   . / arch / x86 / include / asm / fpu / internal . h : 354   fpu__copy + 0xe2 / 0x310  [   3274.140895 ]   CPU :   5   PID :   32   Comm :   word_count - pthr   4.0.0 - lego - ys - gdbe6dbe - dirty   # 249  [   3274.231377 ]   Stack :  [   3274.255298 ]   ffff88107e82fd68   ffffffff81016dbf   00000000ff ffffff   0000000000000000  [   3274.342659 ]   00000000ff ffffff   0000000000000000   ffff88107e831bf8   ffff88107e831c38  [   3274.430021 ]   ffff88107e831838   000000207f e64000   ffff88107e82fd78   ffffffff810170af  [   3274.517382 ]   ffff88107e82fdc0   ffffffff8100b052   0000000000000020   ffff88107e831838  [   3274.604745 ]   ffff88107e827838   ffff88107e827838   ffff88107e831838   ffff88107e827838  [   3274.692106 ]   Call   Trace :  [   3274.721229 ]   TSK  [   3274.744109 ]   [ ffffffff81016dd8 ]   __warn . constprop .0 + 0xe8 / 0x3b0  [   3274.813790 ]   [ ffffffff810170af ]   warn_slowpath_null + 0xf / 0x20  [   3274.881391 ]   [ ffffffff8100b052 ]   fpu__copy + 0xe2 / 0x310  [   3274.941713 ]   [ ffffffff810012e4 ]   arch_dup_task_struct + 0x84 / 0x120  [   3275.013475 ]   [ ffffffff81022c10 ]   copy_process + 0x160 / 0x1e60  [   3275.078996 ]   [ ffffffff81024936 ]   do_fork + 0x26 / 0x140  [   3275.137238 ]   [ ffffffff81024af0 ]   ?   sys_vfork + 0x40 / 0x40  [   3275.198599 ]   [ ffffffff81024af0 ]   ?   sys_vfork + 0x40 / 0x40  [   3275.259960 ]   [ ffffffff81024b19 ]   sys_clone + 0x29 / 0x30  [   3275.319242 ]   [ ffffffff81012314 ]   do_syscall_64 + 0x84 / 0x240  [   3275.383723 ]   [ ffffffff8101106c ]   entry_SYSCALL64_slow_path + 0x25 / 0x25  [   3275.459645 ]   EOT  [   3275.482526 ]   --- [   end   trace   0000000000000000   ] ---  [   3275.537648 ]   wake_up_new_task   CPU5   task : ffff88107e831838 ,   dest_cpu : 6   current : 32  [   3275.623970 ]   SMP   IPI :   reschedule_interrupt ()   CPU ( 6 )   PID ( 0 )  [   3275.739412 ]   do_general_protection : 186 ()   cpu : 6   old : 0xffff88107e831838   33   word_count - pthr   new : 0xffff88107fcaf008   0   swapper / 6   [   3275.871493 ]   ------------ [   cut   here   ] ------------  [   3275.926614 ]   BUG :   failure   at   arch / x86 / kernel / traps . c : 186 / do_general_protection () !  [   3276.015018 ]   Kernel   Panic   -   not   syncing :   BUG !  [   3276.065978 ]   panic : 107 ()   cpu : 6   old : 0xffff88107e831838   33   word_count - pthr   new : 0xffff88107fcaf008   0   swapper / 6    Based on the switch code: 1\n2\n3\n4\n5\n6\n7 __switch_to ( struct   task_struct   * prev_p ,   struct   task_struct   * next_p )  { \n         this_cpu_write ( current_task ,   next_p ); \n\n         /* Reload sp0 This changes current_thread_info(). */ \n         load_sp0 ( tss ,   next );  }    Based on log line 30,  load_sp0()  already happened, which means  this_cpu_write(..)  happened too. If  this_cpu_write(..)  happened, then log line 30 s new should have been updated to  0xffff88107e831838 . Something wrong with percpu?", 
            "title": "02/22 Thur"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0221-wed", 
            "text": "irq_regs, old code, check  signal frame, and fpu hook together Done  in_interrupt() , it is empty, TODO  check arch/x86/Makefile, it introduce a lot FPU flags.  added more than 4K lines today. Damn FPU. Ugh go home sleep.", 
            "title": "02/21 Wed"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0220-tue-cloudy", 
            "text": "Not too many Sunny days recently. Well, continue yesterday s work. I don t think I can easily find out why so many  /proc/memoinfo  open happened. Instead, I m trying to enable the  flush_thread  in P s exec code.  During the way, I found some issue related to  __ARCH_HAS_SA_RESTORER  in signal code. I need to check if these x86 macros are defined, but lego does not port them.  Well, it turns out flush_thread does not make too much difference. Next I m going to try to disable  exit_thread , which uses  fpu__drop() .  Hmm, disable  exit_thread  also does not work.", 
            "title": "02/20 Tue Cloudy"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0219-mon-rainy", 
            "text": "It is another week. I can not deny I m a little tired about the bug. Tried so many possible solutions, but none of them work. Well, today I first need to test the vma changes (pgoff and anon_vma) thing. Especially the vma merge and split.  This morning I fixed a bug in kernel_init process: make kernel_init able to run all possible CPUs. Because the first user process is forked from kernel_init, it is quite important that it gets the right cpu affinity: 1\n2\n3\n4\n5\n6 static   int   kernel_init ( void   * unused )  { \n         ... \n         set_cpus_allowed_ptr ( current ,   cpu_possible_mask ); \n         ...  }    Well, interestingly, the unmodified word_count-pthread succeed with 50MB dataset  with or without any DEBUG option! Amazing! I need to find out why the cpus_allowed becomes 0 at the beginning of kernel_init. Because  init_task  actually has: 1\n2      . cpus_allowed     =   CPU_MASK_ALL , \n     . nr_cpus_allowed =   NR_CPUS ,    Things to do next:   check why the cpus_allowed changed  check why word_count-pthread open  /dev/../cpu  so many times. Anything wrong with our  copy_files , or open, close?  here is an idea, to verify if FPU code is correct, run some scientific benchmarks.   Okay, findings:    cpus_allowd is fine, it is reset inside  sched_init() , when it tries make the  init_task  as the  idle  thread. Thus it is reasonable to set cpus_allowed again at  kernel_init  thread. And it should NOTHING to do with the bug.    about the second, check the following log:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88 [ 11838.364543 ]   STDOUT :   --- [  Wordcount :   Running ...  ] ---  [ 11838.422886 ]   STDOUT :   --- [  ] ---  [ 11838.463445 ]   SYSC_open ( cpu5   pid : 32 ) :   f_name :   / root / ys / phoenix / phoenix - 2.0 / tests / word_count / word_count_datafiles / word_50MB . txt ,   flags :   0 ,   mode :   900  [ 11838.619460 ]   SYSC_open ( cpu5   pid : 32 ) :   fd :   3  [ 11838.667406 ]   SYSC_open ( cpu5   pid : 32 ) :   f_name :   / sys / devices / system / cpu / online ,   flags :   80000 ,   mode :   0  [ 11838.773351 ]   SYSC_open ( cpu5   pid : 32 ) :   fd :   4  [ 11838.821239 ]   seq_file : \n   dest_uva :   00007ff fffffc8d0 ,   nr_chars :   5 \n   string :   [ 0 - 23  ]  [ 11838.913791 ]   SYSC_close ( cpu5   pid : 32 ) :   fd :   4  [ 11838.962622 ]   SYSC_close () :   [ 4 ]   -   [ / sys / devices / system / cpu / online ]  [ 11840.223255 ]   STDOUT :   --- [  Word   Count :   Computation   Completed   1.555581   sec  ] ---  [ 11840.309678 ]   SYSC_open ( cpu5   pid : 32 ) :   f_name :   / sys / devices / system / cpu / online ,   flags :   80000 ,   mode :   0  [ 11840.415754 ]   SYSC_open ( cpu5   pid : 32 ) :   fd :   4  [ 11840.463593 ]   seq_file : \n   dest_uva :   00007ff fffffc8a0 ,   nr_chars :   5 \n   string :   [ 0 - 23  ]  [ 11840.556147 ]   SYSC_close ( cpu5   pid : 32 ) :   fd :   4  [ 11840.605024 ]   SYSC_close () :   [ 4 ]   -   [ / sys / devices / system / cpu / online ]  [ 11840.677821 ]   STDOUT :   --- [  THe   number   of   processors   is   24  \u00f4  ] ---  [ 11840.753769 ]   SYSC_open ( cpu7   pid : 80 ) :   f_name :   / proc / meminfo ,   flags :   80000 ,   mode :   1 b6  [ 11840.844212 ]   SYSC_open ( cpu19   pid : 92 ) :   f_name :   / proc / meminfo ,   flags :   80000 ,   mode :   1 b6  [ 11840.935728 ]   SYSC_open ( cpu7   pid : 80 ) :   fd :   4  [ 11840.983567 ]   SYSC_open ( cpu19   pid : 92 ) :   fd :   5  [ 11841.032444 ]   seq_file : \n   dest_uva :   00007ff ff444c000 ,   nr_chars :   172 \n   string :   [ MemTotal :         115355128   kB  MemFree :          115355128   kB  MemAvailable :     115355128   kB  DirectMap4k :          5812   kB  DirectMap2M :       1861632   kB  DirectMap1G :      134217728   kB  ]  [ 11841.305953 ]   seq_file : \n   dest_uva :   00007ff ff444b000 ,   nr_chars :   172 \n   string :   [ MemTotal :         115355128   kB  MemFree :          115355128   kB  MemAvailable :     115355128   kB  DirectMap4k :          5812   kB  DirectMap2M :       1861632   kB  DirectMap1G :      134217728   kB  ]  [ 11841.579460 ]   SYSC_close ( cpu7   pid : 80 ) :   fd :   4  [ 11841.628339 ]   SYSC_close ( cpu19   pid : 92 ) :   fd :   5  [ 11841.678257 ]   SYSC_close () :   [ 4 ]   -   [ / proc / meminfo ]  [ 11841.733375 ]   SYSC_close () :   [ 5 ]   -   [ / proc / meminfo ]  [ 11841.788493 ]   SYSC_open ( cpu18   pid : 91 ) :   f_name :   / proc / meminfo ,   flags :   80000 ,   mode :   1 b6  [ 11841.880008 ]   SYSC_open ( cpu6   pid : 102 ) :   f_name :   / proc / meminfo ,   flags :   80000 ,   mode :   1 b6  [ 11841.971523 ]   SYSC_open ( cpu12   pid : 85 ) :   f_name :   / proc / meminfo ,   flags :   80000 ,   mode :   1 b6  [ 11842.063040 ]   SYSC_open ( cpu0   pid : 97 ) :   f_name :   / proc / meminfo ,   flags :   80000 ,   mode :   1 b6  [ 11842.153516 ]   SYSC_open ( cpu14   pid : 87 ) :   f_name :   / proc / meminfo ,   flags :   80000 ,   mode :   1 b6  [ 11842.245032 ]   SYSC_open ( cpu16   pid : 89 ) :   f_name :   / proc / meminfo ,   flags :   80000 ,   mode :   1 b6  [ 11842.336548 ]   SYSC_open ( cpu4   pid : 100 ) :   f_name :   / proc / meminfo ,   flags :   80000 ,   mode :   1 b6  [ 11842.428064 ]   SYSC_open ( cpu16   pid : 89 ) :   fd :   9  [ 11842.476942 ]   SYSC_open ( cpu4   pid : 100 ) :   fd :   10  [ 11842.526860 ]   seq_file : \n   dest_uva :   00007ff ff444c000 ,   nr_chars :   172 \n   string :   [ MemTotal :         115355128   kB  MemFree :          115355128   kB  MemAvailable :     115355128   kB  DirectMap4k :          5812   kB  DirectMap2M :       1861632   kB  DirectMap1G :      134217728   kB  ]  [ 11842.800368 ]   seq_file : \n   dest_uva :   00007ff ff444b000 ,   nr_chars :   172 \n   string :   [ MemTotal :         115355128   kB  MemFree :          115355128   kB  MemAvailable :     115355128   kB  DirectMap4k :          5812   kB  DirectMap2M :       1861632   kB  DirectMap1G :      134217728   kB  ]  [ 11843.073877 ]   SYSC_close ( cpu16   pid : 89 ) :   fd :   9      However, in a normal Linux exeution:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15 strace   - C   - o   strace_2   . / word_count - pthread   . / word_count_datafiles / word_50MB . txt  %   time       seconds    usecs / call       calls      errors   syscall  ------   -----------   -----------   ---------   ---------   ---------------- \n  86.41      0.052074          1736          30             futex \n   6.89      0.004151            67          62             munmap \n   2.47      0.001490            17          88             mmap \n   2.12      0.001278            14          93             clone \n   1.51      0.000912            14          64             mprotect \n   0.19      0.000117             7          16             write     0.15      0.000092            46           2             open   $   cat   strace_2   |   grep   open     open ( ./word_count_datafiles/word_50MB.txt ,   O_RDONLY )   =   3     open ( /sys/devices/system/cpu/online ,   O_RDONLY | O_CLOEXEC )   =   4      It opened the  /proc/meminfo  for way too many times. In the normal Linux execution, this should not happen. Is it because our meminfo is faked, so glibs is complaining? But why it does not open meminfo while running in Linux? Or does our entry assembly messed up some stuff in stack, so the return path changed?    oh, about the FPU. It reminds our  flush_thread  function actually has an issue before. When I enabled this function during loading in P, the P will crash. Within  flush_thread , there is a  fpu_clear !!! So, check this tomorrow! (12:00am, need to go home)", 
            "title": "02/19 Mon Rainy"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0218-sun-sunny", 
            "text": "It is a nice day. Yesterday I ve changed one line of code in mmap code path: change anonymous vma s pgoff from some value to 0. The result is I got several succeed work-count-pthread(bind to one core) testing. However, it still fail with unmodified word-count-pthread.  It brings me to inspect pgoff manipulation code and all mmap.c code. We ported everything from linux without almost zero modification. That means we ported all those useless  anon_vma  and pgoff code, which is used a lot by vma_merge, vma_split code. The thing is: our memory manager, our vma code do not need such  anon_vma  structure, and do not maintain pgoff. Thus, I m a little bit worried linux code may doing some crazy behind our back: mess vma and pages, then pcache miss gets some wrong pages  Well. Lego does not use  anon_vma , and pgoff should only be used by file-backed vma. So, I decided to remove  anon_vma  from our code, and make sure pgoff is used properly. Of course, the goal is to make vma_merge, split,\ncopy, do the things we intended.  Lesson learned.", 
            "title": "02/18 Sun Sunny"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0217-sat-snowy", 
            "text": "Fixed the bss bug. It comes from loader. We did not implement the  lego_clear_user  function, so some part of bss is non-zero.  Bad news is word_count-pthread still fail at same fpu instruction. Have to look into memory code more.  This is actually a fun debugging story. We should always add TODO or XXX or some warnings to unfinished code, no matter what. Lesson learned.", 
            "title": "02/17 Sat Snowy"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0216-fri-cloudy", 
            "text": "Yilun found a major loader bug yesterday: the  .bss  section variables are not 0, in the  iozone  benchmark. I did not encounter this issue before with simple test program. This is pretty serious.", 
            "title": "02/16 Fri Cloudy"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0215-thur-rainy", 
            "text": "Today is Chinese New Year.  Line 7 and 8 show the uva belong to the same page. Need to revisit  get_arg_pages  etc functions.  1\n2\n3\n4\n5\n6\n7\n8 [  108.393991] handle_p2m_execve(): pid:22,argc:2,envc:2,file:/root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread\n[  108.395255]     argc[0] (len: 65):  /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread\n[  108.396329]     argc[1] (len: 82):  /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_100MB.txt\n[  108.397530]     envc[0] (len:  7):  HOME=/\n[  108.398069]     envc[1] (len: 11):  TERM=linux\n[  108.398640] __bprm_mm_init vma: ffff88083effe6b8 [  108.399226] faultin_page vma: ffff88083effe6b8 uva: 0x7fffffffefed [  108.399949] faultin_page vma: ffff88083effe6b8 uva: 0x7fffffffef94   Well, this is 100% fine. I wrote this loader code long time ago and need some time to pickup. So, after I read the loader code, especially the  copy_strings  function, I found this is okay. Because copy_strings will be invoked three times, so the  faultin_page  basically will be invoked at least three times. That is why it went to that pte fault handling code.  Although actually I think  copy_strings  should  not  use  faultin_page , instead, it should use  get_user_pages , which will walk through the pgtable first, then went to  handle_lego_mm_fault .", 
            "title": "02/15 Thur Rainy"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0214-wed-rainy", 
            "text": "Hmm, tried to make kmalloc behave as kzalloc, and bind all threads to one core, still gave the same old bug:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14   42731a:       f3 0f 6f 16             movdqu (%rsi),%xmm2 \n  [93182.657376] word_count-pthr[85] general protection ip:42731a sp:7fffe3ffed28 error:0\n  [93182.747959] CPU: 8 PID: 85 Comm: word_count-pthr 4.0.0-lego+ #170\n  [93182.820758] RIP: 0033:[ 000000000042731a ]  [ 000000000042731a ] 0x42731a\n  [93182.901878] RSP: 002b:00007fffe3ffed28  EFLAGS: 00010283\n  [93182.965317] RAX: 000000000000001f RBX: 00007ffff001b010 RCX: 0000000000000005\n  [93183.050596] RDX: 0000000000000000 RSI: 5345485355420045 RDI: 00007ffff294791f\n  [93183.135876] RBP: 00007ffff294791f R08: 000000000000ffff R09: 0000000000000008\n  [93183.221156] R10: fffffffffffff048 R11: 00000000004acfc0 R12: 0000000000001cde\n  [93183.306435] R13: 00000000006e4a8c R14: 0000000000001cd7 R15: 0000000000001cda\n  [93183.391716] FS:  00007fffe3fff700(0000) GS:ffff88107fc80000(0000) knlGS:0000000000000000\n  [93183.488434] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n  [93183.557075] CR2: 00007ffff27a4000 CR3: 000000107e924000 CR4: 00000000000406a0    1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14   427377:       66 0f 6f 17             movdqa (%rdi),%xmm2 \n  [93180.527248] word_count-pthr[93]: segfault at 0x0 ip 0000000000427377 sp 00007fffdfff6d28 error 4\n  [93180.630314] CPU: 8 PID: 93 Comm: word_count-pthr 4.0.0-lego+ #170\n  [93180.703114] RIP: 0033:[ 0000000000427377 ]  [ 0000000000427377 ] 0x427377\n  [93180.784234] RSP: 002b:00007fffdfff6d28  EFLAGS: 00010297\n  [93180.847674] RAX: 0000000000000000 RBX: 000000000073c4c0 RCX: 000000000000000d\n  [93180.932953] RDX: 000000000000ffff RSI: 00007ffff4999070 RDI: 0000000000000000\n  [93181.018233] RBP: 00007ffff499907d R08: 000000000000ffff R09: 0000000000000000\n  [93181.103513] R10: 0000000000427760 R11: 00007ffff49982c0 R12: 0000000000000118\n  [93181.188791] R13: 00000000006e4aac R14: 0000000000000116 R15: 0000000000000117\n  [93181.274072] FS:  00007fffdfff7700(0000) GS:ffff88107fc80000(0000) knlGS:0000000000000000\n  [93181.370790] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n  [93181.439430] CR2: 0000000000000000 CR3: 000000107e924000 CR4: 00000000000406a0   Tried several ways to ensure memory safety. It still failed even if I enabled all of them. So, I guess the memory safety is ensured? Still some other things?   force  alloc_pages  to use  __GFP_ZERO  make  kmalloc  behave as  kzalloc  make  kfree  empty   I also suspect  munmap  may free extra wrong pgtable entries. Although I ve went through all the code and checked, but in addition to the above things, I m going to:   make munmap dummy (no p2m_munmap, return 0 directly)   Failed.  Next, I m going to:   add checksum for every page transferred across network.  add warning for unnormal cases   Bang! I found something while running P+M:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31 [    115.727597 ]   Memory - component   manager   is   up   and   running .  [    116.691723 ]   handle_p2m_fork () :   nid : 0 , pid : 22 , tgid : 22 , parent_tgid : 1  [    116.697038 ]   handle_p2m_fork () :   reply :   0 : OKAY  [    116.791088 ]   handle_p2m_execve () :   pid : 22 , argc : 2 , envc : 2 , file : / root / ys / phoenix / phoenix - 2.0 / tests / word_count / word_count - pthread  [    116.792357 ]       argc [ 0 ]   ( len :   65 ) :    / root / ys / phoenix / phoenix - 2.0 / tests / word_count / word_count - pthread  [    116.793439 ]       argc [ 1 ]   ( len :   82 ) :    / root / ys / phoenix / phoenix - 2.0 / tests / word_count / word_count_datafiles / word_100MB . txt  [    116.794653 ]       envc [ 0 ]   ( len :    7 ) :    HOME =/  [    116.795196 ]       envc [ 1 ]   ( len :   11 ) :    TERM = linux  [    116.795772 ]   __bprm_mm_init   vma :   ffff88083effe6b8  [    116.796209 ]   faultin_page   vma :   ffff88083effe6b8  [    116.796729 ]   faultin_page   vma :   ffff88083effe6b8  [    116.797150 ]   handle_pte_fault   vma :   ffff88083effe6b8   entry :   0xffff88083e8c1067  [    116.798044 ]   pte : ffff88083e8c0ff0   pfn : 0x8083e8c1   flags :( present | writable | user | accessed | dirty | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 )  [    116.799462 ]   ------------ [   cut   here   ] ------------  [    116.800049 ]   WARNING :   CPU :   4   PID :   15   at   managers / memory / vm / fault . c : 148   handle_lego_mm_fault + 0x4d8 / 0x550  [    116.801148 ]   CPU :   4   PID :   15   Comm :   mc - manager   4.0.0 - lego +   # 78  [    116.801818 ]   Stack :  [    116.802179 ]   ffff88083e893c50   ffffffff8100e827   00007ff fffffef94   ffff88083effe6b8  [    116.803283 ]   ffff88083e894008   ffff88083e8c1067   ffff88083e893c60   ffffffff8100e91f  [    116.804387 ]   ffff88083e893cf0   ffffffff8102b008   0000000000000031   ffff88083e893cf0  [    116.805488 ]   00000000000002 96   00003ff fffe00000   ffff800000000067   ffff88083e893d50  [    116.806590 ]   ffff880000000001   ffffffff81066798   ffff88083effe6b8   ffff88083e893d50  [    116.807691 ]   Call   Trace :  [    116.808087 ]   TSK  [    116.808448 ]   [ ffffffff8100e836 ]   __warn . constprop .0 + 0xa6 / 0x100  [    116.809126 ]   [ ffffffff8100e91f ]   warn_slowpath_null + 0xf / 0x20  [    116.809802 ]   [ ffffffff8102b008 ]   handle_lego_mm_fault + 0x4d8 / 0x550  [    116.810505 ]   [ ffffffff8102cfe3 ]   faultin_page + 0x43 / 0xb0  [    116.811131 ]   [ ffffffff8102dab1 ]   copy_strings . isra .1 + 0xe1 / 0x130  [    116.811819 ]   [ ffffffff8102dd1e ]   exec_loader + 0x21e / 0x350  [    116.812457 ]   [ ffffffff8102680a ]   handle_p2m_execve + 0x1aa / 0x290    This is a temporary stack vma that loader created for saving argv and envp. So, this vma was created here:  1\n2\n3\n4\n5\n6 static   int   __bprm_mm_init ( struct   lego_binprm   * bprm )  { \n         ... \n         bprm - vma   =   vma   =   kzalloc ( sizeof ( * vma ),   GFP_KERNEL ); \n         ...  }    And then  copy_strings  will call  faultin_page  to populate a page for a specific user virtual adddress:  1\n2\n3\n4\n5\n6\n7 int   faultin_page ( struct   vm_area_struct   * vma ,   unsigned   long   start , \n                  unsigned   long   flags ,   unsigned   long   * kvaddr )  { \n         ... \n         ret   =   handle_lego_mm_fault ( vma ,   start ,   flags ,   kvaddr ); \n         ...  }    Eventually, the  handle_lego_mm_fault  will call  handle_pte_fault :   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14 static   int   handle_pte_fault ( struct   vm_area_struct   * vma ,   unsigned   long   address , \n                             unsigned   int   flags ,   pte_t   * pte ,   pmd_t   * pmd , \n                             unsigned   long   * mapping_flags )  { \n         ... \n         if   ( ! pte_present ( entry ))   { \n                 ... \n         } \n\n         pr_info ( %s vma: %p entry: %#lx \\n ,   FUNC ,   vma ,   entry . pte ); \n         dump_pte ( pte ,   NULL ); \n         WARN_ON_ONCE ( 1 ); \n         ...  }    Apparently, pte is wrong! But I don t have time today. Continue tomorrow.\nHmm forgot that we are saving kernel virtual addresses in the pte. Just take a quick look at the lego_pud_alloc things, seems will have some issues. I defenitly need to check all these stuff tomorrow. I ve not touch this part for too long!", 
            "title": "02/14 Wed Rainy"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0213-tue-sunny", 
            "text": "Checking our SLOB allocator today. So I found Yutong s code is using  set_page_private  when slob get a new page from buddy. This private field is only intended to be used by buddy to record the  order . This mixed usage will confuse buddy and create bug.  Even though I removed the  set_page_private ( page ,   0 )  after  free_page , word_count-pthread still fails. Damn.", 
            "title": "02/13 Tue Sunny"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0212-mon-cloudy", 
            "text": "Add this commit  4cb3a8b6a943c90714fd9bb5e5465ee315f0aa30 :  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15     memory: Use kzalloc instead of kmalloc in __bprm_mm_init (loader)\n\n    This was an potentionl bug that was not triggered previously.\n    It is simply because kmalloc ed vma contains some garbage area,\n    while later in the pgfault code, we use\n            if (vma- vm_ops   vma- vm_ops- fault)\n                    ...\n    to check if it is an file-backed fault.\n\n    Fortunately the vma- vm_ops happens to have some leftover value.\n    So this bug was triggered.\n\n    This actually reminds me that this is a series of potential bugs!\n    Even though before I ve added things like force GFP_ZERO in all\n    physical page allocation, I missed the kmalloc s case!   The story is:  I patched the stop_machine code today, and tried to run code with P+M on VM, everything works fine. However, when I tried to run the new code with P+M+S on physical machine, M crashed at a very weird point:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21 [ 7791.998168] handle_p2m_execve(): pid:81,argc:2,envc:2,file:/root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread\n[ 7792.129312] BUG: unable to handle kernel NULL pointer dereference at 0000000000000031\n[ 7792.222889] IP: [ ffffffff8102c180 ] handle_lego_mm_fault+0x160/0x4b0\n[ 7792.299842] PGD 0\n[ 7792.323760] Oops: 0000 [#1] PREEMPT SMP MEMORY\n[ 7792.376794] CPU: 4 PID: 79 Comm: mc-manager 4.0.0-lego+ #29 [ 7792.443349] RIP: .. [ ffffffff8102c180 ] handle_lego_mm_fault+0x160/0x4b0 ......\n....\n[ 7793.750506] Call Trace:\n[ 7793.779623]  TSK  [ 7793.802501] [ ffffffff810053f4 ] ? apic_timer_interrupt+0x54/0x90 [ 7793.875295] [ ffffffff8102e469 ] faultin_page+0x9/0x70 [ 7793.936649] [ ffffffff8102ef01 ] copy_strings.isra.1+0xe1/0x130 [ 7794.007362] [ ffffffff8102f11e ] exec_loader+0x1ce/0x340 [ 7794.070796] [ ffffffff81027def ] handle_p2m_execve+0x12f/0x200 [ 7794.140469] [ ffffffff810274fb ] mc_manager+0x1ab/0x2b0\n[ 7794.202864] [ ffffffff81027350 ] ? bitmap_fill+0x33/0x33\n[ 7794.266298] [ ffffffff8101c6b7 ] kthread+0x107/0x130\n[ 7794.325572] [ ffffffff8101c5b0 ] ? __kthread_parkme+0x90/0x90\n[ 7794.394205] [ ffffffff8100b462 ] ret_from_fork+0x22/0x30   So faulting source code is: 1\n2\n3\n4\n5\n6\n7\n8 static   int   handle_pte_fault ( struct   vm_area_struct   * vma ,   unsigned   long   address , \n                             unsigned   int   flags ,   pte_t   * pte ,   pmd_t   * pmd )  { \n     ....           if   ( vma - vm_ops     vma - vm_ops - fault )                   return   do_linear_fault ( vma ,   address ,   flags ,                                          pte ,   pmd ,   entry ) \n     ....    Something wrong with  vma ? At this loader stage, this vma is a temporaty stack vma created for saving  argv  and  envp . So I look back into the code that created this vma:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 managers / memory / loader / core . c :  static   int   __bprm_mm_init ( struct   lego_binprm   * bprm )  { \n         int   err ; \n         struct   vm_area_struct   * vma   =   NULL ; \n         struct   lego_mm_struct   * mm   =   bprm - mm ;           bprm - vma   =   vma   =   kmalloc ( sizeof ( * vma ),   GFP_KERNEL );           if   ( ! vma ) \n                 return   - ENOMEM ;    The code after this does NOT do necessary cleanup. The  vm_ops  happens to have some garbage value from last user. So it is not 0, so the above  vma- vm_ops  is true, and it will try to read  vma- vm_ops- fault . And that, my friend, is where garbage turns into crash.  This presents a series of potential bugs. Ugh,  memory safety !", 
            "title": "02/12 Mon Cloudy"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0209-fri-cloudy", 
            "text": "Tried to modify Phoneix code: replace  realloc  with  malloc+mempcy . Thus the  mremap  syscall is avoided, but it still has general protection fault. Same with yesterday, corrupted at  __strcmp_sse42 , with corrupted  RSI  or  RDI . So I guess it is not about  mremap  itself at all. I will follow yesterday s checking list.", 
            "title": "02/09 Fri Cloudy"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0208-thur-cloudy", 
            "text": "1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38 00000000004272d0  __strcmp_sse42 :\n\n  4272d0:       89 f1                   mov    %esi,%ecx\n  4272d2:       89 f8                   mov    %edi,%eax\n  4272d4:       48 83 e1 3f             and    $0x3f,%rcx\n  4272d8:       48 83 e0 3f             and    $0x3f,%rax\n  4272dc:       83 f9 30                cmp    $0x30,%ecx\n  4272df:       77 3f                   ja     427320  __strcmp_sse42+0x50 \n  4272e1:       83 f8 30                cmp    $0x30,%eax\n  4272e4:       77 3a                   ja     427320  __strcmp_sse42+0x50 \n  4272e6:       f3 0f 6f 0f             movdqu (%rdi),%xmm1 * 4272ea:       f3 0f 6f 16             movdqu (%rsi),%xmm2   4272ee:       66 0f ef c0             pxor   %xmm0,%xmm0\n  4272f2:       66 0f 74 c1             pcmpeqb %xmm1,%xmm0\n  4272f6:       66 0f 74 ca             pcmpeqb %xmm2,%xmm1\n  4272fa:       66 0f f8 c8             psubb  %xmm0,%xmm1\n  4272fe:       66 0f d7 d1             pmovmskb %xmm1,%edx\n  427302:       81 ea ff ff 00 00       sub    $0xffff,%edx\n  427308:       0f 85 42 0d 00 00       jne    428050  __strcmp_sse42+0xd80 \n  42730e:       48 83 c6 10             add    $0x10,%rsi\n  427312:       48 83 c7 10             add    $0x10,%rdi\n  427316:       66 2e 0f 1f 84 00 00    nopw   %cs:0x0(%rax,%rax,1)\n  42731d:       00 00 00  \n  427320:       48 83 e6 f0             and    $0xfffffffffffffff0,%rsi\n  427324:       48 83 e7 f0             and    $0xfffffffffffffff0,%rdi\n  427328:       ba ff ff 00 00          mov    $0xffff,%edx\n  42732d:       45 31 c0                xor    %r8d,%r8d\n  427330:       83 e1 0f                and    $0xf,%ecx\n  427333:       83 e0 0f                and    $0xf,%eax\n  427336:       66 0f ef c0             pxor   %xmm0,%xmm0\n  42733a:       39 c1                   cmp    %eax,%ecx\n  42733c:       74 32                   je     427370  __strcmp_sse42+0xa0 \n  42733e:       77 07                   ja     427347  __strcmp_sse42+0x77 \n  427340:       41 89 d0                mov    %edx,%r8d\n  427343:       91                      xchg   %eax,%ecx\n  427344:       48 87 f7                xchg   %rsi,%rdi * 427347:       66 0f 6f 17             movdqa (%rdi),%xmm2   (RDI: 0000000000000000)   Frustrating! What is wrong with multithread program? Because of broken FPU-switch code? of inappropriate TLB flush? of IB corrupts memory? of what? ugh?  I m done with this random guess and frustrated general protection or segfault, I need to first make sure underlying kernel is 100%  percent correct, this is a checking list:   fpu save/restore  always fail at some XMM instruction  always with corrupted RDI or RSI    switch_to_asm  %gs and %fs  switch_mm (pgd)  stack frame    set_arch_tls (%fs)  glibc s way of using per thread data    some cpu may miss tlb flush  kernel entry/exit assembly  current_task macro  stack_stratch  per-cpu data in entry.S    futex  clear_tid  set_tid  shared mm  robust list    interrupts  vector array  APIC setup  IO-APIC  timer interrupt    cpu_init and Trampoline  faked kernel version  P side pgfault handling code (SMP)  and M side pgfault handling (SMP)  mremap, munmap  check pgtable boundary    In all, check SMP implications   Is there any code, that is solely used to test if the underlying kernel has appropriate behaviors? Like glibc test code?  How to protect kernel virtual memory? Any existing solutions in Linux?  What is the implication of multiple CPU entering kernel at the same time? How can it corrupt user pages? Maybe: kernel entry code, per-cpu data in entry code, fpu code, switch_to, scheduler.  Why it always fail at those FPU code i.e. the strcmp function? I failed to compile without those sse, any solution? How it hurt performance?", 
            "title": "02/08 Thur Cloudy"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0207-wed-cloudy", 
            "text": "20 : 07 \nPushed a small patch on mremap issue. Hope it will work. mremap really makes the whole thing very interesting, will be a very good research finding on combing virtual cache and operating system. Need to go gym with a friend, will be back on debugging late tonight.  9 : 30 \nHave two meetings to do today, and an security class, won t have too much time coding during daytime.", 
            "title": "02/07 Wed Cloudy"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0206-tue-sunny", 
            "text": "Well. We ve ruled out both  smp_call_function  and  workqueue  yesterday with Yiying s help. But the multi-thread word-count still fails  :-(  Single thread word-count just finished 4GB dataset (with 8GB pcache). So what could be still wrong with multithread one????   chill  check exit code  (Checked)  check pcache s usage of task_struct, should always use the group_leader  check cpu boot code and check the switch code again  I believe pinpoint the issue in multithread word-count can solve a lot issues, it must be some thread creation, removal, schedule things.  How about adding a lock for ibapi, make it sequential? Sweet, I tried, finally it is  a bug that we are able to debug .   22 : 39 \nDone for today. I m trying to patch  move_pte  and  pcache_move_pte . Although in theory we defenitly need to patch it, I keep thinking the code before should not trigger any serious bus or memory corruption. Ugh. Maybe it is concurrent  mremap  that one of them remap from A to B, while another one remap from C to A. It is possible. But my dead brain can not think of this anymore. I m going to hit the gym and do some squats.  17 : 01 \nCriminal found:  mremap()  and  virtual cache  did the crime. Interesting, I have not seen any research paper, tech-reports, writeup, code about this, not even the OVC paper, which, by the way, I think they must consider this case. Otherwise, a mremap will simply crash its virtual cache. Many thanks went to my smoke-and-think time.  15 : 14 \nSomething new came up! After adding a spinlock for ibapi, this showed up (I tried one more time after this, which does not show up). We are lucky to catch this. At least I know where to look at. Also, this is defenitly triggered by  mremap . It is seems it is overlapped  mremap() . One thing I did not know is which thread trigger this bug, the sweep thread? Cause mremap related pcache rmap functions do not use  rmap_get_locked_pte .  1\n2\n3\n4\n5\n6\n7 [ 3826.048774] normal_p2s_open(): f_name: word_100MB.txt, mode: 04400, flags: 0\n[ 3827.891622] SYSC_mremap(cpu18): move: [0x7fffe5788000 - 0x7fffe5806000] -  [0x7fffe531b000 - 0x7fffe5399000]\n[ 3828.178643] SYSC_mremap(cpu14): move: [0x7fffe5941000 - 0x7fffe5980000] -  [0x7fffe57c7000 - 0x7fffe5806000]\n\n****    ERROR: mismatched PTE and rmap\n****    rmap- owner_process: word_count-pthr uva: 0x7fffe57c8000 ptep: ffff88107efe0e40, rmap- page_table: ffff88107efe0e40\n****    pcache_pfn: 0x1257c8, pte_pfn: 0x125942   14 : 00    word_count-pthread : 100MB dataset pcache : 8GB, 8-way victim : 8 entries  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21 [ 1294.845313] STDOUT: ---[\nWordcount: Running...\n]---\n[ 1294.903661] STDOUT: ---[\n\no;\n]---\n[ 1294.946301] normal_p2s_open(): f_name: /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_100MB.txt, mode: 04400, flags: 0\n[ 1295.100517] SYSC_close(): [4] -  [/sys/devices/system/cpu/online]\n[ 1295.594658] word_count-pthr[59] general protection ip:4272ea sp:7ffff1b8ed28 error:0\n[ 1295.685236] CPU: 10 PID: 59 Comm: word_count-pthr 4.0.0-lego+ #113\n[ 1295.759070] RIP: 0033:[ 00000000004272ea ]  [ 00000000004272ea ] 0x4272ea\n[ 1295.840184] RSP: 002b:00007ffff1b8ed28  EFLAGS: 00010283\n[ 1295.903621] RAX: 000000000000000f RBX: 00007fffe5a3d010 RCX: 0000000000000001\n[ 1295.988893] RDX: 0000000000000000 RSI: 4854005942004441 RDI: 00007ffff1c1e80f\n[ 1296.074166] RBP: 00007ffff1c1e80f R08: 0000000000000000 R09: 0000000000000010\n[ 1296.211435] R10: 0000000000427ce0 R11: 00007ffff1bbb3ba R12: 0000000000001de4\n[ 1296.296711] R13: 00000000006e4a80 R14: 0000000000001d9e R15: 0000000000001dc1\n[ 1296.433978] FS:  00007ffff1b8f700(0000) GS:ffff88107fca0000(0000) knlGS:0000000000000000\n[ 1296.582686] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[ 1296.963297] CR2: 00007ffff1c1e000 CR3: 000000207fd8a000 CR4: 00000000000406a0  \nSo what is this  ip : 4272 ea , let us objdump the binary:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26 0000000000425e60  strcmp :\n  425e60:       48 8d 05 69 14 00 00    lea    0x1469(%rip),%rax        # 4272d0  __strcmp_sse42 \n  425e67:       f7 05 5f b8 2b 00 00    testl  $0x100000,0x2bb85f(%rip)        # 6e16d0  _dl_x86_cpu_features+0x10 \n  425e6e:       00 10 00\n  425e71:       75 1a                   jne    425e8d  strcmp+0x2d \n  425e73:       48 8d 05 46 b0 00 00    lea    0xb046(%rip),%rax        # 430ec0  __strcmp_ssse3 \n  425e7a:       f7 05 4c b8 2b 00 00    testl  $0x200,0x2bb84c(%rip)        # 6e16d0  _dl_x86_cpu_features+0x10 \n  425e81:       02 00 00\n  425e84:       75 07                   jne    425e8d  strcmp+0x2d \n  425e86:       48 8d 05 03 00 00 00    lea    0x3(%rip),%rax        # 425e90  __GI_strcmp \n  425e8d:       c3                      retq\n  425e8e:       66 90                   xchg   %ax,%ax\n .. ..\n .. ..\n00000000004272d0  __strcmp_sse42 :\n  4272d0:       89 f1                   mov    %esi,%ecx\n  4272d2:       89 f8                   mov    %edi,%eax\n  4272d4:       48 83 e1 3f             and    $0x3f,%rcx\n  4272d8:       48 83 e0 3f             and    $0x3f,%rax\n  4272dc:       83 f9 30                cmp    $0x30,%ecx\n  4272df:       77 3f                   ja     427320  __strcmp_sse42+0x50 \n  4272e1:       83 f8 30                cmp    $0x30,%eax\n  4272e4:       77 3a                   ja     427320  __strcmp_sse42+0x50 \n  4272e6:       f3 0f 6f 0f             movdqu (%rdi),%xmm1\n* 4272ea:       f3 0f 6f 16             movdqu (%rsi),%xmm2\n  4272ee:       66 0f ef c0             pxor   %xmm0,%xmm0  \nYou can see  %rsi  has some garbage value  RSI :   4854005942004441 . Something went wrong. Will it be our FPU? I m not quite sure. If FPU code has error, why single-thread one succeed? Why it only shows up at multithread ones?", 
            "title": "02/06 Tue Sunny"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0205-mon-sunny", 
            "text": "From yesterday s testing of Phoenix, it looks like something is wrong in  smp_call_functions() . They are invoked through  tlb flush , which was further invoked by  mremap , or  munmap . The warning from smp is:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16 [   1260.586696 ]   WARNING :   CPU :   0   PID :   73   at   kernel / smp . c : 129   generic_smp_call_function_single_interrupt + 0xb8 / 0x160  [   1260.705251 ]   CPU :   0   PID :   73   Comm :   word_count - pthr   4.0.0 - lego +   # 99  [   1260.777008 ]   Stack :  [   1260.800927 ]   ffff88207fdffef8   ffffffff8100ec67   ffff88107fc00000   ffff88107fc00000  [   1260.888283 ]   ffffffff8100d410   ffff88207fe23df0   ffff88207fdfff08   ffffffff8100ed5f  [   1260.975639 ]   ffff88207fdfff38   ffffffff8100fe68   00007ff fe58c3010   0000000000000f 96  [   1261.062995 ]   000000000000f 960   0000000000000f 95   ffff88207fdfff48   ffffffff810020dd  [   1261.150351 ]   00007ff ff58869c1   ffffffff8100b2e9   0000000000000f 96   0000000000000f 95  [   1261.237707 ]   Call   Trace :  [   1261.266825 ]   TSK  [   1261.289704 ]   [ ffffffff8100ec76 ]   __warn . constprop .0 + 0xa6 / 0x100  [   1261.359381 ]   [ ffffffff8100d410 ]   ?   pgd_free + 0x90 / 0x90  [   1261.419699 ]   [ ffffffff8100ed5f ]   warn_slowpath_null + 0xf / 0x20  [   1261.487295 ]   [ ffffffff8100fe68 ]   generic_smp_call_function_single_interrupt + 0xb8 / 0x160  [   1261.581931 ]   [ ffffffff810020dd ]   call_function_interrupt + 0x1d / 0x20  [   1261.655767 ]   [ ffffffff8100b2e9 ]   smp__call_function_interrupt + 0x69 / 0x70    So I decided to look into smp.c a little bit to find out if there is something wrong (I wrote it long time ago). The warning itself is true, it means some inconsistent behavior.. I saw  alloc_percpu  stuff during  call_function_init , hence probably I also need to check percpu code a little code cause I m not sure if I port all the functionalities.  In all, today s task, check  percpu  and  smp_call_function  code. Esp,  percpu  code, they are crucial and very hard to relate real bugs to it.  Well  things changed. I found a more serious bug: something about  cpuhotplug , even though lego is not using it.  cpuhotplug  is a set of implict callbacks to all different subsystems who want to do some initialization work on each  offline- online  cpu.  Let us dig into how secondary cpu boots:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 Trampoline ..   setup   64 bit   mode  start_secondary () \n   smp_callin () \n         notify_cpu_starting () \n               ... \n               while   ( st - state     target )   { \n                       st - state ++ ; \n                       cpuhp_invoke_callback ( cpu ,   st - state ,   true ,   NULL ); \n               } \n           cpuhp_invoke_callback ()    See? There will be some callbacks! What are those callbacks exactly? Well, they are predefined at the  kernel/cpu.c . To save the trouble of reading code, I just print what functions are executed, the log is:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37 [    0.118235] cpuhp_invoke_callback(): 136  CPU:0  page_writeback_cpu_online+0x0/0x20\n\n[    0.368478] cpuhp_invoke_callback(): 136  CPU:1  smpboot_create_threads+0x0/0x90\n[    0.370196] cpuhp_invoke_callback(): 136  CPU:1  perf_event_init_cpu+0x0/0xa0\n[    0.370403] cpuhp_invoke_callback(): 136  CPU:1  workqueue_prepare_cpu+0x0/0x80\n[    0.371112] cpuhp_invoke_callback(): 136  CPU:1  hrtimers_prepare_cpu+0x0/0x60\n[    0.371339] cpuhp_invoke_callback(): 136  CPU:1  smpcfd_prepare_cpu+0x0/0x80\n[    0.371584] cpuhp_invoke_callback(): 136  CPU:1  relay_prepare_cpu+0x0/0xe0\n[    0.371794] cpuhp_invoke_callback(): 136  CPU:1  rcutree_prepare_cpu+0x0/0x170\n[    0.372333] cpuhp_invoke_callback(): 136  CPU:1  notify_prepare+0x0/0xa0\n[    0.372744] cpuhp_invoke_callback(): 136  CPU:1  bringup_cpu+0x0/0x100\n[    0.008000] cpuhp_invoke_callback(): 136  CPU:1  sched_cpu_starting+0x0/0x60\n[    0.926124] cpuhp_invoke_callback(): 136  CPU:1  smpboot_unpark_threads+0x0/0x90\n[    0.926124] cpuhp_invoke_callback(): 136  CPU:1  perf_event_init_cpu+0x0/0xa0\n[    0.927028] cpuhp_invoke_callback(): 136  CPU:1  workqueue_online_cpu+0x0/0x2a0\n[    0.927768] cpuhp_invoke_callback(): 136  CPU:1  rcutree_online_cpu+0x0/0x70\n[    0.928045] cpuhp_invoke_callback(): 136  CPU:1  notify_online+0x0/0x20\n[    0.928256] cpuhp_invoke_callback(): 136  CPU:1  page_writeback_cpu_online+0x0/0x20\n[    0.928527] cpuhp_invoke_callback(): 136  CPU:1  sched_cpu_activate+0x0/0x190\n\n[    0.929084] cpuhp_invoke_callback(): 136  CPU:2  smpboot_create_threads+0x0/0x90\n[    0.930240] cpuhp_invoke_callback(): 136  CPU:2  perf_event_init_cpu+0x0/0xa0\n[    0.930434] cpuhp_invoke_callback(): 136  CPU:2  workqueue_prepare_cpu+0x0/0x80\n[    0.931070] cpuhp_invoke_callback(): 136  CPU:2  hrtimers_prepare_cpu+0x0/0x60\n[    0.931264] cpuhp_invoke_callback(): 136  CPU:2  smpcfd_prepare_cpu+0x0/0x80\n[    0.931464] cpuhp_invoke_callback(): 136  CPU:2  relay_prepare_cpu+0x0/0xe0\n[    0.931649] cpuhp_invoke_callback(): 136  CPU:2  rcutree_prepare_cpu+0x0/0x170\n[    0.932245] cpuhp_invoke_callback(): 136  CPU:2  notify_prepare+0x0/0xa0\n[    0.932475] cpuhp_invoke_callback(): 136  CPU:2  bringup_cpu+0x0/0x100\n[    0.008000] cpuhp_invoke_callback(): 136  CPU:2  sched_cpu_starting+0x0/0x60\n[    1.005023] cpuhp_invoke_callback(): 136  CPU:2  smpboot_unpark_threads+0x0/0x90\n[    1.005065] cpuhp_invoke_callback(): 136  CPU:2  perf_event_init_cpu+0x0/0xa0\n[    1.005408] cpuhp_invoke_callback(): 136  CPU:2  workqueue_online_cpu+0x0/0x2a0\n[    1.005729] cpuhp_invoke_callback(): 136  CPU:2  rcutree_online_cpu+0x0/0x70\n[    1.006029] cpuhp_invoke_callback(): 136  CPU:2  notify_online+0x0/0x20\n[    1.006206] cpuhp_invoke_callback(): 136  CPU:2  page_writeback_cpu_online+0x0/0x20\n[    1.006549] cpuhp_invoke_callback(): 136  CPU:2  sched_cpu_activate+0x0/0x190   Interesting! Currently, Lego need to add the  smpboot_create_threads() ,  workqueue_prepare_cpu() ,  workqueue_prepare_cpu() ,  bringup_cpu() ,  smpboot_unpark_threads() ,  workqueue_online_cpu() .  This hidden things is really hard to find and not easy to track during boot. Especially during boot, they should do something like  for_each_online_cpu  and init one by one. But I guess, after adding support of cpu hotplug, code kind of merged. Some stuff will be executed whenever a cpu has been teardown or bought up. And bang, why not use the same set of hotplug during boot, right?\nWell.", 
            "title": "02/05 Mon Sunny"
        }, 
        {
            "location": "/lego/boot/grub/", 
            "text": "Use GRUB2 to boot Lego\n\n\nLast Updated: 02/02/2018\n\n\nThis document explains: \n1)\n how Lego itself is written to pretend as a Linux kernel, \n2)\n how to boot Lego kernel with GRUB2, \n3)\n GRUB2 configurations specific to Lego.\n\n\nHow Lego pretend as a Linux kernel\n\n\nasdsad\n\n\nHow to config GRUB2 for Lego\n\n\nasdsa", 
            "title": "GRUB"
        }, 
        {
            "location": "/lego/boot/grub/#use-grub2-to-boot-lego", 
            "text": "Last Updated: 02/02/2018  This document explains:  1)  how Lego itself is written to pretend as a Linux kernel,  2)  how to boot Lego kernel with GRUB2,  3)  GRUB2 configurations specific to Lego.", 
            "title": "Use GRUB2 to boot Lego"
        }, 
        {
            "location": "/lego/boot/grub/#how-lego-pretend-as-a-linux-kernel", 
            "text": "asdsad", 
            "title": "How Lego pretend as a Linux kernel"
        }, 
        {
            "location": "/lego/boot/grub/#how-to-config-grub2-for-lego", 
            "text": "asdsa", 
            "title": "How to config GRUB2 for Lego"
        }, 
        {
            "location": "/lego/boot/trampoline/", 
            "text": "How trampoline works in Lego\n\n\nWhat is trampoline code?\n\n\nTrampoline code is used by \nBSP\n to boot other secondary CPUs.\nAt startup, \nBSP\n wakeup secondary CPUs by sending a \nAPIC INIT\n\ncommand, which carry the \n[start_ip]\n where the secondary CPUs should\nstart to run.\n\n\nThe trampoline code is the code starting from \n[start_ip]\n. Used\nby the secondary CPU to jump from \n16-bit realmode\n to \n64-bit\n code\n(the first instruction of 64-bit code will be in \narch/x86/kernel/head_64.S\n).\n\n\nWhere is the trampoline source code?\n\n\nThe source files are all in \narch/x86/realmode/\n. There are two parts: \n1)\n \narch/x86/realmode/rm/trampoline.S\n: which is the code that will run. And it is a mix of 16-bit, 32-bit, 64-bit code (ugh..). \n2)\n \narch/x86/realmode/piggy.S\n: Since the trampoline code can not to linked\ninto kernel image directly. So we have to piggyback the trampoline.bin binary\ncode into a section, which is described by \ntrampoline_start\n and \ntrampoline_end\n. So the kernel can address the trampoline code via these two symbols.\n\n\nThe compile flow is:\n\n1\n2\n3\n4\n5\n6\n    arch/x86/realmode/rm/trmapoline.S\n    -\n CC__ arch/x86/realmode/rm/trmapoline.o\n       -\n LD arch/x86/realmode/rm/trampoline\n          -\n OBJCOPY arch/x86/realmode/rm/trampoline.bin\n             -\n This bin goes into piggy.o\n            -\n piggy.o goes into vmImage\n\n\n\n\n\nWhat happened at runtime?\n\n\nThe setup code was loaded by GRUB below 1MB. Inside \narch/x86/boot/main.c\n, we\nwill save the \ncs()\n into the \nboot_params\n and pass it to kernel. In \nsetup_arch()\n, we will copy the trampoline.bin code to the \ncs()\n address reported by \nboot_param\n. This means we will override setup code, which is okay.\n\n\nAt last, we wake up the secondary CPUs inside \nsmp_init()\n.\n\n\nCompare with Linux\n\n\nI vaguely remember how Linux implement this. The only thing I remember is that Linux use some sort of structure, which is filled by BSP and then passed, or used by secondary CPUs. The mechanism has no difference, though. Linux just has more robust debugging facilities.\n\n\n\nYizhou Shan\n\nMar 3, 2017", 
            "title": "Trampoline"
        }, 
        {
            "location": "/lego/boot/trampoline/#how-trampoline-works-in-lego", 
            "text": "", 
            "title": "How trampoline works in Lego"
        }, 
        {
            "location": "/lego/boot/trampoline/#what-is-trampoline-code", 
            "text": "Trampoline code is used by  BSP  to boot other secondary CPUs.\nAt startup,  BSP  wakeup secondary CPUs by sending a  APIC INIT \ncommand, which carry the  [start_ip]  where the secondary CPUs should\nstart to run.  The trampoline code is the code starting from  [start_ip] . Used\nby the secondary CPU to jump from  16-bit realmode  to  64-bit  code\n(the first instruction of 64-bit code will be in  arch/x86/kernel/head_64.S ).", 
            "title": "What is trampoline code?"
        }, 
        {
            "location": "/lego/boot/trampoline/#where-is-the-trampoline-source-code", 
            "text": "The source files are all in  arch/x86/realmode/ . There are two parts:  1)   arch/x86/realmode/rm/trampoline.S : which is the code that will run. And it is a mix of 16-bit, 32-bit, 64-bit code (ugh..).  2)   arch/x86/realmode/piggy.S : Since the trampoline code can not to linked\ninto kernel image directly. So we have to piggyback the trampoline.bin binary\ncode into a section, which is described by  trampoline_start  and  trampoline_end . So the kernel can address the trampoline code via these two symbols.  The compile flow is: 1\n2\n3\n4\n5\n6     arch/x86/realmode/rm/trmapoline.S\n    -  CC__ arch/x86/realmode/rm/trmapoline.o\n       -  LD arch/x86/realmode/rm/trampoline\n          -  OBJCOPY arch/x86/realmode/rm/trampoline.bin\n             -  This bin goes into piggy.o\n            -  piggy.o goes into vmImage", 
            "title": "Where is the trampoline source code?"
        }, 
        {
            "location": "/lego/boot/trampoline/#what-happened-at-runtime", 
            "text": "The setup code was loaded by GRUB below 1MB. Inside  arch/x86/boot/main.c , we\nwill save the  cs()  into the  boot_params  and pass it to kernel. In  setup_arch() , we will copy the trampoline.bin code to the  cs()  address reported by  boot_param . This means we will override setup code, which is okay.  At last, we wake up the secondary CPUs inside  smp_init() .", 
            "title": "What happened at runtime?"
        }, 
        {
            "location": "/lego/boot/trampoline/#compare-with-linux", 
            "text": "I vaguely remember how Linux implement this. The only thing I remember is that Linux use some sort of structure, which is filled by BSP and then passed, or used by secondary CPUs. The mechanism has no difference, though. Linux just has more robust debugging facilities.  \nYizhou Shan \nMar 3, 2017", 
            "title": "Compare with Linux"
        }, 
        {
            "location": "/lego/kernel/kconfig/", 
            "text": "Lego Kconfig\n\n\nNetwork\n\n\n\n\nEnable \nCONFIG_INFINIBAND\n\n\nEnable \nCONFIG_FIT\n\n\nSet \nCONFIG_FIT_INITIAL_SLEEP_TIMEOUT\n: boot time connection timeout\n\n\nSet \nCONFIG_FIT_NR_NODES\n: number of Lego nodes in this run\n\n\nSet \nCONFIG_FIT_LOCAL_ID\n: current node id\n\n\n\n\nIn \nnet/lego/fit_machine.c\n, modify the \nlego_cluster_hostnames\n array to match the machines you are using.\n\n\n\n\n\n\nSet \nCONFIG_DEFAULT_MEM_NODE\n in processor manager\n\n\n\n\nSet \nCONFIG_DEFAULT_STORAGE_NODE\n if you are running with storage component.\n\n\n\n\nNetwork configuration is crucial, please make sure all Lego nodes have consistent configurations. Otherwise the system may panic or fail to connect.\n\n\nProcessor\n\n\n\n\nEnable \nCONFIG_COMP_PROCESSOR\n\n\nopen \n.config\n\n\nremove line \n# CONFIG_COMP_PROCESSOR is not set\n\n\nclose \n.config\n\n\ndo \nmake\n, you will see \nConfigure Lego as processor component (COMP_PROCESSOR) [N/y/?] (NEW)\n, select Y\n\n\nChoose default configuration for all new config options\n\n\n\n\n\n\nEnable \nCONFIG_USE_RAMFS\n if you are not using storage components\n\n\n\n\nMemory\n\n\n\n\nEnable \nCONFIG_COMP_MEMORY\n\n\nopen \n.config\n\n\nremove line \n# CONFIG_COMP_MEMORY is not set\n\n\nclose \n.config\n\n\ndo \nmake\n, you will see \nConfigure Lego as memory component manager (COMP_MEMORY) [N/y/?] (NEW)\n, select Y\n\n\nChoose default configuration for all new config options\n\n\n\n\n\n\nEnable \nCONFIG_USE_RAMFS\n if you are not using storage components\n\n\nSet \nCONFIG_RAMFS_OBJECT_FILE\n: points to \nstatic-linked\n ELF file that you want to execute.\n\n\ntips: you can put your test code under \nusr/\n directory, and a simple \nmake\n will compile everything under.\n\n\n\n\n\n\n\n\nRun without Storage Component\n\n\nTo run Lego just with one processor component and one memory component, you need to:\n\n\n\n\nEnable \nCONFIG_USE_RAMFS\n at both sides. And in memory side, you need to set the \nCONFIG_RAMFS_OBJECT_FILE\n, which points to the ELF binary you want to test.\n\n\nmake sure \nCONFIG_DEFAULT_MEM_NODE\n at processor component is pointing to memory component\ns node id.\n\n\n\n\nA typical code snippet and configuration would be:\n\n1\n2\n3\n4\nstatic\n \nconst\n \nchar\n \n*\nlego_cluster_hostnames\n[\nCONFIG_FIT_NR_NODES\n]\n \n=\n \n{\n\n        \n[\n0\n]\n     \n=\n       \nwuklab00\n,\n\n        \n[\n1\n]\n     \n=\n       \nwuklab01\n,\n\n\n};\n\n\n\n\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\nwuklab00 Processor\n\n#\n# Lego Processor Component Configurations\n#\nCONFIG_COMP_PROCESSOR=y\nCONFIG_CHECKPOINT=y\nCONFIG_MEMMAP_MEMBLOCK_RESERVED=y\n# CONFIG_PCACHE_EVICT_RANDOM is not set\n# CONFIG_PCACHE_EVICT_FIFO is not set\nCONFIG_PCACHE_EVICT_LRU=y\nCONFIG_PCACHE_EVICT_GENERIC_SWEEP=y\n# CONFIG_PCACHE_EVICTION_WRITE_PROTECT is not set\n# CONFIG_PCACHE_EVICTION_PERSET_LIST is not set\nCONFIG_PCACHE_EVICTION_VICTIM=y\nCONFIG_PCACHE_EVICTION_VICTIM_NR_ENTRIES=8\nCONFIG_PCACHE_PREFETCH=y\n\n#\n# Processor DEBUG Options\n#\n\n#\n# Lego Memory Component Configurations\n#\n# CONFIG_COMP_MEMORY is not set\n\n#\n# DRAM Cache Options\n#\nCONFIG_PCACHE_LINE_SIZE_SHIFT=12\nCONFIG_PCACHE_ASSOCIATIVITY_SHIFT=3\n\n#\n# General Manager Config/Debug Options\n#\nCONFIG_DEFAULT_MEM_NODE=1\nCONFIG_DEFAULT_STORAGE_NODE=2\nCONFIG_USE_RAMFS=y\n\n#\n# Networking\n#\n# CONFIG_LWIP is not set\nCONFIG_FIT=y\n# CONFIG_FIT_DEBUG is not set\nCONFIG_FIT_INITIAL_SLEEP_TIMEOUT=30\nCONFIG_FIT_NR_NODES=2\nCONFIG_FIT_LOCAL_ID=0\n\n\n\n\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\nwuklab01 Memory\n\n#\n# Lego Memory Component Configurations\n#\nCONFIG_COMP_MEMORY=y\n\n#\n# Memory DEBUG Options\n#\n# CONFIG_MEM_PREFETCH is not set\n\n#\n# DRAM Cache Options\n#\nCONFIG_PCACHE_LINE_SIZE_SHIFT=12\nCONFIG_PCACHE_ASSOCIATIVITY_SHIFT=3\n\n#\n# General Manager Config/Debug Options\n#\nCONFIG_DEFAULT_MEM_NODE=1\nCONFIG_DEFAULT_STORAGE_NODE=2\nCONFIG_USE_RAMFS=y\nCONFIG_RAMFS_OBJECT_FILE=\nusr/pcache_conflict.o\n\n\n#\n# Networking\n#\n# CONFIG_LWIP is not set\nCONFIG_FIT=y\n# CONFIG_FIT_DEBUG is not set\nCONFIG_FIT_INITIAL_SLEEP_TIMEOUT=30\nCONFIG_FIT_NR_NODES=2\nCONFIG_FIT_LOCAL_ID=1", 
            "title": "Kconfig"
        }, 
        {
            "location": "/lego/kernel/kconfig/#lego-kconfig", 
            "text": "", 
            "title": "Lego Kconfig"
        }, 
        {
            "location": "/lego/kernel/kconfig/#network", 
            "text": "Enable  CONFIG_INFINIBAND  Enable  CONFIG_FIT  Set  CONFIG_FIT_INITIAL_SLEEP_TIMEOUT : boot time connection timeout  Set  CONFIG_FIT_NR_NODES : number of Lego nodes in this run  Set  CONFIG_FIT_LOCAL_ID : current node id   In  net/lego/fit_machine.c , modify the  lego_cluster_hostnames  array to match the machines you are using.    Set  CONFIG_DEFAULT_MEM_NODE  in processor manager   Set  CONFIG_DEFAULT_STORAGE_NODE  if you are running with storage component.   Network configuration is crucial, please make sure all Lego nodes have consistent configurations. Otherwise the system may panic or fail to connect.", 
            "title": "Network"
        }, 
        {
            "location": "/lego/kernel/kconfig/#processor", 
            "text": "Enable  CONFIG_COMP_PROCESSOR  open  .config  remove line  # CONFIG_COMP_PROCESSOR is not set  close  .config  do  make , you will see  Configure Lego as processor component (COMP_PROCESSOR) [N/y/?] (NEW) , select Y  Choose default configuration for all new config options    Enable  CONFIG_USE_RAMFS  if you are not using storage components", 
            "title": "Processor"
        }, 
        {
            "location": "/lego/kernel/kconfig/#memory", 
            "text": "Enable  CONFIG_COMP_MEMORY  open  .config  remove line  # CONFIG_COMP_MEMORY is not set  close  .config  do  make , you will see  Configure Lego as memory component manager (COMP_MEMORY) [N/y/?] (NEW) , select Y  Choose default configuration for all new config options    Enable  CONFIG_USE_RAMFS  if you are not using storage components  Set  CONFIG_RAMFS_OBJECT_FILE : points to  static-linked  ELF file that you want to execute.  tips: you can put your test code under  usr/  directory, and a simple  make  will compile everything under.", 
            "title": "Memory"
        }, 
        {
            "location": "/lego/kernel/kconfig/#run-without-storage-component", 
            "text": "To run Lego just with one processor component and one memory component, you need to:   Enable  CONFIG_USE_RAMFS  at both sides. And in memory side, you need to set the  CONFIG_RAMFS_OBJECT_FILE , which points to the ELF binary you want to test.  make sure  CONFIG_DEFAULT_MEM_NODE  at processor component is pointing to memory component s node id.   A typical code snippet and configuration would be: 1\n2\n3\n4 static   const   char   * lego_cluster_hostnames [ CONFIG_FIT_NR_NODES ]   =   { \n         [ 0 ]       =         wuklab00 , \n         [ 1 ]       =         wuklab01 ,  };     1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49 wuklab00 Processor\n\n#\n# Lego Processor Component Configurations\n#\nCONFIG_COMP_PROCESSOR=y\nCONFIG_CHECKPOINT=y\nCONFIG_MEMMAP_MEMBLOCK_RESERVED=y\n# CONFIG_PCACHE_EVICT_RANDOM is not set\n# CONFIG_PCACHE_EVICT_FIFO is not set\nCONFIG_PCACHE_EVICT_LRU=y\nCONFIG_PCACHE_EVICT_GENERIC_SWEEP=y\n# CONFIG_PCACHE_EVICTION_WRITE_PROTECT is not set\n# CONFIG_PCACHE_EVICTION_PERSET_LIST is not set\nCONFIG_PCACHE_EVICTION_VICTIM=y\nCONFIG_PCACHE_EVICTION_VICTIM_NR_ENTRIES=8\nCONFIG_PCACHE_PREFETCH=y\n\n#\n# Processor DEBUG Options\n#\n\n#\n# Lego Memory Component Configurations\n#\n# CONFIG_COMP_MEMORY is not set\n\n#\n# DRAM Cache Options\n#\nCONFIG_PCACHE_LINE_SIZE_SHIFT=12\nCONFIG_PCACHE_ASSOCIATIVITY_SHIFT=3\n\n#\n# General Manager Config/Debug Options\n#\nCONFIG_DEFAULT_MEM_NODE=1\nCONFIG_DEFAULT_STORAGE_NODE=2\nCONFIG_USE_RAMFS=y\n\n#\n# Networking\n#\n# CONFIG_LWIP is not set\nCONFIG_FIT=y\n# CONFIG_FIT_DEBUG is not set\nCONFIG_FIT_INITIAL_SLEEP_TIMEOUT=30\nCONFIG_FIT_NR_NODES=2\nCONFIG_FIT_LOCAL_ID=0    1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35 wuklab01 Memory\n\n#\n# Lego Memory Component Configurations\n#\nCONFIG_COMP_MEMORY=y\n\n#\n# Memory DEBUG Options\n#\n# CONFIG_MEM_PREFETCH is not set\n\n#\n# DRAM Cache Options\n#\nCONFIG_PCACHE_LINE_SIZE_SHIFT=12\nCONFIG_PCACHE_ASSOCIATIVITY_SHIFT=3\n\n#\n# General Manager Config/Debug Options\n#\nCONFIG_DEFAULT_MEM_NODE=1\nCONFIG_DEFAULT_STORAGE_NODE=2\nCONFIG_USE_RAMFS=y\nCONFIG_RAMFS_OBJECT_FILE= usr/pcache_conflict.o \n\n#\n# Networking\n#\n# CONFIG_LWIP is not set\nCONFIG_FIT=y\n# CONFIG_FIT_DEBUG is not set\nCONFIG_FIT_INITIAL_SLEEP_TIMEOUT=30\nCONFIG_FIT_NR_NODES=2\nCONFIG_FIT_LOCAL_ID=1", 
            "title": "Run without Storage Component"
        }, 
        {
            "location": "/lego/kernel/debug/", 
            "text": "Debug Facility in Lego\n\n\nLego provides several handy debug helpers to ease our coding pain. We category them by layers, namely \n1)\n \nCore Kernel\n, the lowest level of Lego, which is shared by all managers. \n2)\n \nProcessor Manager\n, which controls processor components. \n3)\n \nMemory Manager\n, which controls memory components.\n\n\nCore Kernel\n\n\n1\n2\nvoid\n \ndump_pte\n(\npte_t\n \n*\nptep\n,\n \nconst\n \nchar\n \n*\nreason\n);\n\n\nvoid\n \ndump_page\n(\nstruct\n \npage\n \n*\npage\n,\n \nconst\n \nchar\n \n*\nreason\n);\n\n\n\n\n\nThese two helpers will dump a given pte entry or a page. Use this function if you are developing core related to physical memory allocation or pcache.\n\n\n\n\n1\nvoid\n \nptdump_walk_pgd_level\n(\npgd_t\n \n*\npgd\n);\n\n\n\n\n\nThis debug helper will dump the whole pgtable ranges. Contiguous page table entries that share the same property will be merged together and will be printed once. Use this function if you are developing code related to user page tables.\n\n\n\n\n1\n2\n3\nvoid\n \nshow_state_filter\n(\nunsigned\n \nlong\n \nstate_filter\n,\n \nbool\n \nprint_rq\n);\n\n\nvoid\n \nsched_show_task\n(\nstruct\n \ntask_struct\n \n*\np\n);\n\n\nvoid\n \nsysrq_sched_debug_show\n(\nvoid\n);\n\n\n\n\n\nThis set of functions are debug helpers for local scheduler. They will print all the tasks running in the system, and detailed information about percpu \nrunqueue\n. Use this set of functions if you are developing code related to scheduler.\n\n\nProcessor Manager\n\n\n1\n2\n3\n4\nvoid\n \ndump_pcache_meta\n(\nstruct\n \npcache_meta\n \n*\npcm\n,\n \nconst\n \nchar\n \n*\nreason\n);\n\n\nvoid\n \ndump_pcache_victim\n(\nstruct\n \npcache_victim_meta\n \n*\nvictim\n,\n \nconst\n \nchar\n \n*\nreason\n);\n\n\nvoid\n \ndump_pcache_rmap\n(\nstruct\n \npcache_rmap\n \n*\nrmap\n,\n \nconst\n \nchar\n \n*\nreason\n);\n\n\nvoid\n \ndump_pcache_line\n(\nstruct\n \npcache_meta\n \n*\npcm\n,\n \nconst\n \nchar\n \n*\nreason\n);\n\n\n\n\n\nThese functions dump a given pcache line, a victim line, or a given reserve mapping. The last one will print the pcache line content, which generates a lot messages, you are warned. Use these functions if you are developing pcache or victim cache code.\n\n\nMemory Manager\n\n\n1\n2\nvoid\n \ndump_lego_mm\n(\nconst\n \nstruct\n \nlego_mm_struct\n \n*\nmm\n);\n\n\nvoid\n \ndump_vma\n(\nconst\n \nstruct\n \nvm_area_struct\n \n*\nvma\n);\n\n\n\n\n\nThese two functions are used to dump the virtual address space of a process. Use these functions if you developing process VM related things.", 
            "title": "Debug"
        }, 
        {
            "location": "/lego/kernel/debug/#debug-facility-in-lego", 
            "text": "Lego provides several handy debug helpers to ease our coding pain. We category them by layers, namely  1)   Core Kernel , the lowest level of Lego, which is shared by all managers.  2)   Processor Manager , which controls processor components.  3)   Memory Manager , which controls memory components.", 
            "title": "Debug Facility in Lego"
        }, 
        {
            "location": "/lego/kernel/debug/#core-kernel", 
            "text": "1\n2 void   dump_pte ( pte_t   * ptep ,   const   char   * reason );  void   dump_page ( struct   page   * page ,   const   char   * reason );   \nThese two helpers will dump a given pte entry or a page. Use this function if you are developing core related to physical memory allocation or pcache.   1 void   ptdump_walk_pgd_level ( pgd_t   * pgd );   \nThis debug helper will dump the whole pgtable ranges. Contiguous page table entries that share the same property will be merged together and will be printed once. Use this function if you are developing code related to user page tables.   1\n2\n3 void   show_state_filter ( unsigned   long   state_filter ,   bool   print_rq );  void   sched_show_task ( struct   task_struct   * p );  void   sysrq_sched_debug_show ( void );   \nThis set of functions are debug helpers for local scheduler. They will print all the tasks running in the system, and detailed information about percpu  runqueue . Use this set of functions if you are developing code related to scheduler.", 
            "title": "Core Kernel"
        }, 
        {
            "location": "/lego/kernel/debug/#processor-manager", 
            "text": "1\n2\n3\n4 void   dump_pcache_meta ( struct   pcache_meta   * pcm ,   const   char   * reason );  void   dump_pcache_victim ( struct   pcache_victim_meta   * victim ,   const   char   * reason );  void   dump_pcache_rmap ( struct   pcache_rmap   * rmap ,   const   char   * reason );  void   dump_pcache_line ( struct   pcache_meta   * pcm ,   const   char   * reason );   \nThese functions dump a given pcache line, a victim line, or a given reserve mapping. The last one will print the pcache line content, which generates a lot messages, you are warned. Use these functions if you are developing pcache or victim cache code.", 
            "title": "Processor Manager"
        }, 
        {
            "location": "/lego/kernel/debug/#memory-manager", 
            "text": "1\n2 void   dump_lego_mm ( const   struct   lego_mm_struct   * mm );  void   dump_vma ( const   struct   vm_area_struct   * vma );   \nThese two functions are used to dump the virtual address space of a process. Use these functions if you developing process VM related things.", 
            "title": "Memory Manager"
        }, 
        {
            "location": "/lego/kernel/pagefault_disable/", 
            "text": "The story of pagefault_disable/enable\n\n\npagefault_disable()\n is not really disabling the whole pgfault handling code. It is used to disable only the handling of pgfault that landed from \nuser virtual address\n. Please note the difference between \nuser virtual address\n and \nuser mode fault\n. The first means the faulting address belongs to user virtual address space, while it can come from either user mode (CPL3) or kernel mode (CPL0). The second is a fault come from user mode (CPL3).\n\n\nIf pgfault is disabled, then \ndo_page_fault()\n function will \nNOT\n try to solve the pgfault by calling into \npcache\n, instead, it will go straight to \nfixup\n code (in no_context()).\n\n\nThis function is not intended to be used standalone. Normally, we do \n1)\n \npagefault_disable()\n, \n2)\n then use some functions that have \nfixup\n code, \n3)\n then \npagefault_enable()\n. (The \nfixup\n code is another magic inside kernel. We will cover it in another document.)\n\n\nCurrently in Lego, this is only used by \nfutex\n, which needs something like \natomic_cmpxchg()\n with an user virtual address. If pgfault happens in the middle, then this will not be atomic since kernel need to do pcache operations, which further needs to through network.\n\n\nHowever, do note the difference with \nuaccess\n family functions. Most \nuaccess\n functions will not disable pgfault handling, which means pcache will be invoked. If pcache returns a \nSEGFAULT\n, pgfault code will go into \nfixup\n code. And that, my friend, is where \nuaccess\n returns \n-EFAULT\n to caller.\n\n\n\nYizhou Shan\n\nFeb 01, 2018", 
            "title": "Disable pgfault"
        }, 
        {
            "location": "/lego/kernel/pagefault_disable/#the-story-of-pagefault_disableenable", 
            "text": "pagefault_disable()  is not really disabling the whole pgfault handling code. It is used to disable only the handling of pgfault that landed from  user virtual address . Please note the difference between  user virtual address  and  user mode fault . The first means the faulting address belongs to user virtual address space, while it can come from either user mode (CPL3) or kernel mode (CPL0). The second is a fault come from user mode (CPL3).  If pgfault is disabled, then  do_page_fault()  function will  NOT  try to solve the pgfault by calling into  pcache , instead, it will go straight to  fixup  code (in no_context()).  This function is not intended to be used standalone. Normally, we do  1)   pagefault_disable() ,  2)  then use some functions that have  fixup  code,  3)  then  pagefault_enable() . (The  fixup  code is another magic inside kernel. We will cover it in another document.)  Currently in Lego, this is only used by  futex , which needs something like  atomic_cmpxchg()  with an user virtual address. If pgfault happens in the middle, then this will not be atomic since kernel need to do pcache operations, which further needs to through network.  However, do note the difference with  uaccess  family functions. Most  uaccess  functions will not disable pgfault handling, which means pcache will be invoked. If pcache returns a  SEGFAULT , pgfault code will go into  fixup  code. And that, my friend, is where  uaccess  returns  -EFAULT  to caller.  \nYizhou Shan \nFeb 01, 2018", 
            "title": "The story of pagefault_disable/enable"
        }, 
        {
            "location": "/lego/kernel/stop_machine/", 
            "text": "The highest priority thread in kernel\n\n\nThis document is about \nmigration/N\n kernel threads, \nstop_sched\n schdueling class, and the interesting source file \nkernel/stop_machine.c\n. Background on kernel scheduler design is recommended.\n\n\nScheduler uses the following code to pick the next runnable task:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\nstatic\n \ninline\n \nstruct\n \ntask_struct\n \n*\n\n\npick_next_task\n(\nstruct\n \nrq\n \n*\nrq\n,\n \nstruct\n \ntask_struct\n \n*\nprev\n)\n\n\n{\n\n        \nstruct\n \ntask_struct\n \n*\np\n;\n\n        \nconst\n \nstruct\n \nsched_class\n \n*\nclass\n;\n\n\n\nagain\n:\n\n        \nfor_each_class\n(\nclass\n)\n \n{\n\n                \np\n \n=\n \nclass\n-\npick_next_task\n(\nrq\n,\n \nprev\n);\n\n                \nif\n \n(\np\n)\n \n{\n\n                        \nif\n \n(\nunlikely\n(\np\n \n==\n \nRETRY_TASK\n))\n\n                                \ngoto\n \nagain\n;\n\n                        \nreturn\n \np\n;\n\n                \n}\n    \n        \n}\n\n        \nBUG\n();\n\n\n}\n\n\n\n\n\n\nwhile the class is linked together as:\n\n1\n2\n3\n#define sched_class_highest     (\nstop_sched_class)                                                       \n\n\n#define for_each_class(class) \\                                                                           \n\n   \nfor\n \n(\nclass\n \n=\n \nsched_class_highest\n;\n \nclass\n;\n \nclass\n \n=\n \nclass\n-\nnext\n)\n\n\n\n\n\n\nClearly, the highest priority class is \nstop_sched_class\n. Whenever this scheduling has class runnable threads, scheduler will always run them first. So what kernel threads are using this scheduling class? Well, you must have seen something like \nmigration/0\n when you do \nps aux\n in Linux. And yes, these kernel threads are the only users.\n\n\nThese threads are sleeping most of their lifetime, they will be invoked to do some very urgent stuff. For example, when a user thread that is currently running on CPU0 calls \nsched_setaffinity()\n to bind to CPU1, kernel is not able to do this because this user thread is currently running (runqueue can not move a \nrunning\n task out, it can only move queued task out). Then, scheduler has to ask \nmigration/0\n for help. Once there is a job enqueued, \nmigration/0\n will be invoked. Since it has the highest-priority, it will start execution immediately. Thus the migration from CPU0 to CPU1 is performed safely and fast.\n\n\nmigration\n code is defined in \nkernel/stop_machine.c\n. They are created during early boot. They use the \nsmpboot_register_percpu_thread\n to create threads. They are written in this way because Linux supports cpu hotplug. To simplify we can also create them manually through \nkthread_create\n. Since Lego does not support cpu hotplug, and this \ncpu_stop_init\n is called after SMP is initialized, so Lego has slight different initialiaztion:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\nvoid\n \n__init\n \ncpu_stop_init\n(\nvoid\n)\n\n\n{\n\n        \nunsigned\n \nint\n \ncpu\n;\n\n\n        \nfor_each_possible_cpu\n(\ncpu\n)\n \n{\n\n                \nstruct\n \ncpu_stopper\n \n*\nstopper\n \n=\n \nper_cpu\n(\ncpu_stopper\n,\n \ncpu\n);\n\n\n                \nspin_lock_init\n(\nstopper\n-\nlock\n);\n\n                \nINIT_LIST_HEAD\n(\nstopper\n-\nworks\n);\n\n        \n}\n\n\n        \nBUG_ON\n(\nsmpboot_register_percpu_thread\n(\ncpu_stop_threads\n));\n\n\n        \n/*\n\n\n         * smpboot_create_threads use kthread_create_on_cpu() to\n\n\n         * create new threads. And they are parked, too.\n\n\n         * Since we call this function after smp_init(), all CPUs\n\n\n         * are already online, thus we need to unpark them manually.\n\n\n         */\n\n        \nfor_each_online_cpu\n(\ncpu\n)\n\n                \nstop_machine_unpark\n(\ncpu\n);\n\n\n\n\n\n\nInternally, it also use a list to keep enqueued jobs. Once the thread is waken up, it tries to lookup this list and dequeue jobs (similar to kthread creation, kworker etc.):\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\nstatic\n \nvoid\n \ncpu_stopper_thread\n(\nunsigned\n \nint\n \ncpu\n)\n\n\n{\n\n        \nstruct\n \ncpu_stopper\n \n*\nstopper\n \n=\n \nper_cpu\n(\ncpu_stopper\n,\n \ncpu\n);\n\n        \nstruct\n \ncpu_stop_work\n \n*\nwork\n;\n\n\n\nrepeat\n:\n\n        \nwork\n \n=\n \nNULL\n;\n\n        \nspin_lock_irq\n(\nstopper\n-\nlock\n);\n\n        \nif\n \n(\n!\nlist_empty\n(\nstopper\n-\nworks\n))\n \n{\n\n                \nwork\n \n=\n \nlist_first_entry\n(\nstopper\n-\nworks\n,\n\n                                        \nstruct\n \ncpu_stop_work\n,\n \nlist\n);\n\n                \nlist_del_init\n(\nwork\n-\nlist\n);\n\n        \n}\n   \n        \nspin_unlock_irq\n(\nstopper\n-\nlock\n);\n\n\n        \nif\n \n(\nwork\n)\n \n{\n\n                \n...\n\n                \nret\n \n=\n \nfn\n(\narg\n);\n\n                \n...\n\n                \ngoto\n \nrepeat\n;\n\n        \n}\n   \n\n}\n\n\n\n\n\n\nIt has several interesting public APIs that are quite similar to \nsmp_call_functions\n, but the difference is: this set of APIs provide a guaranteed time-to-execute waiting time, because it will simply preempt anything running on CPU.\n\n\n1\n2\n3\nint\n \nstop_one_cpu\n(\nunsigned\n \nint\n \ncpu\n,\n \ncpu_stop_fn_t\n \nfn\n,\n \nvoid\n \n*\narg\n);\n\n\nint\n \nstop_cpus\n(\nconst\n \nstruct\n \ncpumask\n \n*\ncpumask\n,\n \ncpu_stop_fn_t\n \nfn\n,\n \nvoid\n \n*\narg\n);\n\n\nint\n \ntry_stop_cpus\n(\nconst\n \nstruct\n \ncpumask\n \n*\ncpumask\n,\n \ncpu_stop_fn_t\n \nfn\n,\n \nvoid\n \n*\narg\n);\n\n\n\n\n\n\n\nThey are used only when there are some very urgent things to do. So, please use with caution.\n\n\n\nYizhou Shan\n\nCreated: Feb 12, 2018\n\nLast Updated: Feb 12, 2018", 
            "title": "Stop machine"
        }, 
        {
            "location": "/lego/kernel/stop_machine/#the-highest-priority-thread-in-kernel", 
            "text": "This document is about  migration/N  kernel threads,  stop_sched  schdueling class, and the interesting source file  kernel/stop_machine.c . Background on kernel scheduler design is recommended.  Scheduler uses the following code to pick the next runnable task:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17 static   inline   struct   task_struct   *  pick_next_task ( struct   rq   * rq ,   struct   task_struct   * prev )  { \n         struct   task_struct   * p ; \n         const   struct   sched_class   * class ;  again : \n         for_each_class ( class )   { \n                 p   =   class - pick_next_task ( rq ,   prev ); \n                 if   ( p )   { \n                         if   ( unlikely ( p   ==   RETRY_TASK )) \n                                 goto   again ; \n                         return   p ; \n                 }     \n         } \n         BUG ();  }    while the class is linked together as: 1\n2\n3 #define sched_class_highest     ( stop_sched_class)                                                         #define for_each_class(class) \\                                                                            \n    for   ( class   =   sched_class_highest ;   class ;   class   =   class - next )    Clearly, the highest priority class is  stop_sched_class . Whenever this scheduling has class runnable threads, scheduler will always run them first. So what kernel threads are using this scheduling class? Well, you must have seen something like  migration/0  when you do  ps aux  in Linux. And yes, these kernel threads are the only users.  These threads are sleeping most of their lifetime, they will be invoked to do some very urgent stuff. For example, when a user thread that is currently running on CPU0 calls  sched_setaffinity()  to bind to CPU1, kernel is not able to do this because this user thread is currently running (runqueue can not move a  running  task out, it can only move queued task out). Then, scheduler has to ask  migration/0  for help. Once there is a job enqueued,  migration/0  will be invoked. Since it has the highest-priority, it will start execution immediately. Thus the migration from CPU0 to CPU1 is performed safely and fast.  migration  code is defined in  kernel/stop_machine.c . They are created during early boot. They use the  smpboot_register_percpu_thread  to create threads. They are written in this way because Linux supports cpu hotplug. To simplify we can also create them manually through  kthread_create . Since Lego does not support cpu hotplug, and this  cpu_stop_init  is called after SMP is initialized, so Lego has slight different initialiaztion:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21 void   __init   cpu_stop_init ( void )  { \n         unsigned   int   cpu ; \n\n         for_each_possible_cpu ( cpu )   { \n                 struct   cpu_stopper   * stopper   =   per_cpu ( cpu_stopper ,   cpu ); \n\n                 spin_lock_init ( stopper - lock ); \n                 INIT_LIST_HEAD ( stopper - works ); \n         } \n\n         BUG_ON ( smpboot_register_percpu_thread ( cpu_stop_threads )); \n\n         /*           * smpboot_create_threads use kthread_create_on_cpu() to           * create new threads. And they are parked, too.           * Since we call this function after smp_init(), all CPUs           * are already online, thus we need to unpark them manually.           */ \n         for_each_online_cpu ( cpu ) \n                 stop_machine_unpark ( cpu );    Internally, it also use a list to keep enqueued jobs. Once the thread is waken up, it tries to lookup this list and dequeue jobs (similar to kthread creation, kworker etc.):  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22 static   void   cpu_stopper_thread ( unsigned   int   cpu )  { \n         struct   cpu_stopper   * stopper   =   per_cpu ( cpu_stopper ,   cpu ); \n         struct   cpu_stop_work   * work ;  repeat : \n         work   =   NULL ; \n         spin_lock_irq ( stopper - lock ); \n         if   ( ! list_empty ( stopper - works ))   { \n                 work   =   list_first_entry ( stopper - works , \n                                         struct   cpu_stop_work ,   list ); \n                 list_del_init ( work - list ); \n         }    \n         spin_unlock_irq ( stopper - lock ); \n\n         if   ( work )   { \n                 ... \n                 ret   =   fn ( arg ); \n                 ... \n                 goto   repeat ; \n         }     }    It has several interesting public APIs that are quite similar to  smp_call_functions , but the difference is: this set of APIs provide a guaranteed time-to-execute waiting time, because it will simply preempt anything running on CPU.  1\n2\n3 int   stop_one_cpu ( unsigned   int   cpu ,   cpu_stop_fn_t   fn ,   void   * arg );  int   stop_cpus ( const   struct   cpumask   * cpumask ,   cpu_stop_fn_t   fn ,   void   * arg );  int   try_stop_cpus ( const   struct   cpumask   * cpumask ,   cpu_stop_fn_t   fn ,   void   * arg );    They are used only when there are some very urgent things to do. So, please use with caution.  \nYizhou Shan \nCreated: Feb 12, 2018 \nLast Updated: Feb 12, 2018", 
            "title": "The highest priority thread in kernel"
        }, 
        {
            "location": "/lego/kernel/loader/", 
            "text": "Lego Program Loader\n\n\nThis document explains the high-level workflow of Lego\ns program loader, and how we change the normal loader to fit the disaggregated operating system model. Background on linking and loading is recommended.\n\n\nStatus\n\n\n\n\n\n\n\n\nFormats\n\n\nSupported\n\n\n\n\n\n\n\n\n\n\nELF (static-linked)\n\n\n\n\n\n\n\n\nELF (dynamic-linked)\n\n\n\n\n\n\n\n\n\n\nOverall\n\n\nIn order to support different executable formats, Lego has a \nvirtual loader layer\n above all specific formats, which is quite similar to \nvirtual file system\n. In Lego, \nexecve()\n is divided into two parts: \n1)\n syscall hook at processor side, \n2)\n real loader at memory side. Combined together, they provide the same semantic of \nexecve()\n as described in Linux man page. Also for the code, we divide the Linux implementation into parts. But our emulation model introduces several interesting workarounds.\n\n\nLego\ns Loader\n\n\nLego basically divide the Linux loader into two parts, one in memory manager and other in processor manager. Most dirty work is done by memory manager. Processor manager only needs to make sure the new execution has a fresh environment to start.\n\n\nEntry Point\n\n\nSo the normal entry point is \ndo_execve()\n. Above that, it can be invoked by syscall from user space, or from kernel space by calling \ndo_execve()\n directly. There are not too many places that will call \ndo_execve\n within kernel. One notable case is how kernel starts the \npid 1\n user program. This happens after kernel finished all initialization. The code is:\n\n1\n2\n3\n4\n5\nstatic\n \nint\n \nrun_init_process\n(\nconst\n \nchar\n \n*\ninit_filename\n)\n                                                    \n\n{\n\n        \nargv_init\n[\n0\n]\n \n=\n \ninit_filename\n;\n\n        \nreturn\n \ndo_execve\n(\ninit_filename\n,\n \nargv_init\n,\n \nenvp_init\n);\n\n\n}\n\n\n\n\n\n\nMemory Manager\ns Job\n\n\nMemory manager side will do most of the dirty loading work. It will parse the ELF image, create new VMAs based on ELF information. After that, it only pass \nstart_ip\n and \nstart_stack\n back to processor manager. Once processor manager starts running this new execution, pages will be fetched from memory component on demand.\n\n\nLoad ld-linux\n\n\nFor dynamically-linked images, kernel ELF loader needs to load the \nld-linux.so\n as well. It will first try to map the \nld-linux.so\n into this process\ns virtual address space. Furthermore, the first user instruction that will run is no longer \n__libc_main_start\n, kernel will transfer the kernel to \nld-linux.so\n instead. Thus, for a normal user program, \nld-linux.so\n will load all the shared libraries before running glibc.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\nstatic\n \nint\n \nload_elf_binary\n(\nstruct\n \nlego_task_struct\n \n*\ntsk\n,\n \nstruct\n \nlego_binprm\n \n*\nbprm\n,\n\n                           \nu64\n \n*\nnew_ip\n,\n \nu64\n \n*\nnew_sp\n,\n \nunsigned\n \nlong\n \n*\nargv_len\n,\n \nunsigned\n \nlong\n \n*\nenvp_len\n)\n\n\n{\n\n\n        \n...\n\n        \n/* Dynamically-linked */\n\n        \nif\n \n(\nelf_interpreter\n)\n \n{\n\n                \nunsigned\n \nlong\n \ninterp_map_addr\n \n=\n \n0\n;\n\n\n\n                \nelf_entry\n \n=\n \nload_elf_interp\n(\ntsk\n,\n \nloc\n-\ninterp_elf_ex\n,\n\n\n                                            \ninterpreter\n,\n\n                                            \ninterp_map_addr\n,\n\n                                            \nload_bias\n,\n \ninterp_elf_phdata\n);\n\n                \nif\n \n(\n!\nIS_ERR\n((\nvoid\n \n*\n)\nelf_entry\n))\n \n{\n\n                        \n/*\n\n\n                         * load_elf_interp() returns relocation\n\n\n                         * adjustment\n\n\n                         */\n\n                        \ninterp_load_addr\n \n=\n \nelf_entry\n;\n\n                        \nelf_entry\n \n+=\n \nloc\n-\ninterp_elf_ex\n.\ne_entry\n;\n\n                \n}\n\n                \nif\n \n(\nBAD_ADDR\n(\nelf_entry\n))\n \n{\n\n                        \nretval\n \n=\n \nIS_ERR\n((\nvoid\n \n*\n)\nelf_entry\n)\n \n?\n\n                                        \n(\nint\n)\nelf_entry\n \n:\n \n-\nEINVAL\n;\n\n                        \ngoto\n \nout_free_dentry\n;\n\n                \n}\n\n                \nreloc_func_desc\n \n=\n \ninterp_load_addr\n;\n\n\n                \nput_lego_file\n(\ninterpreter\n);\n\n                \nkfree\n(\nelf_interpreter\n);\n\n        \n}\n \nelse\n \n{\n\n        \n/* Statically-linked */\n\n                \n/*\n\n\n                 * e_entry is the VA to which the system first transfers control\n\n\n                 * Not the start_code! Normally, it is the \n_start\n function.\n\n\n                 */\n\n\n                \nelf_entry\n \n=\n \nloc\n-\nelf_ex\n.\ne_entry\n;\n\n\n                \nif\n \n(\nBAD_ADDR\n(\nelf_entry\n))\n \n{\n\n                        \nretval\n \n=\n \n-\nEINVAL\n;\n\n                        \ngoto\n \nout_free_dentry\n;\n\n                \n}\n\n        \n}\n\n        \n...\n\n\n}\n\n\n\n\n\n\n\nProcessor Manager\ns Job\n\n\nIt needs to flush old execution environment, and setup the new execution environment, such as signal, FPU. Notably, processor manager need to run \nflush_old_exec()\n, and \nsetup_new_exec()\n.\n\n\nDestroy old context: flush_old_exec()\n\n\nZap other threads\n\n\nde_thread\n is used to kill other threads within the same thread group, thus make sure this process has its own signal table. Furthermore, A \nexec\n starts a new thread group with the same TGID of the previous thread group, so we probably also need to switch PID if calling thread is not a leader.\n\n\nSwitch to new address space\n\n\nWe also need to release the old mm, and allocate a new mm. The new mm only has the high address kernel mapping established. Do note that in Lego, pgtable is used to emulate the processor cache:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\nstatic\n \nint\n \nexec_mmap\n(\nvoid\n)\n\n\n{\n\n        \nstruct\n \nmm_struct\n \n*\nnew_mm\n;\n\n        \nstruct\n \nmm_struct\n \n*\nold_mm\n;\n\n        \nstruct\n \ntask_struct\n \n*\ntsk\n;\n\n\n        \nnew_mm\n \n=\n \nmm_alloc\n();\n\n        \nif\n \n(\n!\nnew_mm\n)\n\n                \nreturn\n \n-\nENOMEM\n;\n\n\n        \ntsk\n \n=\n \ncurrent\n;\n\n        \nold_mm\n \n=\n \ncurrent\n-\nmm\n;\n\n        \nmm_release\n(\ntsk\n,\n \nold_mm\n);\n\n\n        \ntask_lock\n(\ntsk\n);\n\n        \ntsk\n-\nmm\n \n=\n \nnew_mm\n;\n\n        \ntsk\n-\nactive_mm\n \n=\n \nnew_mm\n;\n\n        \nactivate_mm\n(\nold_mm\n,\n \nnew_mm\n);\n\n        \ntask_unlock\n(\ntsk\n);\n\n\n        \nif\n \n(\nold_mm\n)\n\n                \nmmput\n(\nold_mm\n);\n\n        \nreturn\n \n0\n;\n\n\n}\n\n\n\n\n\n\nClear Architecture-Specific state\n\n\nThis is performed by \nflush_thread()\n, which is an architecture-specific callback. In x86, we need to clear FPU state, and reset TLS array:\n\n1\n2\n3\n4\n5\n6\n7\nvoid\n \nflush_thread\n(\nvoid\n)\n\n\n{\n\n        \nstruct\n \ntask_struct\n \n*\ntsk\n \n=\n \ncurrent\n;\n\n        \nmemset\n(\ntsk\n-\nthread\n.\ntls_array\n,\n \n0\n,\n \nsizeof\n(\ntsk\n-\nthread\n.\ntls_array\n));\n\n\n        \nfpu__clear\n(\ntsk\n-\nthread\n.\nfpu\n);\n\n\n}\n\n\n\n\n\n\nSetup new context: setup_new_exec()\n\n\nLego\ns \nsetup_new_exec()\n is quite different from Linux\ns default implementation. Lego moves several functions to memory component, like the \narch_pick_mmap_layout\n stuff. Thus, Lego only flush the signal handlers and reset the signal stack stuff:\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\nstatic\n \nvoid\n \nsetup_new_exec\n(\nconst\n \nchar\n \n*\nfilename\n)\n\n\n{\n\n        \n/* This is the point of no return */\n\n        \ncurrent\n-\nsas_ss_sp\n \n=\n \ncurrent\n-\nsas_ss_size\n \n=\n \n0\n;\n\n\n        \nset_task_comm\n(\ncurrent\n,\n \nkbasename\n(\nfilename\n));\n\n\n        \nflush_signal_handlers\n(\ncurrent\n,\n \n0\n);\n\n\n}\n\n\n\n\n\n\nChange return frame in stack\n\n\nWe do not return to user mode here, we simply replace the return IP of the regs frame. While the kernel thread returns, it will simply merge to syscall return path (check ret_from_fork() in entry.S for detail).\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n/**\n\n\n * start_thread - Starting a new user thread\n\n\n * @regs: pointer to pt_regs\n\n\n * @new_ip: the first instruction IP of user thread\n\n\n * @new_sp: the new stack pointer of user thread\n\n\n */\n\n\nvoid\n \nstart_thread\n(\nstruct\n \npt_regs\n \n*\nregs\n,\n \nunsigned\n \nlong\n \nnew_ip\n,\n\n                  \nunsigned\n \nlong\n \nnew_sp\n)\n\n\n{\n\n        \nloadsegment\n(\nfs\n,\n \n0\n);\n\n        \nloadsegment\n(\nes\n,\n \n0\n);\n\n        \nloadsegment\n(\nds\n,\n \n0\n);\n\n        \nload_gs_index\n(\n0\n);\n\n        \nregs\n-\nip\n                \n=\n \nnew_ip\n;\n\n        \nregs\n-\nsp\n                \n=\n \nnew_sp\n;\n\n        \nregs\n-\ncs\n                \n=\n \n__USER_CS\n;\n\n        \nregs\n-\nss\n                \n=\n \n__USER_DS\n;\n\n        \nregs\n-\nflags\n             \n=\n \nX86_EFLAGS_IF\n;\n\n\n}\n\n\n\n\n\n\nIf calling \nexecve()\n from userspace, the return frame is saved in the stack, we can simply do \nstart_thread\n above, and merge to syscall return path. However, if calling \nexecve()\n from a kernel thread, things changed. As you can see, all forked threads will run from \nret_from_fork\n when it wakes for the first time. If it is a kernel thread, it jumps to \nline 23\n, to execute the kernel function. Normally, the function should not return. If it does return, it normally has called an \nexecve()\n, and return frame has been changed by \nstart_thread()\n. So we jump to \nline 16\n to let it merge to syscall return path.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n/*\n\n \n*\n \nA\n \nnewly\n \nforked\n \nprocess\n \ndirectly\n \ncontext\n \nswitches\n \ninto\n \nthis\n \naddress.\n\n \n*\n\n \n*\n \nrax:\n \nprev\n \ntask\n \nwe\n \nswitched\n \nfrom\n\n \n*\n \nrbx:\n \nkernel\n \nthread\n \nfunc\n \n(\nNULL\n \nfor\n \nuser\n \nthread\n)\n\n \n*\n \nr12:\n \nkernel\n \nthread\n \narg\n\n \n*/\n\n\nENTRY\n(\nret_from_fork\n)\n\n        \nmovq\n    \n%rax\n,\n \n%rdi\n\n        \ncall\n    \nschedule_tail\n           \n/\n*\n \nrdi\n:\n \nprev\n \ntask\n \nparameter\n \n*\n/\n\n\n        \ntestq\n   \n%rbx\n,\n \n%rbx\n              \n/\n*\n \nfrom\n \nkernel_thread\n?\n \n*\n/\n\n        \njnz\n     \n1\nf\n                      \n/\n*\n \nkernel\n \nthreads\n \nare\n \nuncommon\n \n*\n/\n\n\n\n2:\n\n\n        \nmovq\n    \n%rsp\n,\n \n%rdi\n\n\n        \ncall\n    \nsyscall_return_slowpath\n \n/\n*\n \nreturn\n \nwith\n \nIRQs\n \ndisabled\n \n*\n/\n\n        \nSWAPGS\n                          \n/\n*\n \nswitch\n \nto\n \nuser\n \ngs.base\n \n*\n/\n\n        \njmp\n     \nrestore_regs_and_iret\n\n\n\n1:\n\n        \n/*\n \nkernel\n \nthread\n \n*\n/\n\n\n        \nmovq\n    \n%r12\n,\n \n%rdi\n\n\n        \ncall\n    \n*\n%rbx\n\n        \n/*\n  \n         \n*\n \nA\n \nkernel\n \nthread\n \nis\n \nallowed\n \nto\n \nreturn\n \nhere\n \nafter\n \nsuccessfully\n\n         \n*\n \ncalling\n \ndo_execve\n().\n  \nExit\n \nto\n \nuserspace\n \nto\n \ncomplete\n \nthe\n \nexecve\n()\n\n         \n*\n \nsyscall:\n\n         \n*/\n\n        \nmovq\n    \n$0\n,\n \nRAX\n(\n%rsp\n)\n\n        \njmp\n     \n2\nb\n  \n\nEND\n(\nret_from_fork\n)\n\n\n\n\n\n\n\nThis is such a typical control flow hijacking. :-)\n\n\nFeatures\n\n\nThis section lists various features, or behaviors and Lego\ns program loader.\n\n\n\n\nVirtual Address Space Range\n\n\nUser\ns virtual address falls into this range:\n\n1\n[sysctl_mmap_min_addr, TASK_SIZE)\n\n\n\n\n\nBy default,\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\nunsigned\n \nlong\n \nsysctl_mmap_min_addr\n \n=\n \nPAGE_SIZE\n;\n\n\n\n/*\n\n\n * User space process size. 47bits minus one guard page.  The guard\n\n\n * page is necessary on Intel CPUs: if a SYSCALL instruction is at\n\n\n * the highest possible canonical userspace address, then that\n\n\n * syscall will enter the kernel with a non-canonical return\n\n\n * address, and SYSRET will explode dangerously.  We avoid this\n\n\n * particular problem by preventing anything from being mapped\n\n\n * at the maximum canonical address.\n\n\n */\n                                                                                                       \n\n#define TASK_SIZE       ((1UL \n 47) - PAGE_SIZE)\n\n\n\n\n\n\nEssentially:\n\n1\n[0x1000, 0x7ffffffff000)\n\n\n\n\n\n\n\nPre-Populated \n.bss\n and \n.brk\n\n\nThe heap vma created at loading time is a combination of \n.bss\n and \n.brk\n segments. Since brk usage is 0 (will it be non-zero?) at this moment, so the heap vma is essentially just \n.bss\n pages. Normally, Linux kernel does not populate pages for this vma during loading, but Lego does. It can save several page allocation cost for heap pcache miss. It is controlled by \nvm_brk()\n.\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\nint\n \nvm_brk\n(\nstruct\n \nlego_task_struct\n \n*\ntsk\n,\n\n           \nunsigned\n \nlong\n \nstart\n,\n \nunsigned\n \nlong\n \nlen\n)\n\n\n{\n\n        \nint\n \nret\n;\n\n        \nstruct\n \nlego_mm_struct\n \n*\nmm\n \n=\n \ntsk\n-\nmm\n;\n\n\n        \nif\n \n(\ndown_write_killable\n(\nmm\n-\nmmap_sem\n))\n\n                \nreturn\n \n-\nEINTR\n;\n\n\n        \nret\n \n=\n \ndo_brk\n(\ntsk\n,\n \nstart\n,\n \nlen\n);\n\n        \nup_write\n(\nmm\n-\nmmap_sem\n);\n\n\n        \n/* Prepopulate brk pages */\n\n        \nif\n \n(\n!\nret\n)\n\n                \nlego_mm_populate\n(\nmm\n,\n \nstart\n,\n \nlen\n);\n\n\n        \nreturn\n \nret\n;\n\n\n}\n\n\n\n\n\n\n\n\nUn-Populated stack\n\n\nStack vma is manually expanded to \n32 pages + pages for argv info\n by loader to accommodate future usage. Only pages for argv are populated by default, the extra 32 pages are not. A typical program may need 1 page for saving argv info, plus the 32 extra, the layout will be:\n\n1\n7ffffffde000-7ffffffff000 rw-p 00000000 [stack]\n\n\n\n\n\nThe code to expand stack is done when ELF loader tries to finalize the stack vma, by calling \nsetup_arg_pages()\n:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\nint\n \nsetup_arg_pages\n(\nstruct\n \nlego_task_struct\n \n*\ntsk\n,\n \nstruct\n \nlego_binprm\n \n*\nbprm\n,\n\n                    \nunsigned\n \nlong\n \nstack_top\n,\n \nint\n \nexecutable_stack\n)\n\n\n{\n\n        \n...\n\n        \n/*\n\n\n         * 32*4k (or 2*64k) pages\n\n\n         */\n\n        \nstack_expand\n \n=\n \n131072UL\n;\n\n        \nstack_size\n \n=\n \nvma\n-\nvm_end\n \n-\n \nvma\n-\nvm_start\n;\n\n        \nstack_base\n \n=\n \nvma\n-\nvm_start\n \n-\n \nstack_expand\n;\n\n\n        \nmm\n-\nstart_stack\n \n=\n \nbprm\n-\np\n;\n\n        \nret\n \n=\n \nexpand_stack\n(\nvma\n,\n \nstack_base\n);\n\n        \n...\n\n\n}\n\n\n\n\n\n\n\n\nUn-Populated \n.text\n and \n.data\n\n\nIn essence, all PT_LOAD segments of ELF image are not pre-populated. They will be fetched from storage on demand. This is the traditional on-demand paging way. If we want to reduce the overhead of code and data\ns on-demand paging, we can prefault them in the future.\n\n\n\n\nDisabled Randomized Top of Stack\n\n\nLego currently does not randomize the stack top. The stack vma is allocated by \nbprm_mm_init()\n at early execve time. There is no randomization at the allocation time, and this applies to all exectuable formats. The end of vma is just \nTASK_SIZE\n:\n\n1\n2\n3\n4\n5\n6\n7\nstatic\n \nint\n \n__bprm_mm_init\n(\nstruct\n \nlego_binprm\n \n*\nbprm\n)\n\n\n{\n\n        \n...\n\n        \nvma\n-\nvm_end\n \n=\n \nTASK_SIZE\n;\n\n        \n...\n\n\n}\n\n\n(\nmanagers\n/\nmemory\n/\nloader\n/\nelf\n.\nc\n)\n\n\n\n\n\n\nTop of stack randomization happens within each specific format loader. They do this by calling back to virtual loader layer\ns \nsetup_arg_pages()\n function, which is used to finalize the top of stack:\n\n1\n2\nint\n \nsetup_arg_pages\n(\nstruct\n \nlego_task_struct\n \n*\ntsk\n,\n \nstruct\n \nlego_binprm\n \n*\nbprm\n,\n\n                    \nunsigned\n \nlong\n \nstack_top\n,\n \nint\n \nexecutable_stack\n);\n\n\n\n\n\n\nSo, to actually randomize the top of stack, you can simply do the following:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\nstatic\n \nunsigned\n \nlong\n \nrandomize_stack_top\n(\nunsigned\n \nlong\n \nstack_top\n)\n\n\n{\n                                \n        \nunsigned\n \nlong\n \nrandom_variable\n \n=\n \n0\n;\n\n\n        \nif\n \n((\ncurrent\n-\nflags\n \n \nPF_RANDOMIZE\n)\n \n\n                \n!\n(\ncurrent\n-\npersonality\n \n \nADDR_NO_RANDOMIZE\n))\n \n{\n\n                \nrandom_variable\n \n=\n \nget_random_long\n();\n\n                \nrandom_variable\n \n=\n \nSTACK_RND_MASK\n;\n\n                \nrandom_variable\n \n=\n \nPAGE_SHIFT\n;\n\n        \n}\n\n\n#ifdef CONFIG_STACK_GROWSUP\n\n        \nreturn\n \nPAGE_ALIGN\n(\nstack_top\n)\n \n+\n \nrandom_variable\n;\n\n\n#else           \n\n        \nreturn\n \nPAGE_ALIGN\n(\nstack_top\n)\n \n-\n \nrandom_variable\n;\n\n\n#endif\n\n\n}\n\n\n\nstatic\n \nint\n \nload_elf_binary\n(\nstruct\n \nlego_task_struct\n \n*\ntsk\n,\n \nstruct\n \nlego_binprm\n \n*\nbprm\n,\n\n                           \nu64\n \n*\nnew_ip\n,\n \nu64\n \n*\nnew_sp\n,\n \nunsigned\n \nlong\n \n*\nargv_len\n,\n \nunsigned\n \nlong\n \n*\nenvp_len\n)\n\n\n{\n\n        \n...\n\n        \nretval\n \n=\n \nsetup_arg_pages\n(\nbprm\n,\n \nrandomize_stack_top\n(\nTASK_SIZE\n),\n\n                                 \nexecutable_stack\n);\n\n        \n...\n\n\n}\n\n\n\n\n\n\nHowever, current Lego disables randomization by passing \nTASK_SIZE\n:\n\n1\n2\n3\n4\n5\n6\n7\n8\nstatic\n \nint\n \nload_elf_binary\n(\nstruct\n \nlego_task_struct\n \n*\ntsk\n,\n \nstruct\n \nlego_binprm\n \n*\nbprm\n,\n\n                           \nu64\n \n*\nnew_ip\n,\n \nu64\n \n*\nnew_sp\n,\n \nunsigned\n \nlong\n \n*\nargv_len\n,\n \nunsigned\n \nlong\n \n*\nenvp_len\n)\n\n\n{\n\n        \n...\n\n        \nretval\n \n=\n \nsetup_arg_pages\n(\ntsk\n,\n \nbprm\n,\n \nTASK_SIZE\n,\n \nexecutable_stack\n);\n\n        \n...\n\n\n}\n\n\n(\nmanagers\n/\nmemory\n/\nloader\n/\nelf\n.\nc\n)\n\n\n\n\n\n\n\n\nNo vDSO\n\n\nCurrently, Lego does not have \nvDSO\n support. There are not too many syscalls mapped in the vDSO, for \nx86-64\n:\n\n\n\n\nclock_gettime\n\n\ngetcpu\n\n\ngettimeofday\n\n\ntime\n\n\n\n\nThe reason to add it back is simple: if those syscalls are used \na lot\n and hurt overall performance. Do note that when we add it back, it will be different from the common design: vDSO \nmust\n be mapped at processor side, mapped in our emulated pgtable.\n\n\nBelow is the original part where loader maps vDSO:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\nstatic\n \nint\n \nload_elf_binary\n(\nstruct\n \nlego_task_struct\n \n*\ntsk\n,\n \nstruct\n \nlego_binprm\n \n*\nbprm\n,\n\n                           \nu64\n \n*\nnew_ip\n,\n \nu64\n \n*\nnew_sp\n,\n \nunsigned\n \nlong\n \n*\nargv_len\n,\n \nunsigned\n \nlong\n \n*\nenvp_len\n)\n\n\n{\n\n        \n...\n\n\n#ifdef ARCH_HAS_SETUP_ADDITIONAL_PAGES\n\n        \n/*\n\n\n         * TODO: vdso\n\n\n         * x86 can map vdso vma here\n\n\n         */\n\n\n#endif\n\n        \n...\n\n\n}\n\n\nmanagers\n/\nmemory\n/\nloader\n/\nelf\n.\nc\n\n\n\n\n\n\nFor lego, we should move it to processor right before \nstart_thread()\n:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\nint\n \ndo_execve\n(\nconst\n \nchar\n \n*\nfilename\n,\n\n              \nconst\n \nchar\n \n*\n \nconst\n \n*\nargv\n,\n\n              \nconst\n \nchar\n \n*\n \nconst\n \n*\nenvp\n)\n\n\n{\n\n        \n...\n\n        \n/* Should be here */\n\n\n        \nstart_thread\n(\nregs\n,\n \nnew_ip\n,\n \nnew_sp\n);\n\n        \n...\n\n\n}\n\n\n\n\n\n\nBesides, don\nt forget to report the \nvDSO\n address in the aux vector:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\nstatic\n \nint\n \ncreate_elf_tables\n(\nstruct\n \nlego_task_struct\n \n*\ntsk\n,\n \nstruct\n \nlego_binprm\n \n*\nbprm\n,\n\n                \nstruct\n \nelfhdr\n \n*\nexec\n,\n \nunsigned\n \nlong\n \nload_addr\n,\n \nunsigned\n \nlong\n \ninterp_load_addr\n,\n\n                \nunsigned\n \nlong\n \n*\nargv_len\n,\n \nunsigned\n \nlong\n \n*\nenvp_len\n)\n\n\n{\n\n        \n...\n\n\n#ifdef ARCH_DLINFO\n\n        \n/*\n\n\n         * ARCH_DLINFO must come first so PPC can do its special alignment of\n\n\n         * AUXV.\n\n\n         * update AT_VECTOR_SIZE_ARCH if the number of NEW_AUX_ENT() in\n\n\n         * ARCH_DLINFO changes\n\n\n         */\n\n        \nARCH_DLINFO\n;\n\n\n#endif\n\n        \n...\n\n\n}\n\n\n\n\n\n\n\nYizhou Shan\n\nCreated: Feb 16, 2018\n\nLast Updated: Feb 27, 2018", 
            "title": "Program Loader"
        }, 
        {
            "location": "/lego/kernel/loader/#lego-program-loader", 
            "text": "This document explains the high-level workflow of Lego s program loader, and how we change the normal loader to fit the disaggregated operating system model. Background on linking and loading is recommended.", 
            "title": "Lego Program Loader"
        }, 
        {
            "location": "/lego/kernel/loader/#status", 
            "text": "Formats  Supported      ELF (static-linked)     ELF (dynamic-linked)", 
            "title": "Status"
        }, 
        {
            "location": "/lego/kernel/loader/#overall", 
            "text": "In order to support different executable formats, Lego has a  virtual loader layer  above all specific formats, which is quite similar to  virtual file system . In Lego,  execve()  is divided into two parts:  1)  syscall hook at processor side,  2)  real loader at memory side. Combined together, they provide the same semantic of  execve()  as described in Linux man page. Also for the code, we divide the Linux implementation into parts. But our emulation model introduces several interesting workarounds.", 
            "title": "Overall"
        }, 
        {
            "location": "/lego/kernel/loader/#legos-loader", 
            "text": "Lego basically divide the Linux loader into two parts, one in memory manager and other in processor manager. Most dirty work is done by memory manager. Processor manager only needs to make sure the new execution has a fresh environment to start.", 
            "title": "Lego's Loader"
        }, 
        {
            "location": "/lego/kernel/loader/#entry-point", 
            "text": "So the normal entry point is  do_execve() . Above that, it can be invoked by syscall from user space, or from kernel space by calling  do_execve()  directly. There are not too many places that will call  do_execve  within kernel. One notable case is how kernel starts the  pid 1  user program. This happens after kernel finished all initialization. The code is: 1\n2\n3\n4\n5 static   int   run_init_process ( const   char   * init_filename )                                                      { \n         argv_init [ 0 ]   =   init_filename ; \n         return   do_execve ( init_filename ,   argv_init ,   envp_init );  }", 
            "title": "Entry Point"
        }, 
        {
            "location": "/lego/kernel/loader/#memory-managers-job", 
            "text": "Memory manager side will do most of the dirty loading work. It will parse the ELF image, create new VMAs based on ELF information. After that, it only pass  start_ip  and  start_stack  back to processor manager. Once processor manager starts running this new execution, pages will be fetched from memory component on demand.", 
            "title": "Memory Manager's Job"
        }, 
        {
            "location": "/lego/kernel/loader/#load-ld-linux", 
            "text": "For dynamically-linked images, kernel ELF loader needs to load the  ld-linux.so  as well. It will first try to map the  ld-linux.so  into this process s virtual address space. Furthermore, the first user instruction that will run is no longer  __libc_main_start , kernel will transfer the kernel to  ld-linux.so  instead. Thus, for a normal user program,  ld-linux.so  will load all the shared libraries before running glibc.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44 static   int   load_elf_binary ( struct   lego_task_struct   * tsk ,   struct   lego_binprm   * bprm , \n                            u64   * new_ip ,   u64   * new_sp ,   unsigned   long   * argv_len ,   unsigned   long   * envp_len )  { \n\n         ... \n         /* Dynamically-linked */ \n         if   ( elf_interpreter )   { \n                 unsigned   long   interp_map_addr   =   0 ;                   elf_entry   =   load_elf_interp ( tsk ,   loc - interp_elf_ex ,                                               interpreter , \n                                             interp_map_addr , \n                                             load_bias ,   interp_elf_phdata ); \n                 if   ( ! IS_ERR (( void   * ) elf_entry ))   { \n                         /*                           * load_elf_interp() returns relocation                           * adjustment                           */ \n                         interp_load_addr   =   elf_entry ; \n                         elf_entry   +=   loc - interp_elf_ex . e_entry ; \n                 } \n                 if   ( BAD_ADDR ( elf_entry ))   { \n                         retval   =   IS_ERR (( void   * ) elf_entry )   ? \n                                         ( int ) elf_entry   :   - EINVAL ; \n                         goto   out_free_dentry ; \n                 } \n                 reloc_func_desc   =   interp_load_addr ; \n\n                 put_lego_file ( interpreter ); \n                 kfree ( elf_interpreter ); \n         }   else   { \n         /* Statically-linked */ \n                 /*                   * e_entry is the VA to which the system first transfers control                   * Not the start_code! Normally, it is the  _start  function.                   */                   elf_entry   =   loc - elf_ex . e_entry ;                   if   ( BAD_ADDR ( elf_entry ))   { \n                         retval   =   - EINVAL ; \n                         goto   out_free_dentry ; \n                 } \n         } \n         ...  }", 
            "title": "Load ld-linux"
        }, 
        {
            "location": "/lego/kernel/loader/#processor-managers-job", 
            "text": "It needs to flush old execution environment, and setup the new execution environment, such as signal, FPU. Notably, processor manager need to run  flush_old_exec() , and  setup_new_exec() .", 
            "title": "Processor Manager's Job"
        }, 
        {
            "location": "/lego/kernel/loader/#destroy-old-context-flush_old_exec", 
            "text": "", 
            "title": "Destroy old context: flush_old_exec()"
        }, 
        {
            "location": "/lego/kernel/loader/#zap-other-threads", 
            "text": "de_thread  is used to kill other threads within the same thread group, thus make sure this process has its own signal table. Furthermore, A  exec  starts a new thread group with the same TGID of the previous thread group, so we probably also need to switch PID if calling thread is not a leader.", 
            "title": "Zap other threads"
        }, 
        {
            "location": "/lego/kernel/loader/#switch-to-new-address-space", 
            "text": "We also need to release the old mm, and allocate a new mm. The new mm only has the high address kernel mapping established. Do note that in Lego, pgtable is used to emulate the processor cache:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24 static   int   exec_mmap ( void )  { \n         struct   mm_struct   * new_mm ; \n         struct   mm_struct   * old_mm ; \n         struct   task_struct   * tsk ; \n\n         new_mm   =   mm_alloc (); \n         if   ( ! new_mm ) \n                 return   - ENOMEM ; \n\n         tsk   =   current ; \n         old_mm   =   current - mm ; \n         mm_release ( tsk ,   old_mm ); \n\n         task_lock ( tsk ); \n         tsk - mm   =   new_mm ; \n         tsk - active_mm   =   new_mm ; \n         activate_mm ( old_mm ,   new_mm ); \n         task_unlock ( tsk ); \n\n         if   ( old_mm ) \n                 mmput ( old_mm ); \n         return   0 ;  }", 
            "title": "Switch to new address space"
        }, 
        {
            "location": "/lego/kernel/loader/#clear-architecture-specific-state", 
            "text": "This is performed by  flush_thread() , which is an architecture-specific callback. In x86, we need to clear FPU state, and reset TLS array: 1\n2\n3\n4\n5\n6\n7 void   flush_thread ( void )  { \n         struct   task_struct   * tsk   =   current ; \n         memset ( tsk - thread . tls_array ,   0 ,   sizeof ( tsk - thread . tls_array )); \n\n         fpu__clear ( tsk - thread . fpu );  }", 
            "title": "Clear Architecture-Specific state"
        }, 
        {
            "location": "/lego/kernel/loader/#setup-new-context-setup_new_exec", 
            "text": "Lego s  setup_new_exec()  is quite different from Linux s default implementation. Lego moves several functions to memory component, like the  arch_pick_mmap_layout  stuff. Thus, Lego only flush the signal handlers and reset the signal stack stuff: 1\n2\n3\n4\n5\n6\n7\n8\n9 static   void   setup_new_exec ( const   char   * filename )  { \n         /* This is the point of no return */ \n         current - sas_ss_sp   =   current - sas_ss_size   =   0 ; \n\n         set_task_comm ( current ,   kbasename ( filename )); \n\n         flush_signal_handlers ( current ,   0 );  }", 
            "title": "Setup new context: setup_new_exec()"
        }, 
        {
            "location": "/lego/kernel/loader/#change-return-frame-in-stack", 
            "text": "We do not return to user mode here, we simply replace the return IP of the regs frame. While the kernel thread returns, it will simply merge to syscall return path (check ret_from_fork() in entry.S for detail).  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19 /**   * start_thread - Starting a new user thread   * @regs: pointer to pt_regs   * @new_ip: the first instruction IP of user thread   * @new_sp: the new stack pointer of user thread   */  void   start_thread ( struct   pt_regs   * regs ,   unsigned   long   new_ip , \n                   unsigned   long   new_sp )  { \n         loadsegment ( fs ,   0 ); \n         loadsegment ( es ,   0 ); \n         loadsegment ( ds ,   0 ); \n         load_gs_index ( 0 ); \n         regs - ip                  =   new_ip ; \n         regs - sp                  =   new_sp ; \n         regs - cs                  =   __USER_CS ; \n         regs - ss                  =   __USER_DS ; \n         regs - flags               =   X86_EFLAGS_IF ;  }    If calling  execve()  from userspace, the return frame is saved in the stack, we can simply do  start_thread  above, and merge to syscall return path. However, if calling  execve()  from a kernel thread, things changed. As you can see, all forked threads will run from  ret_from_fork  when it wakes for the first time. If it is a kernel thread, it jumps to  line 23 , to execute the kernel function. Normally, the function should not return. If it does return, it normally has called an  execve() , and return frame has been changed by  start_thread() . So we jump to  line 16  to let it merge to syscall return path.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32 /* \n  *   A   newly   forked   process   directly   context   switches   into   this   address. \n  * \n  *   rax:   prev   task   we   switched   from \n  *   rbx:   kernel   thread   func   ( NULL   for   user   thread ) \n  *   r12:   kernel   thread   arg \n  */  ENTRY ( ret_from_fork ) \n         movq      %rax ,   %rdi \n         call      schedule_tail             / *   rdi :   prev   task   parameter   * / \n\n         testq     %rbx ,   %rbx                / *   from   kernel_thread ?   * / \n         jnz       1 f                        / *   kernel   threads   are   uncommon   * /  2:           movq      %rsp ,   %rdi           call      syscall_return_slowpath   / *   return   with   IRQs   disabled   * / \n         SWAPGS                            / *   switch   to   user   gs.base   * / \n         jmp       restore_regs_and_iret  1: \n         /*   kernel   thread   * /           movq      %r12 ,   %rdi           call      * %rbx \n         /*   \n          *   A   kernel   thread   is   allowed   to   return   here   after   successfully \n          *   calling   do_execve ().    Exit   to   userspace   to   complete   the   execve () \n          *   syscall: \n          */ \n         movq      $0 ,   RAX ( %rsp ) \n         jmp       2 b    END ( ret_from_fork )    This is such a typical control flow hijacking. :-)", 
            "title": "Change return frame in stack"
        }, 
        {
            "location": "/lego/kernel/loader/#features", 
            "text": "This section lists various features, or behaviors and Lego s program loader.", 
            "title": "Features"
        }, 
        {
            "location": "/lego/kernel/loader/#virtual-address-space-range", 
            "text": "User s virtual address falls into this range: 1 [sysctl_mmap_min_addr, TASK_SIZE)   By default,  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12 unsigned   long   sysctl_mmap_min_addr   =   PAGE_SIZE ;  /*   * User space process size. 47bits minus one guard page.  The guard   * page is necessary on Intel CPUs: if a SYSCALL instruction is at   * the highest possible canonical userspace address, then that   * syscall will enter the kernel with a non-canonical return   * address, and SYSRET will explode dangerously.  We avoid this   * particular problem by preventing anything from being mapped   * at the maximum canonical address.   */                                                                                                         #define TASK_SIZE       ((1UL   47) - PAGE_SIZE)    Essentially: 1 [0x1000, 0x7ffffffff000)", 
            "title": "Virtual Address Space Range"
        }, 
        {
            "location": "/lego/kernel/loader/#pre-populated-bss-and-brk", 
            "text": "The heap vma created at loading time is a combination of  .bss  and  .brk  segments. Since brk usage is 0 (will it be non-zero?) at this moment, so the heap vma is essentially just  .bss  pages. Normally, Linux kernel does not populate pages for this vma during loading, but Lego does. It can save several page allocation cost for heap pcache miss. It is controlled by  vm_brk() .  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18 int   vm_brk ( struct   lego_task_struct   * tsk , \n            unsigned   long   start ,   unsigned   long   len )  { \n         int   ret ; \n         struct   lego_mm_struct   * mm   =   tsk - mm ; \n\n         if   ( down_write_killable ( mm - mmap_sem )) \n                 return   - EINTR ; \n\n         ret   =   do_brk ( tsk ,   start ,   len ); \n         up_write ( mm - mmap_sem ); \n\n         /* Prepopulate brk pages */ \n         if   ( ! ret ) \n                 lego_mm_populate ( mm ,   start ,   len ); \n\n         return   ret ;  }", 
            "title": "Pre-Populated .bss and .brk"
        }, 
        {
            "location": "/lego/kernel/loader/#un-populated-stack", 
            "text": "Stack vma is manually expanded to  32 pages + pages for argv info  by loader to accommodate future usage. Only pages for argv are populated by default, the extra 32 pages are not. A typical program may need 1 page for saving argv info, plus the 32 extra, the layout will be: 1 7ffffffde000-7ffffffff000 rw-p 00000000 [stack]   The code to expand stack is done when ELF loader tries to finalize the stack vma, by calling  setup_arg_pages() :  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15 int   setup_arg_pages ( struct   lego_task_struct   * tsk ,   struct   lego_binprm   * bprm , \n                     unsigned   long   stack_top ,   int   executable_stack )  { \n         ... \n         /*           * 32*4k (or 2*64k) pages           */ \n         stack_expand   =   131072UL ; \n         stack_size   =   vma - vm_end   -   vma - vm_start ; \n         stack_base   =   vma - vm_start   -   stack_expand ; \n\n         mm - start_stack   =   bprm - p ; \n         ret   =   expand_stack ( vma ,   stack_base ); \n         ...  }", 
            "title": "Un-Populated stack"
        }, 
        {
            "location": "/lego/kernel/loader/#un-populated-text-and-data", 
            "text": "In essence, all PT_LOAD segments of ELF image are not pre-populated. They will be fetched from storage on demand. This is the traditional on-demand paging way. If we want to reduce the overhead of code and data s on-demand paging, we can prefault them in the future.", 
            "title": "Un-Populated .text and .data"
        }, 
        {
            "location": "/lego/kernel/loader/#disabled-randomized-top-of-stack", 
            "text": "Lego currently does not randomize the stack top. The stack vma is allocated by  bprm_mm_init()  at early execve time. There is no randomization at the allocation time, and this applies to all exectuable formats. The end of vma is just  TASK_SIZE : 1\n2\n3\n4\n5\n6\n7 static   int   __bprm_mm_init ( struct   lego_binprm   * bprm )  { \n         ... \n         vma - vm_end   =   TASK_SIZE ; \n         ...  }  ( managers / memory / loader / elf . c )    Top of stack randomization happens within each specific format loader. They do this by calling back to virtual loader layer s  setup_arg_pages()  function, which is used to finalize the top of stack: 1\n2 int   setup_arg_pages ( struct   lego_task_struct   * tsk ,   struct   lego_binprm   * bprm , \n                     unsigned   long   stack_top ,   int   executable_stack );    So, to actually randomize the top of stack, you can simply do the following:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25 static   unsigned   long   randomize_stack_top ( unsigned   long   stack_top )  {                                 \n         unsigned   long   random_variable   =   0 ; \n\n         if   (( current - flags     PF_RANDOMIZE )   \n                 ! ( current - personality     ADDR_NO_RANDOMIZE ))   { \n                 random_variable   =   get_random_long (); \n                 random_variable   =   STACK_RND_MASK ; \n                 random_variable   =   PAGE_SHIFT ; \n         }  #ifdef CONFIG_STACK_GROWSUP \n         return   PAGE_ALIGN ( stack_top )   +   random_variable ;  #else            \n         return   PAGE_ALIGN ( stack_top )   -   random_variable ;  #endif  }  static   int   load_elf_binary ( struct   lego_task_struct   * tsk ,   struct   lego_binprm   * bprm , \n                            u64   * new_ip ,   u64   * new_sp ,   unsigned   long   * argv_len ,   unsigned   long   * envp_len )  { \n         ... \n         retval   =   setup_arg_pages ( bprm ,   randomize_stack_top ( TASK_SIZE ), \n                                  executable_stack ); \n         ...  }    However, current Lego disables randomization by passing  TASK_SIZE : 1\n2\n3\n4\n5\n6\n7\n8 static   int   load_elf_binary ( struct   lego_task_struct   * tsk ,   struct   lego_binprm   * bprm , \n                            u64   * new_ip ,   u64   * new_sp ,   unsigned   long   * argv_len ,   unsigned   long   * envp_len )  { \n         ... \n         retval   =   setup_arg_pages ( tsk ,   bprm ,   TASK_SIZE ,   executable_stack ); \n         ...  }  ( managers / memory / loader / elf . c )", 
            "title": "Disabled Randomized Top of Stack"
        }, 
        {
            "location": "/lego/kernel/loader/#no-vdso", 
            "text": "Currently, Lego does not have  vDSO  support. There are not too many syscalls mapped in the vDSO, for  x86-64 :   clock_gettime  getcpu  gettimeofday  time   The reason to add it back is simple: if those syscalls are used  a lot  and hurt overall performance. Do note that when we add it back, it will be different from the common design: vDSO  must  be mapped at processor side, mapped in our emulated pgtable.  Below is the original part where loader maps vDSO:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 static   int   load_elf_binary ( struct   lego_task_struct   * tsk ,   struct   lego_binprm   * bprm , \n                            u64   * new_ip ,   u64   * new_sp ,   unsigned   long   * argv_len ,   unsigned   long   * envp_len )  { \n         ...  #ifdef ARCH_HAS_SETUP_ADDITIONAL_PAGES \n         /*           * TODO: vdso           * x86 can map vdso vma here           */  #endif \n         ...  }  managers / memory / loader / elf . c    For lego, we should move it to processor right before  start_thread() :  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 int   do_execve ( const   char   * filename , \n               const   char   *   const   * argv , \n               const   char   *   const   * envp )  { \n         ... \n         /* Should be here */ \n\n         start_thread ( regs ,   new_ip ,   new_sp ); \n         ...  }    Besides, don t forget to report the  vDSO  address in the aux vector:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16 static   int   create_elf_tables ( struct   lego_task_struct   * tsk ,   struct   lego_binprm   * bprm , \n                 struct   elfhdr   * exec ,   unsigned   long   load_addr ,   unsigned   long   interp_load_addr , \n                 unsigned   long   * argv_len ,   unsigned   long   * envp_len )  { \n         ...  #ifdef ARCH_DLINFO \n         /*           * ARCH_DLINFO must come first so PPC can do its special alignment of           * AUXV.           * update AT_VECTOR_SIZE_ARCH if the number of NEW_AUX_ENT() in           * ARCH_DLINFO changes           */ \n         ARCH_DLINFO ;  #endif \n         ...  }    \nYizhou Shan \nCreated: Feb 16, 2018 \nLast Updated: Feb 27, 2018", 
            "title": "No vDSO"
        }, 
        {
            "location": "/lego/kernel/vfs/", 
            "text": "Processor Manager\ns Virtual File System\n\n\nLego processor manager has an virtual file system layer to accommodate the famous legacy \nEverything is a file\n philosophy. But we implement this in a very dirty way.\n\n\nCover later.\n\n\n\nYizhou Shan\n\nCreated: Feb 20, 2018\n\nLast Updated: Feb 20, 2018", 
            "title": "Virtual File System"
        }, 
        {
            "location": "/lego/kernel/vfs/#processor-managers-virtual-file-system", 
            "text": "Lego processor manager has an virtual file system layer to accommodate the famous legacy  Everything is a file  philosophy. But we implement this in a very dirty way.  Cover later.  \nYizhou Shan \nCreated: Feb 20, 2018 \nLast Updated: Feb 20, 2018", 
            "title": "Processor Manager's Virtual File System"
        }, 
        {
            "location": "/lego/kernel/vm/", 
            "text": "Process Virtual Memory\n\n\nLimits\n\n\nMax Number of VMAs\n\n\nBy default, the maximum number of VMAs is: \n65530\n. It is defined by the following variable:\n\n1\n2\n3\n4\n#define MAPCOUNT_ELF_CORE_MARGIN        (5)\n\n\n#define DEFAULT_MAX_MAP_COUNT   (USHRT_MAX - MAPCOUNT_ELF_CORE_MARGIN)\n\n\n\nint\n \nsysctl_max_map_count\n \n__read_mostly\n \n=\n \nDEFAULT_MAX_MAP_COUNT\n;\n\n\n\n\n\n\nFacts\n\n\nmunmap\n can split vma\n\n\nmunmap\n can create a hole with an existing vma, thus divide one existing vma to two new vmas. Do note that, \nmunmap\n can create hole for both anonymous vma \nand\n file-backed vma.\n\n\nmsync()\n is not atomic\n\n\nDuring \nmsync()\n, pages are being written back to disk one by one (or batched). Consider the case where few pages have been flushed back, while some other few pages are still in the memory. This premature writeback is not atomic and will be affected by failure.\u000b\u000b\n\n\nmsync()\n need concurrency control\n\n\nWith a multi-threaded application, does msync() provide the synchronization semantic? The answer is NO. Other threads within the same process are able to write to pages currently under \nmsync()\n. This implies that application need to handle concurrency by themselves, e.g., rwlocks.\n\n\n\nYizhou Shan\n\nCreated: Feb 19, 2018\n\nLast Updated: Feb 19, 2018", 
            "title": "Process Virtual Memory"
        }, 
        {
            "location": "/lego/kernel/vm/#process-virtual-memory", 
            "text": "", 
            "title": "Process Virtual Memory"
        }, 
        {
            "location": "/lego/kernel/vm/#limits", 
            "text": "", 
            "title": "Limits"
        }, 
        {
            "location": "/lego/kernel/vm/#max-number-of-vmas", 
            "text": "By default, the maximum number of VMAs is:  65530 . It is defined by the following variable: 1\n2\n3\n4 #define MAPCOUNT_ELF_CORE_MARGIN        (5)  #define DEFAULT_MAX_MAP_COUNT   (USHRT_MAX - MAPCOUNT_ELF_CORE_MARGIN)  int   sysctl_max_map_count   __read_mostly   =   DEFAULT_MAX_MAP_COUNT ;", 
            "title": "Max Number of VMAs"
        }, 
        {
            "location": "/lego/kernel/vm/#facts", 
            "text": "", 
            "title": "Facts"
        }, 
        {
            "location": "/lego/kernel/vm/#munmap-can-split-vma", 
            "text": "munmap  can create a hole with an existing vma, thus divide one existing vma to two new vmas. Do note that,  munmap  can create hole for both anonymous vma  and  file-backed vma.", 
            "title": "munmap can split vma"
        }, 
        {
            "location": "/lego/kernel/vm/#msync-is-not-atomic", 
            "text": "During  msync() , pages are being written back to disk one by one (or batched). Consider the case where few pages have been flushed back, while some other few pages are still in the memory. This premature writeback is not atomic and will be affected by failure.", 
            "title": "msync() is not atomic"
        }, 
        {
            "location": "/lego/kernel/vm/#msync-need-concurrency-control", 
            "text": "With a multi-threaded application, does msync() provide the synchronization semantic? The answer is NO. Other threads within the same process are able to write to pages currently under  msync() . This implies that application need to handle concurrency by themselves, e.g., rwlocks.  \nYizhou Shan \nCreated: Feb 19, 2018 \nLast Updated: Feb 19, 2018", 
            "title": "msync() need concurrency control"
        }, 
        {
            "location": "/lego/kernel/fpu/", 
            "text": "x86 Floating Point Unit\n\n\nThis is not a document about the FPU technology, this is just a simple note on FPU code and my debugging lesson.\n\n\nFPU is heavily used by user level code. You may not use it directly, but glibc library is using it a lot, e.g. the \nstrcmp\n function. x86 FPU is really another complex thing designed by Intel. Of course its performance is good and widely used, but the legacy compatible feature? Hmm.\n\n\nI would say, without Ingo Molnar\ns \nx86 FPU code rewrite\n, there is no way for me to easily understand it. The current x86 FPU code is well-written. Even though I don\nt quite understand what and why the code is, but I enjoy reading it. The naming convention, the code organization, the file organization, the header files, it is a nice piece of art.\n\n\nAnyway, Lego ported this low-level FPU code from Linux without any change. The porting is painful because it requires a lot other related features. And it also deals with compatible syscalls a little bit. Below I will just briefly list other subsystems that are using FPU, and talk about my thoughts.\n\n\nBoot\n\n\nFPU detection and init happen during early boot. You should know the \nstruct fpu\n is a dynamically-sized structure. The size of it depends on what features the underlying CPU support. Since \nstruct fpu\n is part of \ntask_struct\n, that implies \ntask_struct\n is dynamically-sized too. Apparently, \ncpu_init()\n will also callback to init its local FPU.\n\n\nContext Switch\n\n\nFPU consists a lot registers, and each thread has its own FPU context. However, CPU will not save the FPU registers for us, it is software\ns duty to save and restore FPU context properly. FPU context is saved in \nstruct fpu\n.\n\n\nThus whenever we switch task, we also need to switch FPU context:\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n__visible\n \nstruct\n \ntask_struct\n \n*\n\n\n__switch_to\n(\nstruct\n \ntask_struct\n \n*\nprev_p\n,\n \nstruct\n \ntask_struct\n \n*\nnext_p\n)\n\n\n{\n\n        \n..\n\n        \nfpu_switch\n \n=\n \nswitch_fpu_prepare\n(\nprev_fpu\n,\n \nnext_fpu\n,\n \ncpu\n);\n\n        \n..\n\n        \nswitch_fpu_finish\n(\nnext_fpu\n,\n \nfpu_switch\n);\n\n        \n..\n\n\n}\n\n\n\n\n\n\nSYSCALL\n\n\n\n\n\n\nfork() and clone(): When a new thread or process is created, the FPU context is copied from the calling thread.\n\n\n\n\n\n\nexecve(): When \nexecve()\n is called, the FPU context will be cleared.\n\n\n\n\n\n\nexit(): When a thread exit,, FPU will do cleanup based on if \neagerfpu\n or \nlazyfpu\n is used.\n\n\n\n\n\n\nExceptions\n\n\nLike the \ndevice not available\n exception, which may be triggered if lazyfpu is used. Also, \ndo_simd_exception\n and \ndo_coprocessor_error\n, which are some math related exceptions.\n\n\nSignal\n\n\nKernel needs to setup a \nsigframe\n for user level signal handlers. \nsigframe\n is a contiguous stack memory consists the general purpose registers and FPU registers. So signal handling part will also call back to FPU to setup and copy the FPU registers to \nsigframe\n in stack.\n\n\nThoughts\n\n\nI\nve been debugging this FPU introduced bugs for over a month. And during this month, I\nm always not sure if it is FPU\ns bug, or some other code that corrupts memory. So I\nm lazy to re-port FPU again. But after rule out every other possibilities, I turned back to FPU. At first I did not port all FPU code, cause I don\nt think I need all of it.\n\n\nOne stupid thing is I forgot to turn on DEBUG_FPU, which should help me in the first place. I kind of lost myself in various engineering work during this debugging. I really need some big context switch in the middle to fresh my mind. Anyway, glad it is all done today (Feb 23), and I\nm able to move to next stage.\n\n\nCompatibility is a heavy thing to carry. But it is also a nice thing for marketing. No one can deny the success of Intel on its backward compatibility. Bad for programmers.\n\n\n\nYizhou Shan\n\nCreated: Feb 22, 2018\n\nLast Updated: Feb 23, 2018", 
            "title": "x86 FPU"
        }, 
        {
            "location": "/lego/kernel/fpu/#x86-floating-point-unit", 
            "text": "This is not a document about the FPU technology, this is just a simple note on FPU code and my debugging lesson.  FPU is heavily used by user level code. You may not use it directly, but glibc library is using it a lot, e.g. the  strcmp  function. x86 FPU is really another complex thing designed by Intel. Of course its performance is good and widely used, but the legacy compatible feature? Hmm.  I would say, without Ingo Molnar s  x86 FPU code rewrite , there is no way for me to easily understand it. The current x86 FPU code is well-written. Even though I don t quite understand what and why the code is, but I enjoy reading it. The naming convention, the code organization, the file organization, the header files, it is a nice piece of art.  Anyway, Lego ported this low-level FPU code from Linux without any change. The porting is painful because it requires a lot other related features. And it also deals with compatible syscalls a little bit. Below I will just briefly list other subsystems that are using FPU, and talk about my thoughts.", 
            "title": "x86 Floating Point Unit"
        }, 
        {
            "location": "/lego/kernel/fpu/#boot", 
            "text": "FPU detection and init happen during early boot. You should know the  struct fpu  is a dynamically-sized structure. The size of it depends on what features the underlying CPU support. Since  struct fpu  is part of  task_struct , that implies  task_struct  is dynamically-sized too. Apparently,  cpu_init()  will also callback to init its local FPU.", 
            "title": "Boot"
        }, 
        {
            "location": "/lego/kernel/fpu/#context-switch", 
            "text": "FPU consists a lot registers, and each thread has its own FPU context. However, CPU will not save the FPU registers for us, it is software s duty to save and restore FPU context properly. FPU context is saved in  struct fpu .  Thus whenever we switch task, we also need to switch FPU context: 1\n2\n3\n4\n5\n6\n7\n8\n9 __visible   struct   task_struct   *  __switch_to ( struct   task_struct   * prev_p ,   struct   task_struct   * next_p )  { \n         .. \n         fpu_switch   =   switch_fpu_prepare ( prev_fpu ,   next_fpu ,   cpu ); \n         .. \n         switch_fpu_finish ( next_fpu ,   fpu_switch ); \n         ..  }", 
            "title": "Context Switch"
        }, 
        {
            "location": "/lego/kernel/fpu/#syscall", 
            "text": "fork() and clone(): When a new thread or process is created, the FPU context is copied from the calling thread.    execve(): When  execve()  is called, the FPU context will be cleared.    exit(): When a thread exit,, FPU will do cleanup based on if  eagerfpu  or  lazyfpu  is used.", 
            "title": "SYSCALL"
        }, 
        {
            "location": "/lego/kernel/fpu/#exceptions", 
            "text": "Like the  device not available  exception, which may be triggered if lazyfpu is used. Also,  do_simd_exception  and  do_coprocessor_error , which are some math related exceptions.", 
            "title": "Exceptions"
        }, 
        {
            "location": "/lego/kernel/fpu/#signal", 
            "text": "Kernel needs to setup a  sigframe  for user level signal handlers.  sigframe  is a contiguous stack memory consists the general purpose registers and FPU registers. So signal handling part will also call back to FPU to setup and copy the FPU registers to  sigframe  in stack.", 
            "title": "Signal"
        }, 
        {
            "location": "/lego/kernel/fpu/#thoughts", 
            "text": "I ve been debugging this FPU introduced bugs for over a month. And during this month, I m always not sure if it is FPU s bug, or some other code that corrupts memory. So I m lazy to re-port FPU again. But after rule out every other possibilities, I turned back to FPU. At first I did not port all FPU code, cause I don t think I need all of it.  One stupid thing is I forgot to turn on DEBUG_FPU, which should help me in the first place. I kind of lost myself in various engineering work during this debugging. I really need some big context switch in the middle to fresh my mind. Anyway, glad it is all done today (Feb 23), and I m able to move to next stage.  Compatibility is a heavy thing to carry. But it is also a nice thing for marketing. No one can deny the success of Intel on its backward compatibility. Bad for programmers.  \nYizhou Shan \nCreated: Feb 22, 2018 \nLast Updated: Feb 23, 2018", 
            "title": "Thoughts"
        }, 
        {
            "location": "/lego/syscall/facts/", 
            "text": "Lego SYSCALL Facts\n\n\nThis document is about the general concepts of Lego syscall implementation. If you are developing syscall, please read this document first.\n\n\nInterrupts Enabled\n\n\nEach syscall is invoked with interrupts enabled. Also, it must return with interrupts enabled as well. Any buggy syscall implementation will be catched by \nsyscall_return_slowpath()\n:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\nvoid\n \nsyscall_return_slowpath\n(\nstruct\n \npt_regs\n \n*\nregs\n)\n\n\n{\n\n        \nif\n \n(\nWARN\n(\nirqs_disabled\n(),\n \nsyscall %ld left IRQs disabled\n,\n \nregs\n-\norig_ax\n))\n\n                \nlocal_irq_enable\n();\n\n\n        \nlocal_irq_disable\n();\n\n        \nprepare_exit_to_usermode\n(\nregs\n);\n\n\n}\n\n\n\nvoid\n \ndo_syscall_64\n(\nstruct\n \npt_regs\n \n*\nregs\n)\n\n\n{\n\n        \n..\n\n        \nlocal_irq_enable\n();\n\n\n        \nif\n \n(\nlikely\n(\nnr\n \n \nNR_syscalls\n))\n \n{\n\n                \nregs\n-\nax\n \n=\n \nsys_call_table\n[\nnr\n](\n\n                        \nregs\n-\ndi\n,\n \nregs\n-\nsi\n,\n \nregs\n-\ndx\n,\n\n                        \nregs\n-\nr10\n,\n \nregs\n-\nr8\n,\n \nregs\n-\nr9\n);\n\n        \n}\n   \n\n        \nsyscall_return_slowpath\n(\nregs\n);\n\n        \n..\n\n\n}\n\n\n\n\n\n\nGet User Entry pt_regs\n\n\nThe macro \ntask_pt_regs()\n always return the \npt_regs\n, that saves the user context when it issued the syscall, no matter how many levels interrupts are nested when you call \ntask_pt_regs()\n. This is based on the fact that kernel stack is empty at syscall entry, thus this user \npt_regs\n was saved at the \ntop\n of kernel stack:\n\n1\n#define task_pt_regs(tsk)       ((struct pt_regs *)(tsk)-\nthread.sp0 - 1)\n\n\n\n\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\nENTRY\n(\nentry_SYSCALL_64\n)\n\n        \nSWAPGS\n\n\n        \n/*\n\n         \n*\n \nSYSCALL\n \ndoes\n \nnot\n \nchange\n \nrsp\n \nfor\n \nus\n!\n\n         \n*\n \nSave\n \nthe\n \nprevious\n \nrsp\n \nand\n \nload\n \nthe\n \ntop\n \nof\n \nkernel\n \nstack.\n\n         \n*\n \nIt\n \nmust\n \nbe\n \nthe\n \ntop\n \nof\n \nkernel\n \nstack\n,\n \nsince\n \nwe\n \ncame\n \nhere\n\n         \n*\n \nfrom\n \n*\nuserspace\n*.\n\n         \n*/\n\n        \nmovq\n    \n%rsp\n,\n \nPER_CPU_VAR\n(\nrsp_scratch\n)\n\n        \nmovq\n    \nPER_CPU_VAR\n(\ncpu_current_top_of_stack\n),\n \n%rsp\n\n\n        \n/*\n\n         \n*\n \nConstruct\n \nstruct\n \npt_regs\n \non\n \nstack\n\n         \n*\n\n         \n*\n \nIn\n \nany\n \nsyscall\n \nhandler\n,\n \nyou\n \ncan\n \nuse\n\n         \n*\n      \ncurrent_pt_regs\n()\n\n         \n*\n \nto\n \nget\n \nthese\n \nregisters.\n\n         \n*/\n\n        \npushq\n   \n$__USER_DS\n                      \n/\n*\n \npt_regs-\nss\n \n*\n/\n\n        \npushq\n   \nPER_CPU_VAR\n(\nrsp_scratch\n)\n        \n/\n*\n \npt_regs-\nsp\n \n*\n/\n\n        \npushq\n   \n%r11\n                            \n/\n*\n \npt_regs-\nflags\n \n*\n/\n\n        \npushq\n   \n$__USER_CS\n                      \n/\n*\n \npt_regs-\ncs\n \n*\n/\n\n        \npushq\n   \n%rcx\n                            \n/\n*\n \npt_regs-\nip\n \n*\n/\n\n        \npushq\n   \n%rax\n                            \n/\n*\n \npt_regs-\norig_ax\n \n*\n/\n\n        \npushq\n   \n%rdi\n                            \n/\n*\n \npt_regs-\ndi\n \n*\n/\n\n        \npushq\n   \n%rsi\n                            \n/\n*\n \npt_regs-\nsi\n \n*\n/\n\n        \npushq\n   \n%rdx\n                            \n/\n*\n \npt_regs-\ndx\n \n*\n/\n\n        \npushq\n   \n%rcx\n                            \n/\n*\n \npt_regs-\ncx\n \n*\n/\n\n        \npushq\n   \n$-ENOSYS\n                        \n/\n*\n \npt_regs-\nax\n \n*\n/\n\n        \npushq\n   \n%r8\n                             \n/\n*\n \npt_regs-\nr8\n \n*\n/\n\n        \npushq\n   \n%r9\n                             \n/\n*\n \npt_regs-\nr9\n \n*\n/\n\n        \npushq\n   \n%r10\n                            \n/\n*\n \npt_regs-\nr10\n \n*\n/\n\n        \npushq\n   \n%r11\n                            \n/\n*\n \npt_regs-\nr11\n \n*\n/\n\n        \nsub\n     \n$\n(\n6\n*\n8\n),\n \n%rsp\n                    \n/\n*\n \npt_regs-\nbp\n,\n \nbx\n,\n \nr12-15\n \n*\n/\n\n        \n....\n\n\n\n\n\n\n\nYizhou Shan\n\nCreated: Feb 22, 2018\n\nLast Updated: Feb 22, 2018", 
            "title": "Facts"
        }, 
        {
            "location": "/lego/syscall/facts/#lego-syscall-facts", 
            "text": "This document is about the general concepts of Lego syscall implementation. If you are developing syscall, please read this document first.", 
            "title": "Lego SYSCALL Facts"
        }, 
        {
            "location": "/lego/syscall/facts/#interrupts-enabled", 
            "text": "Each syscall is invoked with interrupts enabled. Also, it must return with interrupts enabled as well. Any buggy syscall implementation will be catched by  syscall_return_slowpath() :  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23 void   syscall_return_slowpath ( struct   pt_regs   * regs )  { \n         if   ( WARN ( irqs_disabled (),   syscall %ld left IRQs disabled ,   regs - orig_ax )) \n                 local_irq_enable (); \n\n         local_irq_disable (); \n         prepare_exit_to_usermode ( regs );  }  void   do_syscall_64 ( struct   pt_regs   * regs )  { \n         .. \n         local_irq_enable (); \n\n         if   ( likely ( nr     NR_syscalls ))   { \n                 regs - ax   =   sys_call_table [ nr ]( \n                         regs - di ,   regs - si ,   regs - dx , \n                         regs - r10 ,   regs - r8 ,   regs - r9 ); \n         }    \n\n         syscall_return_slowpath ( regs ); \n         ..  }", 
            "title": "Interrupts Enabled"
        }, 
        {
            "location": "/lego/syscall/facts/#get-user-entry-pt_regs", 
            "text": "The macro  task_pt_regs()  always return the  pt_regs , that saves the user context when it issued the syscall, no matter how many levels interrupts are nested when you call  task_pt_regs() . This is based on the fact that kernel stack is empty at syscall entry, thus this user  pt_regs  was saved at the  top  of kernel stack: 1 #define task_pt_regs(tsk)       ((struct pt_regs *)(tsk)- thread.sp0 - 1)     1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36 ENTRY ( entry_SYSCALL_64 ) \n         SWAPGS \n\n         /* \n          *   SYSCALL   does   not   change   rsp   for   us ! \n          *   Save   the   previous   rsp   and   load   the   top   of   kernel   stack. \n          *   It   must   be   the   top   of   kernel   stack ,   since   we   came   here \n          *   from   * userspace *. \n          */ \n         movq      %rsp ,   PER_CPU_VAR ( rsp_scratch ) \n         movq      PER_CPU_VAR ( cpu_current_top_of_stack ),   %rsp \n\n         /* \n          *   Construct   struct   pt_regs   on   stack \n          * \n          *   In   any   syscall   handler ,   you   can   use \n          *        current_pt_regs () \n          *   to   get   these   registers. \n          */ \n         pushq     $__USER_DS                        / *   pt_regs- ss   * / \n         pushq     PER_CPU_VAR ( rsp_scratch )          / *   pt_regs- sp   * / \n         pushq     %r11                              / *   pt_regs- flags   * / \n         pushq     $__USER_CS                        / *   pt_regs- cs   * / \n         pushq     %rcx                              / *   pt_regs- ip   * / \n         pushq     %rax                              / *   pt_regs- orig_ax   * / \n         pushq     %rdi                              / *   pt_regs- di   * / \n         pushq     %rsi                              / *   pt_regs- si   * / \n         pushq     %rdx                              / *   pt_regs- dx   * / \n         pushq     %rcx                              / *   pt_regs- cx   * / \n         pushq     $-ENOSYS                          / *   pt_regs- ax   * / \n         pushq     %r8                               / *   pt_regs- r8   * / \n         pushq     %r9                               / *   pt_regs- r9   * / \n         pushq     %r10                              / *   pt_regs- r10   * / \n         pushq     %r11                              / *   pt_regs- r11   * / \n         sub       $ ( 6 * 8 ),   %rsp                      / *   pt_regs- bp ,   bx ,   r12-15   * / \n         ....    \nYizhou Shan \nCreated: Feb 22, 2018 \nLast Updated: Feb 22, 2018", 
            "title": "Get User Entry pt_regs"
        }, 
        {
            "location": "/lego/syscall/compat/", 
            "text": "Compat SYSCALL in Lego\n\n\nLego does \nnot\n support compatible syscalls, where one is able to run 32-bit image on 64-bit OS. However, the ugly FPU code and signal part in Linux is heavily hacked with the assumption that compat syscall is supported. We are no expert in this FPU thing, just to make sure we don\nt break this FPU evil, Lego adds the fake compat syscall support. Fake means whenever a 32-bit syscall is issued, Lego will just panic.\n\n\nKconfig\n\n\nIf one compiles a x86_64 Linux kernel, compat syscalls are supported by default. Everything related to compat syscalls are controlled by the following two Kconfig options. Lego may want to support compat syscalls in the future, thus we add these two Kconfigs to avoid future mess:\n\n\n\n\nCONFIG_COMPAT\n\n\nCONFIG_IA32_EMULATION\n\n\n\n\nInternal\n\n\nEntry Points\n\n\nThe assembly entry points are defined in \nentry/entry_64_compat.S\n:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\nENTRY\n(\nentry_SYSENTER_compat\n)\n\n        \n...\n\n        \ncall\n    \ndo_fast_syscall_32\n\n\nGLOBAL\n(\n__end_entry_SYSENTER_compat\n)\n\n\nENDPROC\n(\nentry_SYSENTER_compat\n)\n\n\n\nENTRY\n(\nentry_SYSCALL_compat\n)\n\n        \n...\n\n        \ncall\n    \ndo_fast_syscall_32\n\n\nEND\n(\nentry_SYSCALL_compat\n)\n\n\n\nENTRY\n(\nentry_INT80_compat\n)\n\n        \n...\n\n        \ncall\n    \ndo_int80_syscall_32\n\n\nEND\n(\nentry_INT80_compat\n)\n\n\n\n\n\n\nEntry Points Setup\n\n\nThe assembly entry points are filled to system registers and IDT table. So users can \nactually\n issue those calls, Lego is able to catch them:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\nstatic\n \nvoid\n \nsyscall_init\n(\nvoid\n)\n\n\n{\n\n        \nwrmsr\n(\nMSR_STAR\n,\n \n0\n,\n \n(\n__USER32_CS\n \n \n16\n)\n \n|\n \n__KERNEL_CS\n);\n\n        \nwrmsrl\n(\nMSR_LSTAR\n,\n \n(\nunsigned\n \nlong\n)\nentry_SYSCALL_64\n);\n\n\n\n#ifdef CONFIG_IA32_EMULATION\n\n        \nwrmsrl\n(\nMSR_CSTAR\n,\n \n(\nunsigned\n \nlong\n)\nentry_SYSCALL_compat\n);\n\n        \n/*  \n\n\n         * This only works on Intel CPUs.\n\n\n         * On AMD CPUs these MSRs are 32-bit, CPU truncates MSR_IA32_SYSENTER_EIP.\n\n\n         * This does not cause SYSENTER to jump to the wrong location, because\n\n\n         * AMD doesn\nt allow SYSENTER in long mode (either 32- or 64-bit).\n\n\n         */\n\n        \nwrmsrl_safe\n(\nMSR_IA32_SYSENTER_CS\n,\n \n(\nu64\n)\n__KERNEL_CS\n);\n\n        \nwrmsrl_safe\n(\nMSR_IA32_SYSENTER_ESP\n,\n \n0ULL\n);\n\n        \nwrmsrl_safe\n(\nMSR_IA32_SYSENTER_EIP\n,\n \n(\nu64\n)\nentry_SYSENTER_compat\n);\n\n\n#else\n\n        \nwrmsrl\n(\nMSR_CSTAR\n,\n \n(\nunsigned\n \nlong\n)\nignore_sysret\n);\n\n        \nwrmsrl_safe\n(\nMSR_IA32_SYSENTER_CS\n,\n \n(\nu64\n)\nGDT_ENTRY_INVALID_SEG\n);\n\n        \nwrmsrl_safe\n(\nMSR_IA32_SYSENTER_ESP\n,\n \n0ULL\n);\n\n        \nwrmsrl_safe\n(\nMSR_IA32_SYSENTER_EIP\n,\n \n0ULL\n);\n\n\n#endif\n\n\n\n        \n/* Flags to clear on syscall */\n\n        \nwrmsrl\n(\nMSR_SYSCALL_MASK\n,\n\n               \nX86_EFLAGS_TF\n|\nX86_EFLAGS_DF\n|\nX86_EFLAGS_IF\n|\n\n               \nX86_EFLAGS_IOPL\n|\nX86_EFLAGS_AC\n|\nX86_EFLAGS_NT\n);\n\n\n}\n\n\narch\n/\nx86\n/\nkernel\n/\ncpu\n/\ncommon\n.\nc\n\n\n\nvoid\n \n__init\n \ntrap_init\n(\nvoid\n)\n\n\n{\n\n        \n...\n\n\n#ifdef CONFIG_IA32_EMULATION\n\n        \nset_system_intr_gate\n(\nIA32_SYSCALL_VECTOR\n,\n \nentry_INT80_compat\n);\n\n        \nset_bit\n(\nIA32_SYSCALL_VECTOR\n,\n \nused_vectors\n);\n\n\n#endif\n\n        \n...\n\n\n}\n\n\narch\n/\nx86\n/\nkernel\n/\ntraps\n.\nc\n\n\n\n\n\n\nC code\n\n\nThe actual C code is in \nentry/common.c\n:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n#if defined(CONFIG_X86_32) || defined(CONFIG_IA32_EMULATION)\n\n\nstatic\n \n__always_inline\n \nvoid\n \ndo_syscall_32_irqs_on\n(\nstruct\n \npt_regs\n \n*\nregs\n)\n\n\n{\n\n\n#ifdef CONFIG_IA32_EMULATION\n\n        \ncurrent\n-\nthread\n.\nstatus\n \n|=\n \nTS_COMPAT\n;\n\n\n#endif\n\n\n        \nBUG\n();\n\n\n}\n\n\n\n/* Handles int $0x80 */\n\n\n__visible\n \nvoid\n \ndo_int80_syscall_32\n(\nstruct\n \npt_regs\n \n*\nregs\n)\n\n\n{\n\n        \nBUG\n();\n\n\n}\n\n\n\n/* Returns 0 to return using IRET or 1 to return using SYSEXIT/SYSRETL. */\n\n\n__visible\n \nlong\n \ndo_fast_syscall_32\n(\nstruct\n \npt_regs\n \n*\nregs\n)\n\n\n{\n\n        \nBUG\n();\n\n\n}\n\n\n#endif\n\n\n\n\n\n\n\nYizhou Shan\n\nCreated: Feb 22, 2018\n\nLast Updated: Feb 22, 2018", 
            "title": "compat"
        }, 
        {
            "location": "/lego/syscall/compat/#compat-syscall-in-lego", 
            "text": "Lego does  not  support compatible syscalls, where one is able to run 32-bit image on 64-bit OS. However, the ugly FPU code and signal part in Linux is heavily hacked with the assumption that compat syscall is supported. We are no expert in this FPU thing, just to make sure we don t break this FPU evil, Lego adds the fake compat syscall support. Fake means whenever a 32-bit syscall is issued, Lego will just panic.", 
            "title": "Compat SYSCALL in Lego"
        }, 
        {
            "location": "/lego/syscall/compat/#kconfig", 
            "text": "If one compiles a x86_64 Linux kernel, compat syscalls are supported by default. Everything related to compat syscalls are controlled by the following two Kconfig options. Lego may want to support compat syscalls in the future, thus we add these two Kconfigs to avoid future mess:   CONFIG_COMPAT  CONFIG_IA32_EMULATION", 
            "title": "Kconfig"
        }, 
        {
            "location": "/lego/syscall/compat/#internal", 
            "text": "", 
            "title": "Internal"
        }, 
        {
            "location": "/lego/syscall/compat/#entry-points", 
            "text": "The assembly entry points are defined in  entry/entry_64_compat.S :  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15 ENTRY ( entry_SYSENTER_compat ) \n         ... \n         call      do_fast_syscall_32  GLOBAL ( __end_entry_SYSENTER_compat )  ENDPROC ( entry_SYSENTER_compat )  ENTRY ( entry_SYSCALL_compat ) \n         ... \n         call      do_fast_syscall_32  END ( entry_SYSCALL_compat )  ENTRY ( entry_INT80_compat ) \n         ... \n         call      do_int80_syscall_32  END ( entry_INT80_compat )", 
            "title": "Entry Points"
        }, 
        {
            "location": "/lego/syscall/compat/#entry-points-setup", 
            "text": "The assembly entry points are filled to system registers and IDT table. So users can  actually  issue those calls, Lego is able to catch them:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41 static   void   syscall_init ( void )  { \n         wrmsr ( MSR_STAR ,   0 ,   ( __USER32_CS     16 )   |   __KERNEL_CS ); \n         wrmsrl ( MSR_LSTAR ,   ( unsigned   long ) entry_SYSCALL_64 );  #ifdef CONFIG_IA32_EMULATION \n         wrmsrl ( MSR_CSTAR ,   ( unsigned   long ) entry_SYSCALL_compat ); \n         /*             * This only works on Intel CPUs.           * On AMD CPUs these MSRs are 32-bit, CPU truncates MSR_IA32_SYSENTER_EIP.           * This does not cause SYSENTER to jump to the wrong location, because           * AMD doesn t allow SYSENTER in long mode (either 32- or 64-bit).           */ \n         wrmsrl_safe ( MSR_IA32_SYSENTER_CS ,   ( u64 ) __KERNEL_CS ); \n         wrmsrl_safe ( MSR_IA32_SYSENTER_ESP ,   0ULL ); \n         wrmsrl_safe ( MSR_IA32_SYSENTER_EIP ,   ( u64 ) entry_SYSENTER_compat );  #else \n         wrmsrl ( MSR_CSTAR ,   ( unsigned   long ) ignore_sysret ); \n         wrmsrl_safe ( MSR_IA32_SYSENTER_CS ,   ( u64 ) GDT_ENTRY_INVALID_SEG ); \n         wrmsrl_safe ( MSR_IA32_SYSENTER_ESP ,   0ULL ); \n         wrmsrl_safe ( MSR_IA32_SYSENTER_EIP ,   0ULL );  #endif \n\n\n         /* Flags to clear on syscall */ \n         wrmsrl ( MSR_SYSCALL_MASK , \n                X86_EFLAGS_TF | X86_EFLAGS_DF | X86_EFLAGS_IF | \n                X86_EFLAGS_IOPL | X86_EFLAGS_AC | X86_EFLAGS_NT );  }  arch / x86 / kernel / cpu / common . c  void   __init   trap_init ( void )  { \n         ...  #ifdef CONFIG_IA32_EMULATION \n         set_system_intr_gate ( IA32_SYSCALL_VECTOR ,   entry_INT80_compat ); \n         set_bit ( IA32_SYSCALL_VECTOR ,   used_vectors );  #endif \n         ...  }  arch / x86 / kernel / traps . c", 
            "title": "Entry Points Setup"
        }, 
        {
            "location": "/lego/syscall/compat/#c-code", 
            "text": "The actual C code is in  entry/common.c :  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22 #if defined(CONFIG_X86_32) || defined(CONFIG_IA32_EMULATION)  static   __always_inline   void   do_syscall_32_irqs_on ( struct   pt_regs   * regs )  {  #ifdef CONFIG_IA32_EMULATION \n         current - thread . status   |=   TS_COMPAT ;  #endif \n\n         BUG ();  }  /* Handles int $0x80 */  __visible   void   do_int80_syscall_32 ( struct   pt_regs   * regs )  { \n         BUG ();  }  /* Returns 0 to return using IRET or 1 to return using SYSEXIT/SYSRETL. */  __visible   long   do_fast_syscall_32 ( struct   pt_regs   * regs )  { \n         BUG ();  }  #endif    \nYizhou Shan \nCreated: Feb 22, 2018 \nLast Updated: Feb 22, 2018", 
            "title": "C code"
        }, 
        {
            "location": "/lego/syscall/msync/", 
            "text": "msync()\n\n\nThe document is a summary I wrote after reading \nFailure-atomic msync()\n paper, which help me understand several questions related to \nmsync()\n.\n\n\n\n\n\n\nmsync() is not atomic.\n During msync(), pages are being written back to disk one by one (or batched): few pages have been flushed back, but few pages are still in the memory. This premature writeback is not atomic and will be affected by failure.\u000b\u000b\n\n\n\n\n\n\nmsync() need concurrency control\n. This actually is the issue I asked before. With a multi-threaded application, does msync() provide the synchronization semantic? The answer is no. Other threads within the same process are able to write to pages under msync(). This implies, application need to handle concurrency by themselves, e.g., rwlocks. \u000b\u000bAt the very beginning, I thought msync() provide this semantic. The only way to implement this should be: kernel make all pages\n PTE read-only, and then perform flush back. If any other threads does a write during flush, they will have a page fault. And in the pgfault function, we hold the threads until the pages are written back.\n\n\n\n\n\n\n\nYizhou Shan\n\nFeb 01, 2018", 
            "title": "msync()"
        }, 
        {
            "location": "/lego/syscall/msync/#msync", 
            "text": "The document is a summary I wrote after reading  Failure-atomic msync()  paper, which help me understand several questions related to  msync() .    msync() is not atomic.  During msync(), pages are being written back to disk one by one (or batched): few pages have been flushed back, but few pages are still in the memory. This premature writeback is not atomic and will be affected by failure.\u000b\u000b    msync() need concurrency control . This actually is the issue I asked before. With a multi-threaded application, does msync() provide the synchronization semantic? The answer is no. Other threads within the same process are able to write to pages under msync(). This implies, application need to handle concurrency by themselves, e.g., rwlocks. \u000b\u000bAt the very beginning, I thought msync() provide this semantic. The only way to implement this should be: kernel make all pages  PTE read-only, and then perform flush back. If any other threads does a write during flush, they will have a page fault. And in the pgfault function, we hold the threads until the pages are written back.    \nYizhou Shan \nFeb 01, 2018", 
            "title": "msync()"
        }, 
        {
            "location": "/lego/syscall/mremap/", 
            "text": "mremap()", 
            "title": "mremap()"
        }, 
        {
            "location": "/lego/syscall/mremap/#mremap", 
            "text": "", 
            "title": "mremap()"
        }, 
        {
            "location": "/lego/syscall/fork/", 
            "text": "fork()\n\n\nMemory Manager\n\n\nWe need to duplicate the address space in the memory manager side. Follow the traditional \nfork()\n semantic, both the existing and newly created address space will be write-protected.\n\n\nSince we have the flexibility to implement any VM organization, we should be careful while duplicating the address space. Currently, we are using page-based VM, thus the duplicating is basically creating a new \npgd\n and copy existing pgtables, and further downgrade permission to read-only. This is now performed by \nlego_copy_page_range()\n.\n\n\nThe final write-protect is performed by \nlego_copy_one_pte()\n:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\nstatic\n \ninline\n \nint\n \nlego_copy_one_pte\n(..)\n\n\n{\n\n    \n..\n\n    \n/*\n\n\n     * If it\ns a COW mapping, write protect it both\n\n\n     * in the parent and the child\n\n\n     */\n\n    \nif\n \n(\nis_cow_mapping\n(\nvm_flags\n))\n \n{\n\n        \nptep_set_wrprotect\n(\nsrc_pte\n);\n   \n        \npte\n \n=\n \npte_wrprotect\n(\npte\n);\n      \n    \n}\n\n    \n...\n\n\n}\n\n\n\n\n\n\nDuplicate VM Free Pool\n\n\nTODO\n Yutong\n\n\nProcessor Manager\n\n\nBoring implementation details in the processor manager side.\n\n\nEntry Points\n\n\n\n\nfork()\n\n\nvfork()\n\n\nclone()\n\n\nkernel_thread()\n\n\n\n\nAll of them land on \ndo_fork()\n, which is Lego\ns main fork function.\n\n\ndo_fork()\n\n\nThere are mainly three parts within \ndo_fork()\n: \n1)\n \ncopy_process()\n, which duplicates a new task based on \ncurrent\n, including allocate new kernel stack, new task_struct, increase mm reference counter, etc. \n2)\n If we are creating a new process, then tell global monitor or memory manager to let them update bookkeeping and create corresponding data structures. \n3)\n \nwake_up_new_task()\n, which gives away the newly created task to local scheduler.\n\n\ncopy_process()\n\n\nThe routine is kind of boring. It do a lot dirty work to copy information from calling thread to new thread. The most important data structures of course are \ntask_struct\n, \nmm_sturct\n, \nsighand\n, and so on. This section only talks about few of them, and leave others to readers who are interested.\n\n\nSanity Checking\n\n\nMainly check if \nclone_flags\n are passed properly. For example, if user is creating a new thread, that implies certain data structures are shared, cause new thread belongs to the same process with the calling thread. If \nCLONE_THREAD\n is passed, then \nCLONE_SIGHAND\n, \nCLONE_VM\n, and so on must be set as well.\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n    \n/*\n\n\n     * Thread groups must share signals as well, and detached threads\n\n\n     * can only be started up within the thread group.\n\n\n     */\n\n    \nif\n \n((\nclone_flags\n \n \nCLONE_THREAD\n)\n \n \n!\n(\nclone_flags\n \n \nCLONE_SIGHAND\n))\n\n        \nreturn\n \nERR_PTR\n(\n-\nEINVAL\n);\n\n\n    \n/*\n\n\n     * Shared signal handlers imply shared VM. By way of the above,\n\n\n     * thread groups also imply shared VM. Blocking this case allows\n\n\n     * for various simplifications in other code.\n\n\n     */\n\n    \nif\n \n((\nclone_flags\n \n \nCLONE_SIGHAND\n)\n \n \n!\n(\nclone_flags\n \n \nCLONE_VM\n))\n\n        \nreturn\n \nERR_PTR\n(\n-\nEINVAL\n);\n\n\n\n\n\n\ndup_task_struct()\n\n\nTwo main things: 1) duplicate a new \ntask_struct\n, 2) duplicate a new kernel stack. x86 is just a weird architecture, the size of \ntask_struct\n depends on the size of fpu. So the allocation and duplication need to callback to x86-specific code to duplicate the task_struct and fpu info.\n\n1\n2\n3\n4\n5\n6\nint\n \narch_dup_task_struct\n(\nstruct\n \ntask_struct\n \n*\ndst\n,\n \nstruct\n \ntask_struct\n \n*\nsrc\n)\n\n\n{\n\n    \nmemcpy\n(\ndst\n,\n \nsrc\n,\n \narch_task_struct_size\n);\n\n\n    \nreturn\n \nfpu__copy\n(\ndst\n-\nthread\n.\nfpu\n,\n \nsrc\n-\nthread\n.\nfpu\n);\n\n\n}\n\n\n\n\n\nThe stack duplication is fairly simple, just copy everything from the old stack to new stack. Of course, it needs to setup the \nthread_info\n to points to this new thread, so the \ncurrent\n macro will work.\n\n1\n2\n3\n4\n5\n6\n7\n8\nstatic\n \nvoid\n \nsetup_thread_stack\n(\nstruct\n \ntask_struct\n \n*\np\n,\n \nstruct\n \ntask_struct\n \n*\norg\n)\n\n\n{\n\n        \n/* Duplicate whole stack! */\n\n        \n*\ntask_thread_info\n(\np\n)\n \n=\n \n*\ntask_thread_info\n(\norg\n);\n\n\n        \n/* Make the `current\n macro work */\n\n        \ntask_thread_info\n(\np\n)\n-\ntask\n \n=\n \np\n;\n\n\n}\n\n\n\n\n\n\ncopy_mm()\n\n\nThis is where threads within a process will share the virtual address space happens. If we are creating a new process, then this function will create a new \nmm_struct\n, and also a new \npgd\n:\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n/*\n\n\n * pgd_alloc() will duplicate the identity kernel mapping\n\n\n * but leaves other entries empty:\n\n\n */\n\n\nmm\n-\npgd\n \n=\n \npgd_alloc\n(\nmm\n);\n\n\nif\n \n(\nunlikely\n(\n!\nmm\n-\npgd\n))\n \n{\n\n        \nkfree\n(\nmm\n);\n\n        \nreturn\n \nNULL\n;\n\n\n}\n\n\n\n\n\n\nDuplicate pcache data\n\n\nTODO\n\n\nTODO: hook with pcache\nWe need to duplicate the pcache vm_range array, once Yutong finished the code.\nsetup_sched_fork()\n\n\nCallback to scheduler to setup this new task. It may reset all scheduler related information. Here we also have a chance to change this task\ns scheduler class:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\nint\n \nsetup_sched_fork\n(\nunsigned\n \nlong\n \nclone_flags\n,\n \nstruct\n \ntask_struct\n \n*\np\n)\n\n\n{\n\n        \nint\n \ncpu\n \n=\n \nget_cpu\n();\n\n\n        \n__sched_fork\n(\nclone_flags\n,\n \np\n);\n\n\n        \np\n-\nstate\n \n=\n \nTASK_NEW\n;\n\n        \n...\n\n        \nif\n \n(\nunlikely\n(\np\n-\nsched_reset_on_fork\n))\n \n{\n\n                \nif\n \n(\ntask_has_rt_policy\n(\np\n))\n \n{\n\n                        \np\n-\npolicy\n \n=\n \nSCHED_NORMAL\n;\n\n                        \np\n-\nstatic_prio\n \n=\n \nNICE_TO_PRIO\n(\n0\n);\n\n                        \np\n-\nrt_priority\n \n=\n \n0\n;\n\n                \n}\n \nelse\n \nif\n \n(\nPRIO_TO_NICE\n(\np\n-\nstatic_prio\n)\n \n \n0\n)\n\n                        \np\n-\nstatic_prio\n \n=\n \nNICE_TO_PRIO\n(\n0\n);\n\n\n                \np\n-\nprio\n \n=\n \np\n-\nnormal_prio\n \n=\n \n__normal_prio\n(\np\n);\n\n                \nset_load_weight\n(\np\n);\n\n                \n...\n\n        \n}\n    \n\n        \nif\n \n(\nrt_prio\n(\np\n-\nprio\n))\n\n                \np\n-\nsched_class\n \n=\n \nrt_sched_class\n;\n\n        \nelse\n \n{\n\n                \np\n-\nsched_class\n \n=\n \nfair_sched_class\n;\n\n                \nset_load_weight\n(\np\n);\n\n        \n}\n    \n\n        \n__set_task_cpu\n(\np\n,\n \ncpu\n);\n\n        \nif\n \n(\np\n-\nsched_class\n-\ntask_fork\n)\n\n                \np\n-\nsched_class\n-\ntask_fork\n(\np\n);\n\n\n        \n...\n\n\n}\n\n\n\n\n\n\n\nAllocate new pid\n\n\nIn both Lego and Linux, we don\nt allocate new pid for a new thread, if that thread is an \nidle thread\n. So callers of \ndo_fork\n needs to pass something to let \ndo_fork\n know. In Linux, they use \nstruct pid, init_struct_pid\n to check. In Lego, we introduce an new clone_flag \nCLONE_IDLE_THREAD\n. If that flag is set, \ndo_fork()\n will try to allocate a new pid for the new thread. Otherwise, it will be 0:\n\n1\n2\n3\n4\n5\n6\n/* clone idle thread, whose pid is 0 */\n\n\nif\n \n(\n!\n(\nclone_flags\n \n \nCLONE_IDLE_THREAD\n))\n \n{\n\n        \npid\n \n=\n \nalloc_pid\n(\np\n);\n\n        \nif\n \n(\n!\npid\n)\n\n                \ngoto\n \nout_cleanup_thread\n;\n\n\n}\n\n\n\n\n\n\nSo, only the \ninit_idle()\n function can pass this \nCLONE_IDLE_THREAD\n down. All other usages are wrong and should be reported.\n\n\nIn order to avoid conflict with Linux clone_flag, we define it as:\n\n1\n#define CLONE_IDLE_THREAD       0x100000000\n\n\n\n\n\n\nSETTID/CLEARTID\n\n\nThese are some futex related stuff. I will cover these stuff in futex document:\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\np\n-\nset_child_tid\n \n=\n \n(\nclone_flags\n \n \nCLONE_CHILD_SETTID\n)\n \n?\n \nchild_tidptr\n \n:\n \nNULL\n;\n\n\n/*  \n\n\n * Clear TID on mm_release()?\n\n\n */\n\n\np\n-\nclear_child_tid\n \n=\n \n(\nclone_flags\n \n \nCLONE_CHILD_CLEARTID\n)\n \n?\n \nchild_tidptr\n \n:\n \nNULL\n;\n\n\n\n#ifdef CONFIG_FUTEX\n\n\np\n-\nrobust_list\n \n=\n \nNULL\n;\n\n\n#endif\n\n\n\n\n\n\ncopy_thread_tls()\n\n\nThis is the most interesting function. Cover later.\n\n\np2m_fork()\n\n\nIn order to track user activities, we need to know when user are going to create new process. Fork is the best time and the only time we kernel know. So, Lego adds this special hook to tell remote global monitor or memory manager that there is a new process going to be created. Upon receiving this message, remote monitor will update its bookkeeping for this specific user/vNode.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n/* Tell remote memory component */\n\n\n#ifdef CONFIG_COMP_PROCESSOR\n\n\nif\n \n(\nclone_flags\n \n \nCLONE_GLOBAL_THREAD\n)\n \n{\n\n        \n...\n\n        \np2m_fork\n(\np\n,\n \nclone_flags\n);\n\n        \n...\n\n\n}\n   \n\n#endif\n\n\n\n\n\n\n\nThe \nCLONE_GLOBAL_THREAD\n should only be set, if the following cases happen:\n\n\n\n\nfork()\n\n\nvfork()\n\n\nclone(), without \nCLONE_THREAD\n being set\n\n\n\n\nIn order to avoid conflict with Linux clone_flag, we define it as:\n\n1\n#define CLONE_GLOBAL_THREAD     0x200000000\n\n\n\n\n\n\nwake_up_new_task()\n\n\nThe last step of \ndo_fork\n is waking up the new thread or process, which is performed by \nwake_up_new_task()\n function. The first question this function will ask is: \nwhich cpu to land?\n The answer comes from \nselect_task_rq()\n:\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\nstatic\n \ninline\n\n\nint\n \nselect_task_rq\n(\nstruct\n \ntask_struct\n \n*\np\n,\n \nint\n \ncpu\n,\n \nint\n \nsd_flags\n,\n \nint\n \nwake_flags\n)\n\n\n{\n\n        \nif\n \n(\np\n-\nnr_cpus_allowed\n \n \n1\n)\n\n                \ncpu\n \n=\n \np\n-\nsched_class\n-\nselect_task_rq\n(\np\n,\n \ncpu\n,\n \nsd_flags\n,\n \nwake_flags\n);\n\n        \nelse\n\n                \ncpu\n \n=\n \ncpumask_any\n(\np\n-\ncpus_allowed\n);\n\n        \n...\n\n\n}\n\n\n\n\n\n\n\nClearly, this is determined by \ncpus_allowed\n, which is the same with its parent at this point. That being said, if the parent is only able to run on one specific CPU, then all its children will end up running on the same CPU when they wake up (they could change their affinity later). This is also the default on Linux: \nA child created via fork(2) inherits its parent\ns CPU affinity mask. The affinity mask is preserved across an execve(2).\n\n\nAfter landing CPU is selected, following operation is simple: just enqueue this task into landing CPU\ns runqueue, and we are done:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\nvoid\n \nwake_up_new_task\n(\nstruct\n \ntask_struct\n \n*\np\n)\n\n\n{\n\n        \n...\n\n\n/* Select a CPU for new thread to run */\n\n\n#ifdef CONFIG_SMP\n\n        \n/*   \n\n\n         * Fork balancing, do it here and not earlier because:\n\n\n         *  - cpus_allowed can change in the fork path\n\n\n         *  - any previously selected cpu might disappear through hotplug\n\n\n         */\n\n        \nset_task_cpu\n(\np\n,\n \nselect_task_rq\n(\np\n,\n \ntask_cpu\n(\np\n),\n \nSD_BALANCE_FORK\n,\n \n0\n));\n\n\n#endif\n\n\n        \nrq\n \n=\n \n__task_rq_lock\n(\np\n);\n\n        \nactivate_task\n(\nrq\n,\n \np\n,\n \n0\n);\n\n        \np\n-\non_rq\n \n=\n \nTASK_ON_RQ_QUEUED\n;\n\n        \n...\n\n\n}\n\n\n\n\n\n\n\n\nYizhou Shan\n\nCreated: Feb 11, 2018\n\nLast Updated: Feb 27, 2018", 
            "title": "fork()"
        }, 
        {
            "location": "/lego/syscall/fork/#fork", 
            "text": "", 
            "title": "fork()"
        }, 
        {
            "location": "/lego/syscall/fork/#memory-manager", 
            "text": "We need to duplicate the address space in the memory manager side. Follow the traditional  fork()  semantic, both the existing and newly created address space will be write-protected.  Since we have the flexibility to implement any VM organization, we should be careful while duplicating the address space. Currently, we are using page-based VM, thus the duplicating is basically creating a new  pgd  and copy existing pgtables, and further downgrade permission to read-only. This is now performed by  lego_copy_page_range() .  The final write-protect is performed by  lego_copy_one_pte() :  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 static   inline   int   lego_copy_one_pte (..)  { \n     .. \n     /*       * If it s a COW mapping, write protect it both       * in the parent and the child       */ \n     if   ( is_cow_mapping ( vm_flags ))   { \n         ptep_set_wrprotect ( src_pte );    \n         pte   =   pte_wrprotect ( pte );       \n     } \n     ...  }", 
            "title": "Memory Manager"
        }, 
        {
            "location": "/lego/syscall/fork/#duplicate-vm-free-pool", 
            "text": "TODO  Yutong", 
            "title": "Duplicate VM Free Pool"
        }, 
        {
            "location": "/lego/syscall/fork/#processor-manager", 
            "text": "Boring implementation details in the processor manager side.", 
            "title": "Processor Manager"
        }, 
        {
            "location": "/lego/syscall/fork/#entry-points", 
            "text": "fork()  vfork()  clone()  kernel_thread()   All of them land on  do_fork() , which is Lego s main fork function.", 
            "title": "Entry Points"
        }, 
        {
            "location": "/lego/syscall/fork/#do_fork", 
            "text": "There are mainly three parts within  do_fork() :  1)   copy_process() , which duplicates a new task based on  current , including allocate new kernel stack, new task_struct, increase mm reference counter, etc.  2)  If we are creating a new process, then tell global monitor or memory manager to let them update bookkeeping and create corresponding data structures.  3)   wake_up_new_task() , which gives away the newly created task to local scheduler.", 
            "title": "do_fork()"
        }, 
        {
            "location": "/lego/syscall/fork/#copy_process", 
            "text": "The routine is kind of boring. It do a lot dirty work to copy information from calling thread to new thread. The most important data structures of course are  task_struct ,  mm_sturct ,  sighand , and so on. This section only talks about few of them, and leave others to readers who are interested.", 
            "title": "copy_process()"
        }, 
        {
            "location": "/lego/syscall/fork/#sanity-checking", 
            "text": "Mainly check if  clone_flags  are passed properly. For example, if user is creating a new thread, that implies certain data structures are shared, cause new thread belongs to the same process with the calling thread. If  CLONE_THREAD  is passed, then  CLONE_SIGHAND ,  CLONE_VM , and so on must be set as well.  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14      /*       * Thread groups must share signals as well, and detached threads       * can only be started up within the thread group.       */ \n     if   (( clone_flags     CLONE_THREAD )     ! ( clone_flags     CLONE_SIGHAND )) \n         return   ERR_PTR ( - EINVAL ); \n\n     /*       * Shared signal handlers imply shared VM. By way of the above,       * thread groups also imply shared VM. Blocking this case allows       * for various simplifications in other code.       */ \n     if   (( clone_flags     CLONE_SIGHAND )     ! ( clone_flags     CLONE_VM )) \n         return   ERR_PTR ( - EINVAL );", 
            "title": "Sanity Checking"
        }, 
        {
            "location": "/lego/syscall/fork/#dup_task_struct", 
            "text": "Two main things: 1) duplicate a new  task_struct , 2) duplicate a new kernel stack. x86 is just a weird architecture, the size of  task_struct  depends on the size of fpu. So the allocation and duplication need to callback to x86-specific code to duplicate the task_struct and fpu info. 1\n2\n3\n4\n5\n6 int   arch_dup_task_struct ( struct   task_struct   * dst ,   struct   task_struct   * src )  { \n     memcpy ( dst ,   src ,   arch_task_struct_size ); \n\n     return   fpu__copy ( dst - thread . fpu ,   src - thread . fpu );  }   \nThe stack duplication is fairly simple, just copy everything from the old stack to new stack. Of course, it needs to setup the  thread_info  to points to this new thread, so the  current  macro will work. 1\n2\n3\n4\n5\n6\n7\n8 static   void   setup_thread_stack ( struct   task_struct   * p ,   struct   task_struct   * org )  { \n         /* Duplicate whole stack! */ \n         * task_thread_info ( p )   =   * task_thread_info ( org ); \n\n         /* Make the `current  macro work */ \n         task_thread_info ( p ) - task   =   p ;  }", 
            "title": "dup_task_struct()"
        }, 
        {
            "location": "/lego/syscall/fork/#copy_mm", 
            "text": "This is where threads within a process will share the virtual address space happens. If we are creating a new process, then this function will create a new  mm_struct , and also a new  pgd : 1\n2\n3\n4\n5\n6\n7\n8\n9 /*   * pgd_alloc() will duplicate the identity kernel mapping   * but leaves other entries empty:   */  mm - pgd   =   pgd_alloc ( mm );  if   ( unlikely ( ! mm - pgd ))   { \n         kfree ( mm ); \n         return   NULL ;  }", 
            "title": "copy_mm()"
        }, 
        {
            "location": "/lego/syscall/fork/#duplicate-pcache-data", 
            "text": "TODO  TODO: hook with pcache We need to duplicate the pcache vm_range array, once Yutong finished the code.", 
            "title": "Duplicate pcache data"
        }, 
        {
            "location": "/lego/syscall/fork/#setup_sched_fork", 
            "text": "Callback to scheduler to setup this new task. It may reset all scheduler related information. Here we also have a chance to change this task s scheduler class:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34 int   setup_sched_fork ( unsigned   long   clone_flags ,   struct   task_struct   * p )  { \n         int   cpu   =   get_cpu (); \n\n         __sched_fork ( clone_flags ,   p ); \n\n         p - state   =   TASK_NEW ; \n         ... \n         if   ( unlikely ( p - sched_reset_on_fork ))   { \n                 if   ( task_has_rt_policy ( p ))   { \n                         p - policy   =   SCHED_NORMAL ; \n                         p - static_prio   =   NICE_TO_PRIO ( 0 ); \n                         p - rt_priority   =   0 ; \n                 }   else   if   ( PRIO_TO_NICE ( p - static_prio )     0 ) \n                         p - static_prio   =   NICE_TO_PRIO ( 0 ); \n\n                 p - prio   =   p - normal_prio   =   __normal_prio ( p ); \n                 set_load_weight ( p ); \n                 ... \n         }     \n\n         if   ( rt_prio ( p - prio )) \n                 p - sched_class   =   rt_sched_class ; \n         else   { \n                 p - sched_class   =   fair_sched_class ; \n                 set_load_weight ( p ); \n         }     \n\n         __set_task_cpu ( p ,   cpu ); \n         if   ( p - sched_class - task_fork ) \n                 p - sched_class - task_fork ( p ); \n\n         ...  }", 
            "title": "setup_sched_fork()"
        }, 
        {
            "location": "/lego/syscall/fork/#allocate-new-pid", 
            "text": "In both Lego and Linux, we don t allocate new pid for a new thread, if that thread is an  idle thread . So callers of  do_fork  needs to pass something to let  do_fork  know. In Linux, they use  struct pid, init_struct_pid  to check. In Lego, we introduce an new clone_flag  CLONE_IDLE_THREAD . If that flag is set,  do_fork()  will try to allocate a new pid for the new thread. Otherwise, it will be 0: 1\n2\n3\n4\n5\n6 /* clone idle thread, whose pid is 0 */  if   ( ! ( clone_flags     CLONE_IDLE_THREAD ))   { \n         pid   =   alloc_pid ( p ); \n         if   ( ! pid ) \n                 goto   out_cleanup_thread ;  }    So, only the  init_idle()  function can pass this  CLONE_IDLE_THREAD  down. All other usages are wrong and should be reported.  In order to avoid conflict with Linux clone_flag, we define it as: 1 #define CLONE_IDLE_THREAD       0x100000000", 
            "title": "Allocate new pid"
        }, 
        {
            "location": "/lego/syscall/fork/#settidcleartid", 
            "text": "These are some futex related stuff. I will cover these stuff in futex document: 1\n2\n3\n4\n5\n6\n7\n8\n9 p - set_child_tid   =   ( clone_flags     CLONE_CHILD_SETTID )   ?   child_tidptr   :   NULL ;  /*     * Clear TID on mm_release()?   */  p - clear_child_tid   =   ( clone_flags     CLONE_CHILD_CLEARTID )   ?   child_tidptr   :   NULL ;  #ifdef CONFIG_FUTEX  p - robust_list   =   NULL ;  #endif", 
            "title": "SETTID/CLEARTID"
        }, 
        {
            "location": "/lego/syscall/fork/#copy_thread_tls", 
            "text": "This is the most interesting function. Cover later.", 
            "title": "copy_thread_tls()"
        }, 
        {
            "location": "/lego/syscall/fork/#p2m_fork", 
            "text": "In order to track user activities, we need to know when user are going to create new process. Fork is the best time and the only time we kernel know. So, Lego adds this special hook to tell remote global monitor or memory manager that there is a new process going to be created. Upon receiving this message, remote monitor will update its bookkeeping for this specific user/vNode.  1\n2\n3\n4\n5\n6\n7\n8 /* Tell remote memory component */  #ifdef CONFIG_COMP_PROCESSOR  if   ( clone_flags     CLONE_GLOBAL_THREAD )   { \n         ... \n         p2m_fork ( p ,   clone_flags ); \n         ...  }     #endif    The  CLONE_GLOBAL_THREAD  should only be set, if the following cases happen:   fork()  vfork()  clone(), without  CLONE_THREAD  being set   In order to avoid conflict with Linux clone_flag, we define it as: 1 #define CLONE_GLOBAL_THREAD     0x200000000", 
            "title": "p2m_fork()"
        }, 
        {
            "location": "/lego/syscall/fork/#wake_up_new_task", 
            "text": "The last step of  do_fork  is waking up the new thread or process, which is performed by  wake_up_new_task()  function. The first question this function will ask is:  which cpu to land?  The answer comes from  select_task_rq() :  1\n2\n3\n4\n5\n6\n7\n8\n9 static   inline  int   select_task_rq ( struct   task_struct   * p ,   int   cpu ,   int   sd_flags ,   int   wake_flags )  { \n         if   ( p - nr_cpus_allowed     1 ) \n                 cpu   =   p - sched_class - select_task_rq ( p ,   cpu ,   sd_flags ,   wake_flags ); \n         else \n                 cpu   =   cpumask_any ( p - cpus_allowed ); \n         ...  }    Clearly, this is determined by  cpus_allowed , which is the same with its parent at this point. That being said, if the parent is only able to run on one specific CPU, then all its children will end up running on the same CPU when they wake up (they could change their affinity later). This is also the default on Linux:  A child created via fork(2) inherits its parent s CPU affinity mask. The affinity mask is preserved across an execve(2).  After landing CPU is selected, following operation is simple: just enqueue this task into landing CPU s runqueue, and we are done:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18 void   wake_up_new_task ( struct   task_struct   * p )  { \n         ...  /* Select a CPU for new thread to run */  #ifdef CONFIG_SMP \n         /*              * Fork balancing, do it here and not earlier because:           *  - cpus_allowed can change in the fork path           *  - any previously selected cpu might disappear through hotplug           */ \n         set_task_cpu ( p ,   select_task_rq ( p ,   task_cpu ( p ),   SD_BALANCE_FORK ,   0 ));  #endif \n\n         rq   =   __task_rq_lock ( p ); \n         activate_task ( rq ,   p ,   0 ); \n         p - on_rq   =   TASK_ON_RQ_QUEUED ; \n         ...  }    \nYizhou Shan \nCreated: Feb 11, 2018 \nLast Updated: Feb 27, 2018", 
            "title": "wake_up_new_task()"
        }, 
        {
            "location": "/lego/pcache/config/", 
            "text": "Pcache Configuration\n\n\nLast Updated: 02/01/18\n\n\nThis doc explains what configuration options pcache has, and how to config them properly. Pcache is only enabled in Lego\ns processor manager and currently it uses DRAM to emulate the last-level cache (or, L4).\n\n\nKconfig\n\n\nCONFIG_MEMMAP_MEMBLOCK_RESERVED\n\n\nDEFAULT: Y\n\n\nBy default, boot command line option \nmemmap $\n will reserve a range of physical memory.\nThis reserved memory will be marked reserved in e820 table, which\nmeans this range will not be registered into \nmemblock\n. Only memory that has been\nregistered into \nmemblock\n will be assigned \nstruct page\n with it (both \nmemblock.memory\n and \nmemblock.reserve\n will have). And do note that this part of reserved memory can be mapped as 1GB page at boot time.\n\n\nIn other words, by default (the linux semantic), users need to \nioremap\n\nthe \nmemmap $\n reserved physical memory, and use the returned kernel virtual address afterwards.\nAnd do note that the \nioremap()\n only support 4KB mapping.\n\n\nIn Lego, if this option is enabled, the memory marked by \nmemmap $\n will \nNOT\n be marked\nreserved into e820 table, instead, it will be pushed into \nmemblock\n, which means\nit is mapped into kernel direct mapping and has \nstruct page\n.\n\n\nFor those who have done DAX, or NVM related stuff, you must have struggled with\n\nmemmap $\n, and complained why it does not have \nstruct page\n, I guess? So here is\nthe simple code to do so:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\nif\n \n(\n*\np\n \n==\n \n@\n)\n \n{\n\n        \nstart_at\n \n=\n \nmemparse\n(\np\n+\n1\n,\n \np\n);\n\n        \ne820_add_region\n(\nstart_at\n,\n \nmem_size\n,\n \nE820_RAM\n);\n\n\n}\n \nelse\n \nif\n \n(\n*\np\n \n==\n \n#\n)\n \n{\n\n        \nstart_at\n \n=\n \nmemparse\n(\np\n+\n1\n,\n \np\n);\n\n        \ne820_add_region\n(\nstart_at\n,\n \nmem_size\n,\n \nE820_ACPI\n);\n\n\n}\n \nelse\n \nif\n \n(\n*\np\n \n==\n \n$\n)\n \n{\n\n        \nstart_at\n \n=\n \nmemparse\n(\np\n+\n1\n,\n \np\n);\n\n\n\n#ifdef CONFIG_MEMMAP_MEMBLOCK_RESERVED\n\n        \nmemblock_reserve\n(\nstart_at\n,\n \nmem_size\n);\n\n\n#else\n\n        \ne820_add_region\n(\nstart_at\n,\n \nmem_size\n,\n \nE820_RESERVED\n);\n\n\n#endif\n\n\n\n\n\n\nBut why we are having this? Because I think the \ndirect 1GB mapping\n may have\nbetter performance: huge page mapping can truly save us a lot TLB misses. However, the real performance number is unknown.\n\n\nIf unsure, say \nY\n.", 
            "title": "Config"
        }, 
        {
            "location": "/lego/pcache/config/#pcache-configuration", 
            "text": "Last Updated: 02/01/18  This doc explains what configuration options pcache has, and how to config them properly. Pcache is only enabled in Lego s processor manager and currently it uses DRAM to emulate the last-level cache (or, L4).", 
            "title": "Pcache Configuration"
        }, 
        {
            "location": "/lego/pcache/config/#kconfig", 
            "text": "", 
            "title": "Kconfig"
        }, 
        {
            "location": "/lego/pcache/config/#config_memmap_memblock_reserved", 
            "text": "DEFAULT: Y  By default, boot command line option  memmap $  will reserve a range of physical memory.\nThis reserved memory will be marked reserved in e820 table, which\nmeans this range will not be registered into  memblock . Only memory that has been\nregistered into  memblock  will be assigned  struct page  with it (both  memblock.memory  and  memblock.reserve  will have). And do note that this part of reserved memory can be mapped as 1GB page at boot time.  In other words, by default (the linux semantic), users need to  ioremap \nthe  memmap $  reserved physical memory, and use the returned kernel virtual address afterwards.\nAnd do note that the  ioremap()  only support 4KB mapping.  In Lego, if this option is enabled, the memory marked by  memmap $  will  NOT  be marked\nreserved into e820 table, instead, it will be pushed into  memblock , which means\nit is mapped into kernel direct mapping and has  struct page .  For those who have done DAX, or NVM related stuff, you must have struggled with memmap $ , and complained why it does not have  struct page , I guess? So here is\nthe simple code to do so:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14 if   ( * p   ==   @ )   { \n         start_at   =   memparse ( p + 1 ,   p ); \n         e820_add_region ( start_at ,   mem_size ,   E820_RAM );  }   else   if   ( * p   ==   # )   { \n         start_at   =   memparse ( p + 1 ,   p ); \n         e820_add_region ( start_at ,   mem_size ,   E820_ACPI );  }   else   if   ( * p   ==   $ )   { \n         start_at   =   memparse ( p + 1 ,   p );  #ifdef CONFIG_MEMMAP_MEMBLOCK_RESERVED \n         memblock_reserve ( start_at ,   mem_size );  #else \n         e820_add_region ( start_at ,   mem_size ,   E820_RESERVED );  #endif    But why we are having this? Because I think the  direct 1GB mapping  may have\nbetter performance: huge page mapping can truly save us a lot TLB misses. However, the real performance number is unknown.  If unsure, say  Y .", 
            "title": "CONFIG_MEMMAP_MEMBLOCK_RESERVED"
        }, 
        {
            "location": "/lego/pcache/rmap/", 
            "text": "Reverse Mapping of Pcache\n\n\nThis document explains Lego\ns reverse mapping design for pcache. We also present Lego internal functions that eventually manipulate rmap data structures.\nFor readers who are not familiar with reverse mapping, I recommend you search \nwhat is rmap in Linux\n first.\n\n\nDesign\n\n\nThe reverse mapping, or rmap, of our pcache is implemented in a very basic and\nstraightforward way: pointing back to all page table entries (ptes) directly.\nShared pcache lines will have a list of ptes that point to this pcache line.\nWe also did this way in Hotpot.\n\n\nrmap is used by \n1)\n a bunch of syscalls, such as \nfork()\n, \nexecv()\n, \nmmap()\n,\n\nmunmap()\n, \nmremap()\n, \nbrk()\n. \n2)\n page reclaim, which needs to unmap all ptes for a\ngiven swapped page. Other than \nfork()\n and \nexecv()\n, other vm related syscalls\nare invoked very frequently for a typical datacenter application. Moreover, page\nreclaim and swap also run concurrently to gain exclusive access to rmap.\n\n\nSo, rmap operations have to be fast. Directly pointing to pte seems the best\nsolution here. However, this fine-granularity design will consume a lot memory\nfor the per-pte list.\nFurthermore, vma creation, deletion, split and merge happen frequently, the overhead\nto manage rmap is quite high. No wonder Linux choses another object-based way to do so,\nwhich leverages vma itself to take a longer path towards pte.\n\n\nThe important question is: \ndoes this naive solution fit \ncurrent\n Lego?\n\n\nYes, it fits, for several reasons. \n1)\n Current Lego run static-linked ELF binary only,\nthus there will not be any shared hot library pages, which implies rmap list maintenance\nis simplified. \n2)\n Our targeted applications\nmostly are single process. Even for multiple process ones, the number of processes\nstay stable and \nfork()\n happen at early init time. \n3)\n major users of rmap such\nas \nmremap()\n and \nmunmap()\n  perform rmap operation explicitly, \nmmap()\n perform\nrmap implicitly via pgfault (or pcache miss), \npcache reclaim\n perform sweep async.\nAll of them, combined with 1) and 2), most of the time will perform rmap operation\non a single pte.\n\n\nInternal\n\n\nThe following table describes different contexts that manipulate rmap data structures. Currently, rmap only has four possible operations. The context field describes the large context that trigger such rmap operation. The related functions and pcache callback field lists functions that actually did the dirty work.\n\n\n\n\n\n\n\n\nrmap operation\n\n\nContext\n\n\nRelated functions and pcache callback\n\n\n\n\n\n\n\n\n\n\nAdd\n\n\nfork()\n \npgfault\n\n\ncopy_pte_range()\n -\n \npcache_copy_pte()\n \n \npcache_add_rmap()\n\n\n\n\n\n\nRemove\n\n\nmunmap()\n \n \nexit_mmap()\n\n\nzap_pte_range()\n -\n \npcache_zap_pte()\n\n\n\n\n\n\nUpdate\n\n\nmremap()\n\n\nmove_ptes()\n -\n \npcache_move_pte()\n\n\n\n\n\n\nLookup\n\n\npcache eviction sweep, etc.\n\n\npcache_referenced()\n, \npcache_wrprotect()\n \n \npcache_try_to_unmap()\n\n\n\n\n\n\n\n\nThought\n\n\nOne function I personally love the most is \nrmap_walk()\n, whose name pretty much tells the story. To use \nrmap_walk()\n, caller passes a \nstruct rmap_walk_control\n, which including caller specific callback for each rmap. This function also isolates the specific data structures used by rmap from various callers. In Lego, a lot pcache functions are built upon \nrmap_walk()\n.\n\n\nstruct rmap_walk_control\n, or \nstruct scan_control\n, or \nstruct something_control\n are used a lot by Linux kernel. Personally I do love this way of doing data structure walk, or reuse functions. However, even this way can greatly reduce duplicated code size, it will make the code unnecessary complex. As a system developer, no more expects to see a function longer than 100 lines. People love saying: \nDo one thing and do it better\n, while it not always works that perfectly. Coding is nothing different life, it is all about trade-off.\n\n\n\nYizhou Shan\n\nFeb 02, 2018", 
            "title": "Reverse Mapping"
        }, 
        {
            "location": "/lego/pcache/rmap/#reverse-mapping-of-pcache", 
            "text": "This document explains Lego s reverse mapping design for pcache. We also present Lego internal functions that eventually manipulate rmap data structures.\nFor readers who are not familiar with reverse mapping, I recommend you search  what is rmap in Linux  first.", 
            "title": "Reverse Mapping of Pcache"
        }, 
        {
            "location": "/lego/pcache/rmap/#design", 
            "text": "The reverse mapping, or rmap, of our pcache is implemented in a very basic and\nstraightforward way: pointing back to all page table entries (ptes) directly.\nShared pcache lines will have a list of ptes that point to this pcache line.\nWe also did this way in Hotpot.  rmap is used by  1)  a bunch of syscalls, such as  fork() ,  execv() ,  mmap() , munmap() ,  mremap() ,  brk() .  2)  page reclaim, which needs to unmap all ptes for a\ngiven swapped page. Other than  fork()  and  execv() , other vm related syscalls\nare invoked very frequently for a typical datacenter application. Moreover, page\nreclaim and swap also run concurrently to gain exclusive access to rmap.  So, rmap operations have to be fast. Directly pointing to pte seems the best\nsolution here. However, this fine-granularity design will consume a lot memory\nfor the per-pte list.\nFurthermore, vma creation, deletion, split and merge happen frequently, the overhead\nto manage rmap is quite high. No wonder Linux choses another object-based way to do so,\nwhich leverages vma itself to take a longer path towards pte.  The important question is:  does this naive solution fit  current  Lego?  Yes, it fits, for several reasons.  1)  Current Lego run static-linked ELF binary only,\nthus there will not be any shared hot library pages, which implies rmap list maintenance\nis simplified.  2)  Our targeted applications\nmostly are single process. Even for multiple process ones, the number of processes\nstay stable and  fork()  happen at early init time.  3)  major users of rmap such\nas  mremap()  and  munmap()   perform rmap operation explicitly,  mmap()  perform\nrmap implicitly via pgfault (or pcache miss),  pcache reclaim  perform sweep async.\nAll of them, combined with 1) and 2), most of the time will perform rmap operation\non a single pte.", 
            "title": "Design"
        }, 
        {
            "location": "/lego/pcache/rmap/#internal", 
            "text": "The following table describes different contexts that manipulate rmap data structures. Currently, rmap only has four possible operations. The context field describes the large context that trigger such rmap operation. The related functions and pcache callback field lists functions that actually did the dirty work.     rmap operation  Context  Related functions and pcache callback      Add  fork()   pgfault  copy_pte_range()  -   pcache_copy_pte()     pcache_add_rmap()    Remove  munmap()     exit_mmap()  zap_pte_range()  -   pcache_zap_pte()    Update  mremap()  move_ptes()  -   pcache_move_pte()    Lookup  pcache eviction sweep, etc.  pcache_referenced() ,  pcache_wrprotect()     pcache_try_to_unmap()", 
            "title": "Internal"
        }, 
        {
            "location": "/lego/pcache/rmap/#thought", 
            "text": "One function I personally love the most is  rmap_walk() , whose name pretty much tells the story. To use  rmap_walk() , caller passes a  struct rmap_walk_control , which including caller specific callback for each rmap. This function also isolates the specific data structures used by rmap from various callers. In Lego, a lot pcache functions are built upon  rmap_walk() .  struct rmap_walk_control , or  struct scan_control , or  struct something_control  are used a lot by Linux kernel. Personally I do love this way of doing data structure walk, or reuse functions. However, even this way can greatly reduce duplicated code size, it will make the code unnecessary complex. As a system developer, no more expects to see a function longer than 100 lines. People love saying:  Do one thing and do it better , while it not always works that perfectly. Coding is nothing different life, it is all about trade-off.  \nYizhou Shan \nFeb 02, 2018", 
            "title": "Thought"
        }, 
        {
            "location": "/lego/pcache/smp_design/", 
            "text": "SMP Design Thought\n\n\nCoding pcache is nothing different from coding mm code. It is the same with your familiar mixed pgfault, LRU, page cache and writeback code. Each pcache line can be involved with multiple activities at the same time. We have to use different states to synchronize among them. If you have ever read linux mm code, you will know that sometimes, comment is literally more than code. SMP pain in ass.\n\n\nI don\nt think this document is well written. It is just some random thoughts I wrote down while coding. Some of them might be wrong. But it is still worth looking back.\n\n\nPcache and Victim Cache Organization\n\n\nOur pcache and victim cache are allocated and arranged as a big array. As for\npcache we look at it in a \ncache set view\n, which means consecutive pcache lines\nare not relevant in natual. As for victim cache, we simply treat it as a big array\nand walk through it one by one.\n\n\nAllocation/Eviction SMP Consideration\n\n\nThe alloc/free of both pcache and victim cache are simple: each pcache line or\nvictim cache line has a \nAllocated\n bit to indicate if this line is free or not.\nThe \nAllocated\n bit is manipulated by atomic bit operations, thus SMP safe. This\nfurther implies that we do not need another spinlock to guard allocation.\n\n\nHowever, other activities such as explict eviction, background sweep may walk\nthrough the cache lines at the same time of cache allocation, a single \nAllocated\n\nbit is not enough. Because an allocated cache line will need some initial setup,\nsuch as reset refcount, clear flags (prep_new_pcache),\nthus there is a small time gap between Allocated bit being set and the cache line\nbeing truly safe to use. Other activities must wait the cache line to be usable,\nand then they can do further operations on this cache line.\n\n\nTo solve this race condition, there two possible solutions:\n1) Add another bit: \nUsable\n, which is set once initial setup is done.\n   In this case, functions excluding alloction code should always check if the \nUsable\n\n   bit is set or not. a) If it is set, this means the cache line is safe for further operations\n   b) If not, and \nAllocated\n bit is set, this means the cache line is under setup in another core,\n   We should skip it.\n   c) If not, and \nAllocated\n bit is not set, this means this cache line is simply free.\n   We should skip it.\n\n\n2) Add allocated cache lines to a list (such as LRU list), and functions excluding allocation\n   code will only look into cache lines within this list. In other words, others will only\n   look into surely usable cache lines.\n\n\nBoth solutions try to avoid others looking into \nun-mature\n cache lines in SMP envorinment.\nThe rule is simple: function should \nNOT\n look into data that is not supposed to be seen.\nThe cache line that has Allocated bit set but under setup is a typical case.\n\n\nAs an example, the physical page allocator, page reclaim, page cache in Linux are implemented with\nthe second solution. Pages freshly allocated will be added a LRU list or page cache own list.\nAnd page reclaim code will only look into pages within the LRU list, it will not go through all\nphysical pages to do so. The reason for Linux to do so is simple: kernel can not scan the whole\nphysical pages to find out pages to operate.\n\n\nPcache:\n When it comes to pcache, we use both.\nIn our envision, pcache will have high-associativity such as 64 or 128.\nIt will have very bad performance if our eviction algorithm or sweep thread need to go through every\ncache lines within a set to find out candidates, while there might be only 1 or 2 allocated lines.\nHowever, additional \nUsable\n bit is added for debug purpose.\n\n\nVictim Cache:\n When it comes to victim cache, the first solution seems a better choice.\nBecause victim cache only a few cache lines, e.g., 8 or 16. This means a whole victim cache line\nwalk is fast. While the list deletion and addition seem may introduce some unnecessary overhead.\nIt is all about trade-off.\n\n\nThese choices affect the usage of pcache and victim cache, mostly the eviction code.\n\n\nMore on above two solutions\n\n\nThe first solution is used if evict_random is configured. The second solution is used when\nevict_lru is configured.\n\n\nI do not have any doubt about second solution, it works, though with a lot SMP pain in ass.\nBut I do have more to say about the first solution, which is adding another usable bit.\nThe \nUsable\n bit \nonly\n ensures other threads will not use unmature pcache, but it can not\nprevent other threads seeing a going-to-be-freed pcache.\n\n\nWhat is this going-to-be-freed asshole? Let us consider this case: CPU0 is doing eviction\nand checked the \nUsable\n bit, which is set. Then CPU0 thought this cache line is all set,\nready to be torqued. Before doing all the dirty work, CPU0 will \nget_pcache_unless_zero()\n\nfirst to make sure the pcache will not go away in the middle. However, meanwhile, CPU1 did\na \nput_pcache()\n \nand\n a consecutive \npcache_alloc()\n right before CPU0 did called\n\nget_pcache_unless_zero()\n. Bang! CPU0 may use an mature pcache line, cause CPU1\ns \npcache_init_ref_count()\n\nmay come before CPU1\ns \nget_pcache_unless_zero()\n! How to solve this? CPU0 need to add\nadditional checking after \nget_pcache_unless_zero()\n.\n\n\nFor more details, please check the code in \npcache/evcit_random.c\n, which has more pretty explanation.\n\n\n\nYizhou Shan\n\nJan 31, 2018", 
            "title": "SMP Design"
        }, 
        {
            "location": "/lego/pcache/smp_design/#smp-design-thought", 
            "text": "Coding pcache is nothing different from coding mm code. It is the same with your familiar mixed pgfault, LRU, page cache and writeback code. Each pcache line can be involved with multiple activities at the same time. We have to use different states to synchronize among them. If you have ever read linux mm code, you will know that sometimes, comment is literally more than code. SMP pain in ass.  I don t think this document is well written. It is just some random thoughts I wrote down while coding. Some of them might be wrong. But it is still worth looking back.", 
            "title": "SMP Design Thought"
        }, 
        {
            "location": "/lego/pcache/smp_design/#pcache-and-victim-cache-organization", 
            "text": "Our pcache and victim cache are allocated and arranged as a big array. As for\npcache we look at it in a  cache set view , which means consecutive pcache lines\nare not relevant in natual. As for victim cache, we simply treat it as a big array\nand walk through it one by one.", 
            "title": "Pcache and Victim Cache Organization"
        }, 
        {
            "location": "/lego/pcache/smp_design/#allocationeviction-smp-consideration", 
            "text": "The alloc/free of both pcache and victim cache are simple: each pcache line or\nvictim cache line has a  Allocated  bit to indicate if this line is free or not.\nThe  Allocated  bit is manipulated by atomic bit operations, thus SMP safe. This\nfurther implies that we do not need another spinlock to guard allocation.  However, other activities such as explict eviction, background sweep may walk\nthrough the cache lines at the same time of cache allocation, a single  Allocated \nbit is not enough. Because an allocated cache line will need some initial setup,\nsuch as reset refcount, clear flags (prep_new_pcache),\nthus there is a small time gap between Allocated bit being set and the cache line\nbeing truly safe to use. Other activities must wait the cache line to be usable,\nand then they can do further operations on this cache line.  To solve this race condition, there two possible solutions:\n1) Add another bit:  Usable , which is set once initial setup is done.\n   In this case, functions excluding alloction code should always check if the  Usable \n   bit is set or not. a) If it is set, this means the cache line is safe for further operations\n   b) If not, and  Allocated  bit is set, this means the cache line is under setup in another core,\n   We should skip it.\n   c) If not, and  Allocated  bit is not set, this means this cache line is simply free.\n   We should skip it.  2) Add allocated cache lines to a list (such as LRU list), and functions excluding allocation\n   code will only look into cache lines within this list. In other words, others will only\n   look into surely usable cache lines.  Both solutions try to avoid others looking into  un-mature  cache lines in SMP envorinment.\nThe rule is simple: function should  NOT  look into data that is not supposed to be seen.\nThe cache line that has Allocated bit set but under setup is a typical case.  As an example, the physical page allocator, page reclaim, page cache in Linux are implemented with\nthe second solution. Pages freshly allocated will be added a LRU list or page cache own list.\nAnd page reclaim code will only look into pages within the LRU list, it will not go through all\nphysical pages to do so. The reason for Linux to do so is simple: kernel can not scan the whole\nphysical pages to find out pages to operate.  Pcache:  When it comes to pcache, we use both.\nIn our envision, pcache will have high-associativity such as 64 or 128.\nIt will have very bad performance if our eviction algorithm or sweep thread need to go through every\ncache lines within a set to find out candidates, while there might be only 1 or 2 allocated lines.\nHowever, additional  Usable  bit is added for debug purpose.  Victim Cache:  When it comes to victim cache, the first solution seems a better choice.\nBecause victim cache only a few cache lines, e.g., 8 or 16. This means a whole victim cache line\nwalk is fast. While the list deletion and addition seem may introduce some unnecessary overhead.\nIt is all about trade-off.  These choices affect the usage of pcache and victim cache, mostly the eviction code.", 
            "title": "Allocation/Eviction SMP Consideration"
        }, 
        {
            "location": "/lego/pcache/smp_design/#more-on-above-two-solutions", 
            "text": "The first solution is used if evict_random is configured. The second solution is used when\nevict_lru is configured.  I do not have any doubt about second solution, it works, though with a lot SMP pain in ass.\nBut I do have more to say about the first solution, which is adding another usable bit.\nThe  Usable  bit  only  ensures other threads will not use unmature pcache, but it can not\nprevent other threads seeing a going-to-be-freed pcache.  What is this going-to-be-freed asshole? Let us consider this case: CPU0 is doing eviction\nand checked the  Usable  bit, which is set. Then CPU0 thought this cache line is all set,\nready to be torqued. Before doing all the dirty work, CPU0 will  get_pcache_unless_zero() \nfirst to make sure the pcache will not go away in the middle. However, meanwhile, CPU1 did\na  put_pcache()   and  a consecutive  pcache_alloc()  right before CPU0 did called get_pcache_unless_zero() . Bang! CPU0 may use an mature pcache line, cause CPU1 s  pcache_init_ref_count() \nmay come before CPU1 s  get_pcache_unless_zero() ! How to solve this? CPU0 need to add\nadditional checking after  get_pcache_unless_zero() .  For more details, please check the code in  pcache/evcit_random.c , which has more pretty explanation.  \nYizhou Shan \nJan 31, 2018", 
            "title": "More on above two solutions"
        }, 
        {
            "location": "/lego/paper/nmp/", 
            "text": "Near Memory Processing\n\n\n\n\nNMP: Near Memory Processing\n\n\n\n\nNDC: Near Data Computing\n\n\n\n\n\n\nPRIME\n:\n \nA\n \nNovel\n \nProcessing\n-\nin\n-\nmemory\n \nArchitecture\n \nfor\n \nNeural\n \nNetwork\nComputation\n \nin\n \nReRAM\n-\nbased\n \nMain\n \nMemory\n,\n \nISCA\n16\n\n\n\n\nHigh-performance\nacceleration of NN requires high memory bandwidth since\nthe \nPUs are hungry for fetching the synaptic weights [17]\n. To\naddress this challenge, recent special-purpose chip designs\nhave adopted large on-chip memory to store the synaptic\nweights. For example, DaDianNao [18] employed a large\non-chip eDRAM for both high bandwidth and data locality;\nTrueNorth utilized an SRAM crossbar memory for synapses\nin each core [19].\n\n\n\n\n\n\nDianNao\n and \nDaDianNao\n\n\n \nmemory bandwidth requirements\n of two important\nlayer types: convolutional layers with private kernels\n(used in DNNs) and classifier layers used in both CNNs and\nDNNs. For these types of layers, the total number of required\nsynapses can be massive, in the millions of parameters, or\neven tens or hundreds thereof.\n\n\nproviding sufficient eDRAM capacity to hold\nall \nsynapse\n on the combined eDRAM of all chips will\nsave on \noff-chip DRAM accesses\n, which are particularly\ncostly energy-wise\n\n\nSynapses\n. In a perceptron layer, all synapses are usually\nunique, and thus there is no reuse within the layer. On the\nother hand, the synapses are reused across network invocations,\ni.e., for each new input data (also called \u201cinput row\u201d)\npresented to the neural network. So a sufficiently large L2\ncould store all network synapses and take advantage of that\nlocality. For DNNs with private kernels, this is not possible\nas the total number of synapses are in the tens or hundreds\nof millions (the largest network to date has a billion\nsynapses [26]). However, for both CNNs and DNNs with\nshared kernels, the total number of synapses range in the\nmillions, which is within the reach of an L2 cache. In Figure\n6, see CLASS1 - Tiled+L2, we emulate the case where reuse\nacross network invocations is possible by considering only\nthe perceptron layer; as a result, the total bandwidth requirements\nare now drastically reduced.\n\n\nSo, ML workloads do need large memory bandwidth, and need a lot memory. But how about \ntemporary working set size\n? It\ns the best if it has a reasonable working set size that can fit the cache.\n\n\n\n\n\n\nTPU\n\n\nEach model needs between 5M and 100M weights (9\nth\n\ncolumn of Table 1), which can take a lot of time and energy to\naccess. To amortize the access costs, \nthe same weights are reused\nacross a batch of independent examples during inference or\ntraining\n, which improves performance.\n\n\nThe weights for the matrix unit are staged through an onchip\n\nWeight FIFO\n that reads from an \noff-chip 8 GiB DRAM\ncalled Weight Memory\n (for inference, weights are read-only; 8\nGiB supports many simultaneously active models). The weight\nFIFO is four tiles deep. The intermediate results are held in the \n24\nMiB on-chip Unified Buffer\n, which can serve as inputs to the Matrix Unit.\n\n\nIn virtual cache model, we actually can assign those weights to some designated sets, thus avoid conflicting with other data, which means we can sustain those weights in cache!\n\n\n\n\n\n\n\n\nTo conclude:\n\n\na)\n ML needs to use weight/synapses during computation, and those data will be reused repeatly across different stages. Besides, output from last stage serves the input of next stage, so buffering the \nintermediate data\n is important. Most ML accelerators use some kind of \non-chip memory\n (\nWeighted FIFO, Unified Cache in TPU\n) to buffer those data. This fits the \nHBM+Disaggregated Memory\n model: HBM is the on-chip memory, while disaggregated memory is the off-chip memory. \nb)\n Combined with virtual cache, we could assign special virtual addresses to weight data, so they stay in some designated cache sets. Kernel can avoid allocating conflict virtual addresses later. Thus we can retain these weight data in virtual cache easily.", 
            "title": "NMP"
        }, 
        {
            "location": "/lego/paper/nmp/#near-memory-processing", 
            "text": "NMP: Near Memory Processing   NDC: Near Data Computing    PRIME :   A   Novel   Processing - in - memory   Architecture   for   Neural   Network Computation   in   ReRAM - based   Main   Memory ,   ISCA 16   High-performance\nacceleration of NN requires high memory bandwidth since\nthe  PUs are hungry for fetching the synaptic weights [17] . To\naddress this challenge, recent special-purpose chip designs\nhave adopted large on-chip memory to store the synaptic\nweights. For example, DaDianNao [18] employed a large\non-chip eDRAM for both high bandwidth and data locality;\nTrueNorth utilized an SRAM crossbar memory for synapses\nin each core [19].    DianNao  and  DaDianNao    memory bandwidth requirements  of two important\nlayer types: convolutional layers with private kernels\n(used in DNNs) and classifier layers used in both CNNs and\nDNNs. For these types of layers, the total number of required\nsynapses can be massive, in the millions of parameters, or\neven tens or hundreds thereof.  providing sufficient eDRAM capacity to hold\nall  synapse  on the combined eDRAM of all chips will\nsave on  off-chip DRAM accesses , which are particularly\ncostly energy-wise  Synapses . In a perceptron layer, all synapses are usually\nunique, and thus there is no reuse within the layer. On the\nother hand, the synapses are reused across network invocations,\ni.e., for each new input data (also called \u201cinput row\u201d)\npresented to the neural network. So a sufficiently large L2\ncould store all network synapses and take advantage of that\nlocality. For DNNs with private kernels, this is not possible\nas the total number of synapses are in the tens or hundreds\nof millions (the largest network to date has a billion\nsynapses [26]). However, for both CNNs and DNNs with\nshared kernels, the total number of synapses range in the\nmillions, which is within the reach of an L2 cache. In Figure\n6, see CLASS1 - Tiled+L2, we emulate the case where reuse\nacross network invocations is possible by considering only\nthe perceptron layer; as a result, the total bandwidth requirements\nare now drastically reduced.  So, ML workloads do need large memory bandwidth, and need a lot memory. But how about  temporary working set size ? It s the best if it has a reasonable working set size that can fit the cache.    TPU  Each model needs between 5M and 100M weights (9 th \ncolumn of Table 1), which can take a lot of time and energy to\naccess. To amortize the access costs,  the same weights are reused\nacross a batch of independent examples during inference or\ntraining , which improves performance.  The weights for the matrix unit are staged through an onchip Weight FIFO  that reads from an  off-chip 8 GiB DRAM\ncalled Weight Memory  (for inference, weights are read-only; 8\nGiB supports many simultaneously active models). The weight\nFIFO is four tiles deep. The intermediate results are held in the  24\nMiB on-chip Unified Buffer , which can serve as inputs to the Matrix Unit.  In virtual cache model, we actually can assign those weights to some designated sets, thus avoid conflicting with other data, which means we can sustain those weights in cache!     To conclude:  a)  ML needs to use weight/synapses during computation, and those data will be reused repeatly across different stages. Besides, output from last stage serves the input of next stage, so buffering the  intermediate data  is important. Most ML accelerators use some kind of  on-chip memory  ( Weighted FIFO, Unified Cache in TPU ) to buffer those data. This fits the  HBM+Disaggregated Memory  model: HBM is the on-chip memory, while disaggregated memory is the off-chip memory.  b)  Combined with virtual cache, we could assign special virtual addresses to weight data, so they stay in some designated cache sets. Kernel can avoid allocating conflict virtual addresses later. Thus we can retain these weight data in virtual cache easily.", 
            "title": "Near Memory Processing"
        }, 
        {
            "location": "/lego/paper/processor_oom/", 
            "text": "Process/Memory Kernel Memory\n\n\nThis document is based on discussion with Yiying, about how to deal with processor or memory component\ns out-of-kernel-memory situation. It mainly bothers processor component, which has a small kernel memory while needs to support all running user threads.\n\n\nProcess\ns local kernel memory is limited by design. There are several major users:\n\n\n\n\n1) pcache\ns rmap, which is propotional to pcache size.\n\n\n2) IB, which depends on concurrent outgoing messages.\n\n\n3) running threads. For each thread at processor, Lego needs to allocate some kernel memory for it, e.g, \nkernel stack\n, \ntask_strcut\n, and so on.\n\n\n\n\nBoth 1) and 2) are fine, they can be easily controlled. However we can not limit how many threads user can create, thus 3) becomes the critical criminal of oom.\n\n\nWhen processor is running out of kernel memory, Lego needs to deal with it. Currently, we propose three different solutions:\n\n\n\n\ns1) \nSwap\n kernel memory to remote memory component\n\n\ns2) \nKill\n some threads to have some usable memory (OOM killer)\n\n\ns3) \nMigrate\n, or \ncheckpoint\n, threads to processors that have usable kernel memory\n\n\n\n\nFor solution 3), there is a case where \nall\n processors are running out of memory. Then we have to use solution 1) or 2).\n\n\n\nYizhou Shan\n\nFeb 17, 2018", 
            "title": "processor_oom"
        }, 
        {
            "location": "/lego/paper/processor_oom/#processmemory-kernel-memory", 
            "text": "This document is based on discussion with Yiying, about how to deal with processor or memory component s out-of-kernel-memory situation. It mainly bothers processor component, which has a small kernel memory while needs to support all running user threads.  Process s local kernel memory is limited by design. There are several major users:   1) pcache s rmap, which is propotional to pcache size.  2) IB, which depends on concurrent outgoing messages.  3) running threads. For each thread at processor, Lego needs to allocate some kernel memory for it, e.g,  kernel stack ,  task_strcut , and so on.   Both 1) and 2) are fine, they can be easily controlled. However we can not limit how many threads user can create, thus 3) becomes the critical criminal of oom.  When processor is running out of kernel memory, Lego needs to deal with it. Currently, we propose three different solutions:   s1)  Swap  kernel memory to remote memory component  s2)  Kill  some threads to have some usable memory (OOM killer)  s3)  Migrate , or  checkpoint , threads to processors that have usable kernel memory   For solution 3), there is a case where  all  processors are running out of memory. Then we have to use solution 1) or 2).  \nYizhou Shan \nFeb 17, 2018", 
            "title": "Process/Memory Kernel Memory"
        }, 
        {
            "location": "/lego/paper/genz/", 
            "text": "Gen-Z\n\n\nOpenCAPI\n\n\nCCIX\n\n\nOmniPath\n\n\nPCIe 3.0\n\n\nPCIe 4.0\n\n\n\n\n\n\n\n\n\n\nProducts\n\n\nN/A\n\n\nPower9\n\n\n?\n\n\nIntel\n\n\nA lot\n\n\nComing Soon\n\n\n\n\n\n\nDomain\n\n\ncross components\n\n\nMotherboard\n\n\nMotherboard\n\n\ncross components\n\n\nMotherboard\n\n\nMotherboard\n\n\n\n\n\n\nSemantic\n\n\nmemory\n\n\nmemory\n\n\nmemory\n\n\nnetwork+pcie\n\n\npcie\n\n\npcie\n\n\n\n\n\n\nBandwidth\n\n\n32GBps ~ 400+GBps \n \nUnidirectional\n\n\n25GBps/lane x4~x32 \n \nUnidirectional\n\n\n16/20/25 GBps/lane \n \nUnidirectional\n\n\n25 GBps/port \n \nBidirectional\n\n\n~1GBps/lane\n\n\n~2GBps/lane\n\n\n\n\n\n\nLatency\n\n\nsub 100-ns\n\n\n.\n\n\n.\n\n\n.\n\n\n.\n\n\n.\n\n\n\n\n\n\n\n\nReferences:\n- \nhttps://www.openfabrics.org/images/eventpresos/2017presentations/213_CCIXGen-Z_BBenton.pdf\n\n- \nhttps://www.anandtech.com/show/11967/pcisig-finalizes-and-releasees-pcie-40-spec", 
            "title": "genz"
        }
    ]
}