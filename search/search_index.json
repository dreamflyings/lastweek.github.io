{
    "docs": [
        {
            "location": "/", 
            "text": "My name is \nYizhou Shan\n. I\nm a second-year Ph.D. student at \nPurdue ECE\n,\nadvised by Prof. \nYiying Zhang\n. Our lab is \nWuklab.io\n. Yes, the \nMonkey King\n Lab.\nPlease find my CV \nhere\n.\n\n\nI\nm currently looking for summer 2018 intern.\n\n\nResearch\n\n\nMy research interests span Operating System, Distributed Systems,\nand Non-Volatile Memory. I like hacking kernel and no doubt Linux is my\nfavorite open-source project.\n\n\nContact\n\n\n465 Northwestern Ave\n\nPurdue University\n\nWest Lafayette, IN 47907\n\nOffice: EE 345  \n\n\nEmail: \n\n\nConferences and Workshops\n\n\n\n\nDistributed Shared Persistent Memory\n, NVMW\n18\n\n\nDisaggregated Operating System\n, HPTS\n17\n\n\nDistributed Shared Persistent Memory\n, SoCC\n17\n\n\n\n\nPosters\n\n\n\n\nLego: A Distributed, Decomposed OS for Resource Disaggregation\n, SOSP\n17\n\n\nDisaggregated Operating System\n, SoCC\n17\n\n\n\n\nSocial\n\n\n\n\nGithub\n\n\nInstagram", 
            "title": "Home"
        }, 
        {
            "location": "/#research", 
            "text": "My research interests span Operating System, Distributed Systems,\nand Non-Volatile Memory. I like hacking kernel and no doubt Linux is my\nfavorite open-source project.", 
            "title": "Research"
        }, 
        {
            "location": "/#contact", 
            "text": "465 Northwestern Ave \nPurdue University \nWest Lafayette, IN 47907 \nOffice: EE 345    Email:", 
            "title": "Contact"
        }, 
        {
            "location": "/#conferences-and-workshops", 
            "text": "Distributed Shared Persistent Memory , NVMW 18  Disaggregated Operating System , HPTS 17  Distributed Shared Persistent Memory , SoCC 17", 
            "title": "Conferences and Workshops"
        }, 
        {
            "location": "/#posters", 
            "text": "Lego: A Distributed, Decomposed OS for Resource Disaggregation , SOSP 17  Disaggregated Operating System , SoCC 17", 
            "title": "Posters"
        }, 
        {
            "location": "/#social", 
            "text": "Github  Instagram", 
            "title": "Social"
        }, 
        {
            "location": "/misc/cheatsheet/", 
            "text": "cheatsheet\n\n\nvirsh\n\n\n\n\nPass commands to QEMU in the virsh bash:\n\n1\n# qemu-monitor-command guest_os_id --hmp \ninfo cpus\n\n\n\n\n\n\n\n\nQEMU\n\n\n\n\nRun standalone kernel:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n# Create a new directory to store the serial output from printk().\n\n\nOUTPUT_DIR\n=\ntest-output\n\n\nif\n \n[\n -e \n$OUTPUT_DIR\n \n]\n;\n \nthen\n\n        \nif\n \n[\n -f \n$OUTPUT_DIR\n \n]\n;\n \nthen\n\n                \necho\n \nERROR: \n$OUTPUT_DIR\n is not a directly\n\n                \nexit\n \n1\n\n        \nfi\n\n\nelse\n\n        mkdir -p \n$OUTPUT_DIR\n\n\nfi\n\n\n\nKERNEL\n=\narch/x86_64/boot/bzImage\n\n\nKERNEL_PARAM\n=\nconsole=ttyS0 earlyprintk=serial,ttyS0,115200\n\n\nSERIAL\n=\n-serial file:\n$OUTPUT_DIR\n/ttyS0 -serial file:\n$OUTPUT_DIR\n/ttyS1\n\n\n\n# -cpu Haswell,+tsc,+sse,+xsave,+aes,+avx,+erms,+pdpe1gb,+pge \\\n\n\n# Above -cpu option may not work with some kernels.\n\nqemu-system-x86_64 -s  \n\\\n\n        -nographic \n\\\n\n        -kernel \n$KERNEL\n -append \n$KERNEL_PARAM\n \n\\\n\n        -no-reboot \n\\\n\n        -d int,cpu_reset -D \n$OUTPUT_DIR\n/qemu.log \n\\\n\n        \n$SERIAL\n \n\\\n\n        -m 16G \n\\\n\n        -monitor stdio \n\\\n\n        -smp \ncpus\n=\n24\n,cores\n=\n12\n,threads\n=\n2\n,sockets\n=\n2\n \n\\\n\n        -numa node,cpus\n=\n0\n-11,mem\n=\n8G,nodeid\n=\n0\n \n\\\n\n        -numa node,cpus\n=\n12\n-23,mem\n=\n8G,nodeid\n=\n1\n\n\n\n\n\n\n\n\nMarkdown\n\n\n\n\nEmoji cheatsheet", 
            "title": "Cheatsheet"
        }, 
        {
            "location": "/misc/cheatsheet/#cheatsheet", 
            "text": "", 
            "title": "cheatsheet"
        }, 
        {
            "location": "/misc/cheatsheet/#virsh", 
            "text": "Pass commands to QEMU in the virsh bash: 1 # qemu-monitor-command guest_os_id --hmp  info cpus", 
            "title": "virsh"
        }, 
        {
            "location": "/misc/cheatsheet/#qemu", 
            "text": "Run standalone kernel:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28 # Create a new directory to store the serial output from printk().  OUTPUT_DIR = test-output  if   [  -e  $OUTPUT_DIR   ] ;   then \n         if   [  -f  $OUTPUT_DIR   ] ;   then \n                 echo   ERROR:  $OUTPUT_DIR  is not a directly \n                 exit   1 \n         fi  else \n        mkdir -p  $OUTPUT_DIR  fi  KERNEL = arch/x86_64/boot/bzImage  KERNEL_PARAM = console=ttyS0 earlyprintk=serial,ttyS0,115200  SERIAL = -serial file: $OUTPUT_DIR /ttyS0 -serial file: $OUTPUT_DIR /ttyS1  # -cpu Haswell,+tsc,+sse,+xsave,+aes,+avx,+erms,+pdpe1gb,+pge \\  # Above -cpu option may not work with some kernels. \nqemu-system-x86_64 -s   \\ \n        -nographic  \\ \n        -kernel  $KERNEL  -append  $KERNEL_PARAM   \\ \n        -no-reboot  \\ \n        -d int,cpu_reset -D  $OUTPUT_DIR /qemu.log  \\ \n         $SERIAL   \\ \n        -m 16G  \\ \n        -monitor stdio  \\ \n        -smp  cpus = 24 ,cores = 12 ,threads = 2 ,sockets = 2   \\ \n        -numa node,cpus = 0 -11,mem = 8G,nodeid = 0   \\ \n        -numa node,cpus = 12 -23,mem = 8G,nodeid = 1", 
            "title": "QEMU"
        }, 
        {
            "location": "/misc/cheatsheet/#markdown", 
            "text": "Emoji cheatsheet", 
            "title": "Markdown"
        }, 
        {
            "location": "/misc/jasmine/", 
            "text": "Cool and good-to-know stuff:\n\n\n\n\n\n\nServeless\n\n\n\n\nAWS Lambda\n\n\nGoogle Cloud Function\n\n\nAzure Functions\n\n\n\n\n\n\n\n\nSDS\n\n\n\n\nTidalScale\n\n\nScaleMP\n\n\n\n\n\n\n\n\nApache Crail\n\n\n\n\n\n\nRedis Lab\n\n\n\n\n\n\nJournaling of journal\n\n\n\n\n\n\nConcurrent Data Structures\n\n\n\n\nNUMA-aware data structures\n\n\nlinearizability\n\n\nlock-free skip list\n\n\nblog", 
            "title": "Jasmine"
        }, 
        {
            "location": "/lego/log/log-02-2018/", 
            "text": "Feb 2018\n\n\n\n\n02/19 Mon Rainy\n\n\nIt is another week. I can not deny I\nm a little tired about the bug. Tried so many possible solutions, but none of them work. Well, today I first need to test the vma changes (pgoff and anon_vma) thing. Especially the vma merge and split.\n\n\nThis morning I fixed a bug in kernel_init process: make kernel_init able to run all possible CPUs. Because the first user process is forked from kernel_init, it is quite important that it gets the right cpu affinity:\n\n1\n2\n3\n4\n5\n6\nstatic\n \nint\n \nkernel_init\n(\nvoid\n \n*\nunused\n)\n\n\n{\n\n        \n...\n\n        \nset_cpus_allowed_ptr\n(\ncurrent\n,\n \ncpu_possible_mask\n);\n\n        \n...\n\n\n}\n\n\n\n\n\n\nWell, interestingly, the unmodified word_count-pthread succeed with 50MB dataset\n with or without any DEBUG option! Amazing! I need to find out why the cpus_allowed becomes 0 at the beginning of kernel_init. Because \ninit_task\n actually has:\n\n1\n2\n    \n.\ncpus_allowed\n   \n=\n \nCPU_MASK_ALL\n,\n\n    \n.\nnr_cpus_allowed\n=\n \nNR_CPUS\n,\n\n\n\n\n\n\nThings to do next:\n\n\n\n\ncheck why the cpus_allowed changed\n\n\ncheck why word_count-pthread open \n/dev/../cpu\n so many times. Anything wrong with our \ncopy_files\n, or open, close?\n\n\nhere is an idea, to verify if FPU code is correct, run some scientific benchmarks.\n\n\n\n\nOkay, findings:\n\n\n\n\ncpus_allowd is fine, it is reset inside \nsched_init()\n, when it tries make the \ninit_task\n as the \nidle\n thread. Thus it is reasonable to set cpus_allowed again at \nkernel_init\n thread.\n\n\n\n\n\n\n02/18 Sun Sunny\n\n\nIt is a nice day. Yesterday I\nve changed one line of code in mmap code path: change anonymous vma\ns pgoff from some value to 0. The result is I got several succeed work-count-pthread(bind to one core) testing. However, it still fail with unmodified word-count-pthread.\n\n\nIt brings me to inspect pgoff manipulation code and all mmap.c code. We ported everything from linux without almost zero modification. That means we ported all those useless \nanon_vma\n and pgoff code, which is used a lot by vma_merge, vma_split code. The thing is: our memory manager, our vma code do not need such \nanon_vma\n structure, and do not maintain pgoff. Thus, I\nm a little bit worried linux code may doing some crazy behind our back: mess vma and pages, then pcache miss gets some wrong pages\n\n\nWell. Lego does not use \nanon_vma\n, and pgoff should only be used by file-backed vma. So, I decided to remove \nanon_vma\n from our code, and make sure pgoff is used properly. Of course, the goal is to make vma_merge, split,\ncopy, do the things we intended.\n\n\nLesson learned.\n\n\n\n\n02/17 Sat Snowy\n\n\nFixed the bss bug. It comes from loader. We did not implement the \nlego_clear_user\n function, so some part of bss is non-zero.\n\n\nBad news is word_count-pthread still fail at same fpu instruction. Have to look into memory code more.\n\n\nThis is actually a fun debugging story. We should always add TODO or XXX or some warnings to unfinished code, no matter what. Lesson learned.\n\n\n\n\n02/16 Fri Cloudy\n\n\nYilun found a major loader bug yesterday: the \n.bss\n section variables are not 0, in the \niozone\n benchmark. I did not encounter this issue before with simple test program. This is pretty serious.\n\n\n\n\n02/15 Thur Rainy\n\n\nToday is Chinese New Year.\n\n\nLine 7 and 8 show the uva belong to the same page. Need to revisit \nget_arg_pages\n etc functions.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n[  108.393991] handle_p2m_execve(): pid:22,argc:2,envc:2,file:/root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread\n[  108.395255]     argc[0] (len: 65):  /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread\n[  108.396329]     argc[1] (len: 82):  /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_100MB.txt\n[  108.397530]     envc[0] (len:  7):  HOME=/\n[  108.398069]     envc[1] (len: 11):  TERM=linux\n[  108.398640] __bprm_mm_init vma: ffff88083effe6b8\n\n[  108.399226] faultin_page vma: ffff88083effe6b8 uva: 0x7fffffffefed\n\n[  108.399949] faultin_page vma: ffff88083effe6b8 uva: 0x7fffffffef94\n\n\n\n\n\n\nWell, this is 100% fine. I wrote this loader code long time ago and need some time to pickup. So, after I read the loader code, especially the \ncopy_strings\n function, I found this is okay. Because copy_strings will be invoked three times, so the \nfaultin_page\n basically will be invoked at least three times. That is why it went to that pte fault handling code.\n\n\nAlthough actually I think \ncopy_strings\n should \nnot\n use \nfaultin_page\n, instead, it should use \nget_user_pages\n, which will walk through the pgtable first, then went to \nhandle_lego_mm_fault\n.\n\n\n\n\n02/14 Wed Rainy\n\n\nHmm, tried to make kmalloc behave as kzalloc, and bind all threads to one core, still gave the same old bug:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n  42731a:       f3 0f 6f 16             movdqu (%rsi),%xmm2\n\n\n  [93182.657376] word_count-pthr[85] general protection ip:42731a sp:7fffe3ffed28 error:0\n  [93182.747959] CPU: 8 PID: 85 Comm: word_count-pthr 4.0.0-lego+ #170\n  [93182.820758] RIP: 0033:[\n000000000042731a\n]  [\n000000000042731a\n] 0x42731a\n  [93182.901878] RSP: 002b:00007fffe3ffed28  EFLAGS: 00010283\n  [93182.965317] RAX: 000000000000001f RBX: 00007ffff001b010 RCX: 0000000000000005\n  [93183.050596] RDX: 0000000000000000 RSI: 5345485355420045 RDI: 00007ffff294791f\n  [93183.135876] RBP: 00007ffff294791f R08: 000000000000ffff R09: 0000000000000008\n  [93183.221156] R10: fffffffffffff048 R11: 00000000004acfc0 R12: 0000000000001cde\n  [93183.306435] R13: 00000000006e4a8c R14: 0000000000001cd7 R15: 0000000000001cda\n  [93183.391716] FS:  00007fffe3fff700(0000) GS:ffff88107fc80000(0000) knlGS:0000000000000000\n  [93183.488434] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n  [93183.557075] CR2: 00007ffff27a4000 CR3: 000000107e924000 CR4: 00000000000406a0\n\n\n\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n  427377:       66 0f 6f 17             movdqa (%rdi),%xmm2\n\n\n  [93180.527248] word_count-pthr[93]: segfault at 0x0 ip 0000000000427377 sp 00007fffdfff6d28 error 4\n  [93180.630314] CPU: 8 PID: 93 Comm: word_count-pthr 4.0.0-lego+ #170\n  [93180.703114] RIP: 0033:[\n0000000000427377\n]  [\n0000000000427377\n] 0x427377\n  [93180.784234] RSP: 002b:00007fffdfff6d28  EFLAGS: 00010297\n  [93180.847674] RAX: 0000000000000000 RBX: 000000000073c4c0 RCX: 000000000000000d\n  [93180.932953] RDX: 000000000000ffff RSI: 00007ffff4999070 RDI: 0000000000000000\n  [93181.018233] RBP: 00007ffff499907d R08: 000000000000ffff R09: 0000000000000000\n  [93181.103513] R10: 0000000000427760 R11: 00007ffff49982c0 R12: 0000000000000118\n  [93181.188791] R13: 00000000006e4aac R14: 0000000000000116 R15: 0000000000000117\n  [93181.274072] FS:  00007fffdfff7700(0000) GS:ffff88107fc80000(0000) knlGS:0000000000000000\n  [93181.370790] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n  [93181.439430] CR2: 0000000000000000 CR3: 000000107e924000 CR4: 00000000000406a0\n\n\n\n\n\n\nTried several ways to ensure memory safety. It still failed even if I enabled all of them. So, I guess the memory safety is ensured? Still some other things?\n\n\n\n\nforce \nalloc_pages\n to use \n__GFP_ZERO\n\n\nmake \nkmalloc\n behave as \nkzalloc\n\n\nmake \nkfree\n empty\n\n\n\n\nI also suspect \nmunmap\n may free extra wrong pgtable entries. Although I\nve went through all the code and checked, but in addition to the above things, I\nm going to:\n\n\n\n\nmake munmap dummy (no p2m_munmap, return 0 directly)\n\n\n\n\nFailed.\n\n\nNext, I\nm going to:\n\n\n\n\nadd checksum for every page transferred across network.\n\n\nadd warning for unnormal cases\n\n\n\n\nBang! I found something while running P+M:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n[\n  \n115.727597\n]\n \nMemory\n-\ncomponent\n \nmanager\n \nis\n \nup\n \nand\n \nrunning\n.\n\n\n[\n  \n116.691723\n]\n \nhandle_p2m_fork\n()\n:\n \nnid\n:\n0\n,\npid\n:\n22\n,\ntgid\n:\n22\n,\nparent_tgid\n:\n1\n\n\n[\n  \n116.697038\n]\n \nhandle_p2m_fork\n()\n:\n \nreply\n:\n \n0\n:\nOKAY\n\n\n[\n  \n116.791088\n]\n \nhandle_p2m_execve\n()\n:\n \npid\n:\n22\n,\nargc\n:\n2\n,\nenvc\n:\n2\n,\nfile\n:\n/\nroot\n/\nys\n/\nphoenix\n/\nphoenix\n-\n2.0\n/\ntests\n/\nword_count\n/\nword_count\n-\npthread\n\n\n[\n  \n116.792357\n]\n     \nargc\n[\n0\n]\n \n(\nlen\n:\n \n65\n)\n:\n  \n/\nroot\n/\nys\n/\nphoenix\n/\nphoenix\n-\n2.0\n/\ntests\n/\nword_count\n/\nword_count\n-\npthread\n\n\n[\n  \n116.793439\n]\n     \nargc\n[\n1\n]\n \n(\nlen\n:\n \n82\n)\n:\n  \n/\nroot\n/\nys\n/\nphoenix\n/\nphoenix\n-\n2.0\n/\ntests\n/\nword_count\n/\nword_count_datafiles\n/\nword_100MB\n.\ntxt\n\n\n[\n  \n116.794653\n]\n     \nenvc\n[\n0\n]\n \n(\nlen\n:\n  \n7\n)\n:\n  \nHOME\n=/\n\n\n[\n  \n116.795196\n]\n     \nenvc\n[\n1\n]\n \n(\nlen\n:\n \n11\n)\n:\n  \nTERM\n=\nlinux\n\n\n[\n  \n116.795772\n]\n \n__bprm_mm_init\n \nvma\n:\n \nffff88083effe6b8\n\n\n[\n  \n116.796209\n]\n \nfaultin_page\n \nvma\n:\n \nffff88083effe6b8\n\n\n[\n  \n116.796729\n]\n \nfaultin_page\n \nvma\n:\n \nffff88083effe6b8\n\n\n[\n  \n116.797150\n]\n \nhandle_pte_fault\n \nvma\n:\n \nffff88083effe6b8\n \nentry\n:\n \n0xffff88083e8c1067\n\n\n[\n  \n116.798044\n]\n \npte\n:\nffff88083e8c0ff0\n \npfn\n:\n0x8083e8c1\n \nflags\n:(\npresent\n|\nwritable\n|\nuser\n|\naccessed\n|\ndirty\n|\nsoftw4\n|\npkey0\n|\npkey1\n|\npkey2\n|\npkey3\n|\nnx\n|\n0x3ff800000000000\n)\n\n\n[\n  \n116.799462\n]\n \n------------\n[\n \ncut\n \nhere\n \n]\n------------\n\n\n[\n  \n116.800049\n]\n \nWARNING\n:\n \nCPU\n:\n \n4\n \nPID\n:\n \n15\n \nat\n \nmanagers\n/\nmemory\n/\nvm\n/\nfault\n.\nc\n:\n148\n \nhandle_lego_mm_fault\n+\n0x4d8\n/\n0x550\n\n\n[\n  \n116.801148\n]\n \nCPU\n:\n \n4\n \nPID\n:\n \n15\n \nComm\n:\n \nmc\n-\nmanager\n \n4.0.0\n-\nlego\n+\n \n#\n78\n\n\n[\n  \n116.801818\n]\n \nStack\n:\n\n\n[\n  \n116.802179\n]\n \nffff88083e893c50\n \nffffffff8100e827\n \n00007ff\nfffffef94\n \nffff88083effe6b8\n\n\n[\n  \n116.803283\n]\n \nffff88083e894008\n \nffff88083e8c1067\n \nffff88083e893c60\n \nffffffff8100e91f\n\n\n[\n  \n116.804387\n]\n \nffff88083e893cf0\n \nffffffff8102b008\n \n0000000000000031\n \nffff88083e893cf0\n\n\n[\n  \n116.805488\n]\n \n00000000000002\n96\n \n00003ff\nfffe00000\n \nffff800000000067\n \nffff88083e893d50\n\n\n[\n  \n116.806590\n]\n \nffff880000000001\n \nffffffff81066798\n \nffff88083effe6b8\n \nffff88083e893d50\n\n\n[\n  \n116.807691\n]\n \nCall\n \nTrace\n:\n\n\n[\n  \n116.808087\n]\n \nTSK\n\n\n[\n  \n116.808448\n]\n \n[\nffffffff8100e836\n]\n \n__warn\n.\nconstprop\n.0\n+\n0xa6\n/\n0x100\n\n\n[\n  \n116.809126\n]\n \n[\nffffffff8100e91f\n]\n \nwarn_slowpath_null\n+\n0xf\n/\n0x20\n\n\n[\n  \n116.809802\n]\n \n[\nffffffff8102b008\n]\n \nhandle_lego_mm_fault\n+\n0x4d8\n/\n0x550\n\n\n[\n  \n116.810505\n]\n \n[\nffffffff8102cfe3\n]\n \nfaultin_page\n+\n0x43\n/\n0xb0\n\n\n[\n  \n116.811131\n]\n \n[\nffffffff8102dab1\n]\n \ncopy_strings\n.\nisra\n.1\n+\n0xe1\n/\n0x130\n\n\n[\n  \n116.811819\n]\n \n[\nffffffff8102dd1e\n]\n \nexec_loader\n+\n0x21e\n/\n0x350\n\n\n[\n  \n116.812457\n]\n \n[\nffffffff8102680a\n]\n \nhandle_p2m_execve\n+\n0x1aa\n/\n0x290\n\n\n\n\n\n\nThis is a temporary stack vma that loader created for saving argv and envp. So, this vma was created here:\n\n\n1\n2\n3\n4\n5\n6\nstatic\n \nint\n \n__bprm_mm_init\n(\nstruct\n \nlego_binprm\n \n*\nbprm\n)\n\n\n{\n\n        \n...\n\n        \nbprm\n-\nvma\n \n=\n \nvma\n \n=\n \nkzalloc\n(\nsizeof\n(\n*\nvma\n),\n \nGFP_KERNEL\n);\n\n        \n...\n\n\n}\n\n\n\n\n\n\n\nAnd then \ncopy_strings\n will call \nfaultin_page\n to populate a page for a specific user virtual adddress:\n\n\n1\n2\n3\n4\n5\n6\n7\nint\n \nfaultin_page\n(\nstruct\n \nvm_area_struct\n \n*\nvma\n,\n \nunsigned\n \nlong\n \nstart\n,\n\n                 \nunsigned\n \nlong\n \nflags\n,\n \nunsigned\n \nlong\n \n*\nkvaddr\n)\n\n\n{\n\n        \n...\n\n        \nret\n \n=\n \nhandle_lego_mm_fault\n(\nvma\n,\n \nstart\n,\n \nflags\n,\n \nkvaddr\n);\n\n        \n...\n\n\n}\n\n\n\n\n\n\n\nEventually, the \nhandle_lego_mm_fault\n will call \nhandle_pte_fault\n:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\nstatic\n \nint\n \nhandle_pte_fault\n(\nstruct\n \nvm_area_struct\n \n*\nvma\n,\n \nunsigned\n \nlong\n \naddress\n,\n\n                            \nunsigned\n \nint\n \nflags\n,\n \npte_t\n \n*\npte\n,\n \npmd_t\n \n*\npmd\n,\n\n                            \nunsigned\n \nlong\n \n*\nmapping_flags\n)\n\n\n{\n\n        \n...\n\n        \nif\n \n(\n!\npte_present\n(\nentry\n))\n \n{\n\n                \n...\n\n        \n}\n\n\n        \npr_info\n(\n%s vma: %p entry: %#lx\n\\n\n,\n \nFUNC\n,\n \nvma\n,\n \nentry\n.\npte\n);\n\n        \ndump_pte\n(\npte\n,\n \nNULL\n);\n\n        \nWARN_ON_ONCE\n(\n1\n);\n\n        \n...\n\n\n}\n\n\n\n\n\n\n\nApparently, pte is wrong! But I don\nt have time today. Continue tomorrow.\nHmm forgot that we are saving kernel virtual addresses in the pte. Just take a quick look at the lego_pud_alloc things, seems will have some issues. I defenitly need to check all these stuff tomorrow. I\nve not touch this part for too long!\n\n\n\n\n02/13 Tue Sunny\n\n\nChecking our SLOB allocator today. So I found Yutong\ns code is using \nset_page_private\n when slob get a new page from buddy. This private field is only intended to be used by buddy to record the \norder\n. This mixed usage will confuse buddy and create bug.\n\n\nEven though I removed the \nset_page_private\n(\npage\n,\n \n0\n)\n after \nfree_page\n, word_count-pthread still fails. Damn.\n\n\n\n\n02/12 Mon Cloudy\n\n\nAdd this commit \n4cb3a8b6a943c90714fd9bb5e5465ee315f0aa30\n:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n    memory: Use kzalloc instead of kmalloc in __bprm_mm_init (loader)\n\n    This was an potentionl bug that was not triggered previously.\n    It is simply because kmalloc\ned vma contains some garbage area,\n    while later in the pgfault code, we use\n            if (vma-\nvm_ops \n vma-\nvm_ops-\nfault)\n                    ...\n    to check if it is an file-backed fault.\n\n    Fortunately the vma-\nvm_ops happens to have some leftover value.\n    So this bug was triggered.\n\n    This actually reminds me that this is a series of potential bugs!\n    Even though before I\nve added things like force GFP_ZERO in all\n    physical page allocation, I missed the kmalloc\ns case!\n\n\n\n\n\nThe story is:\n\n\nI patched the stop_machine code today, and tried to run code with P+M on VM, everything works fine. However, when I tried to run the new code with P+M+S on physical machine, M crashed at a very weird point:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n[ 7791.998168] handle_p2m_execve(): pid:81,argc:2,envc:2,file:/root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread\n[ 7792.129312] BUG: unable to handle kernel NULL pointer dereference at 0000000000000031\n[ 7792.222889] IP: [\nffffffff8102c180\n] handle_lego_mm_fault+0x160/0x4b0\n[ 7792.299842] PGD 0\n[ 7792.323760] Oops: 0000 [#1] PREEMPT SMP MEMORY\n[ 7792.376794] CPU: 4 PID: 79 Comm: mc-manager 4.0.0-lego+ #29\n\n[ 7792.443349] RIP: .. [\nffffffff8102c180\n] handle_lego_mm_fault+0x160/0x4b0\n\n......\n....\n[ 7793.750506] Call Trace:\n[ 7793.779623] \nTSK\n\n\n[ 7793.802501] [\nffffffff810053f4\n] ? apic_timer_interrupt+0x54/0x90\n\n[ 7793.875295] [\nffffffff8102e469\n] faultin_page+0x9/0x70\n\n[ 7793.936649] [\nffffffff8102ef01\n] copy_strings.isra.1+0xe1/0x130\n\n[ 7794.007362] [\nffffffff8102f11e\n] exec_loader+0x1ce/0x340\n\n[ 7794.070796] [\nffffffff81027def\n] handle_p2m_execve+0x12f/0x200\n\n[ 7794.140469] [\nffffffff810274fb\n] mc_manager+0x1ab/0x2b0\n[ 7794.202864] [\nffffffff81027350\n] ? bitmap_fill+0x33/0x33\n[ 7794.266298] [\nffffffff8101c6b7\n] kthread+0x107/0x130\n[ 7794.325572] [\nffffffff8101c5b0\n] ? __kthread_parkme+0x90/0x90\n[ 7794.394205] [\nffffffff8100b462\n] ret_from_fork+0x22/0x30\n\n\n\n\n\nSo faulting source code is:\n\n1\n2\n3\n4\n5\n6\n7\n8\nstatic\n \nint\n \nhandle_pte_fault\n(\nstruct\n \nvm_area_struct\n \n*\nvma\n,\n \nunsigned\n \nlong\n \naddress\n,\n\n                            \nunsigned\n \nint\n \nflags\n,\n \npte_t\n \n*\npte\n,\n \npmd_t\n \n*\npmd\n)\n\n\n{\n\n    \n....\n\n\n        \nif\n \n(\nvma\n-\nvm_ops\n \n \nvma\n-\nvm_ops\n-\nfault\n)\n\n\n                \nreturn\n \ndo_linear_fault\n(\nvma\n,\n \naddress\n,\n \nflags\n,\n\n\n                                       \npte\n,\n \npmd\n,\n \nentry\n)\n\n    \n....\n\n\n\n\n\n\nSomething wrong with \nvma\n? At this loader stage, this vma is a temporaty stack vma created for saving \nargv\n and \nenvp\n. So I look back into the code that created this vma:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\nmanagers\n/\nmemory\n/\nloader\n/\ncore\n.\nc\n:\n\n\nstatic\n \nint\n \n__bprm_mm_init\n(\nstruct\n \nlego_binprm\n \n*\nbprm\n)\n\n\n{\n\n        \nint\n \nerr\n;\n\n        \nstruct\n \nvm_area_struct\n \n*\nvma\n \n=\n \nNULL\n;\n\n        \nstruct\n \nlego_mm_struct\n \n*\nmm\n \n=\n \nbprm\n-\nmm\n;\n\n\n\n        \nbprm\n-\nvma\n \n=\n \nvma\n \n=\n \nkmalloc\n(\nsizeof\n(\n*\nvma\n),\n \nGFP_KERNEL\n);\n\n\n        \nif\n \n(\n!\nvma\n)\n\n                \nreturn\n \n-\nENOMEM\n;\n\n\n\n\n\n\nThe code after this does NOT do necessary cleanup. The \nvm_ops\n happens to have some garbage value from last user. So it is not 0, so the above \nvma-\nvm_ops\n is true, and it will try to read \nvma-\nvm_ops-\nfault\n. And that, my friend, is where garbage turns into crash.\n\n\nThis presents a series of potential bugs. Ugh, \nmemory safety\n!\n\n\n\n\n02/09 Fri Cloudy\n\n\nTried to modify Phoneix code: replace \nrealloc\n with \nmalloc+mempcy\n. Thus the \nmremap\n syscall is avoided, but it still has general protection fault. Same with yesterday, corrupted at \n__strcmp_sse42\n, with corrupted \nRSI\n or \nRDI\n. So I guess it is not about \nmremap\n itself at all. I will follow yesterday\ns checking list.\n\n\n\n\n02/08 Thur Cloudy\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n00000000004272d0 \n__strcmp_sse42\n:\n\n  4272d0:       89 f1                   mov    %esi,%ecx\n  4272d2:       89 f8                   mov    %edi,%eax\n  4272d4:       48 83 e1 3f             and    $0x3f,%rcx\n  4272d8:       48 83 e0 3f             and    $0x3f,%rax\n  4272dc:       83 f9 30                cmp    $0x30,%ecx\n  4272df:       77 3f                   ja     427320 \n__strcmp_sse42+0x50\n\n  4272e1:       83 f8 30                cmp    $0x30,%eax\n  4272e4:       77 3a                   ja     427320 \n__strcmp_sse42+0x50\n\n  4272e6:       f3 0f 6f 0f             movdqu (%rdi),%xmm1\n\n* 4272ea:       f3 0f 6f 16             movdqu (%rsi),%xmm2\n\n  4272ee:       66 0f ef c0             pxor   %xmm0,%xmm0\n  4272f2:       66 0f 74 c1             pcmpeqb %xmm1,%xmm0\n  4272f6:       66 0f 74 ca             pcmpeqb %xmm2,%xmm1\n  4272fa:       66 0f f8 c8             psubb  %xmm0,%xmm1\n  4272fe:       66 0f d7 d1             pmovmskb %xmm1,%edx\n  427302:       81 ea ff ff 00 00       sub    $0xffff,%edx\n  427308:       0f 85 42 0d 00 00       jne    428050 \n__strcmp_sse42+0xd80\n\n  42730e:       48 83 c6 10             add    $0x10,%rsi\n  427312:       48 83 c7 10             add    $0x10,%rdi\n  427316:       66 2e 0f 1f 84 00 00    nopw   %cs:0x0(%rax,%rax,1)\n  42731d:       00 00 00  \n  427320:       48 83 e6 f0             and    $0xfffffffffffffff0,%rsi\n  427324:       48 83 e7 f0             and    $0xfffffffffffffff0,%rdi\n  427328:       ba ff ff 00 00          mov    $0xffff,%edx\n  42732d:       45 31 c0                xor    %r8d,%r8d\n  427330:       83 e1 0f                and    $0xf,%ecx\n  427333:       83 e0 0f                and    $0xf,%eax\n  427336:       66 0f ef c0             pxor   %xmm0,%xmm0\n  42733a:       39 c1                   cmp    %eax,%ecx\n  42733c:       74 32                   je     427370 \n__strcmp_sse42+0xa0\n\n  42733e:       77 07                   ja     427347 \n__strcmp_sse42+0x77\n\n  427340:       41 89 d0                mov    %edx,%r8d\n  427343:       91                      xchg   %eax,%ecx\n  427344:       48 87 f7                xchg   %rsi,%rdi\n\n* 427347:       66 0f 6f 17             movdqa (%rdi),%xmm2\n\n  (RDI: 0000000000000000)\n\n\n\n\n\n\nFrustrating! What is wrong with multithread program? Because of broken FPU-switch code? of inappropriate TLB flush? of IB corrupts memory? of what? ugh?\n\n\nI\nm done with this random guess and frustrated general protection or segfault, I need to first make sure underlying kernel is 100%  percent correct, this is a checking list:\n\n\n\n\nfpu save/restore\n\n\nalways fail at some XMM instruction\n\n\nalways with corrupted RDI or RSI\n\n\n\n\n\n\nswitch_to_asm\n\n\n%gs and %fs\n\n\nswitch_mm (pgd)\n\n\nstack frame\n\n\n\n\n\n\nset_arch_tls (%fs)\n\n\nglibc\ns way of using per thread data\n\n\n\n\n\n\nsome cpu may miss tlb flush\n\n\nkernel entry/exit assembly\n\n\ncurrent_task macro\n\n\nstack_stratch\n\n\nper-cpu data in entry.S\n\n\n\n\n\n\nfutex\n\n\nclear_tid\n\n\nset_tid\n\n\nshared mm\n\n\nrobust list\n\n\n\n\n\n\ninterrupts\n\n\nvector array\n\n\nAPIC setup\n\n\nIO-APIC\n\n\ntimer interrupt\n\n\n\n\n\n\ncpu_init and Trampoline\n\n\nfaked kernel version\n\n\nP side pgfault handling code (SMP)\n\n\nand M side pgfault handling (SMP)\n\n\nmremap, munmap\n\n\ncheck pgtable boundary\n\n\n\n\n\n\nIn all, check SMP implications\n\n\n\n\nIs there any code, that is solely used to test if the underlying kernel has appropriate behaviors? Like glibc test code?\n\n\nHow to protect kernel virtual memory? Any existing solutions in Linux?\n\n\nWhat is the implication of multiple CPU entering kernel at the same time? How can it corrupt user pages? Maybe: kernel entry code, per-cpu data in entry code, fpu code, switch_to, scheduler.\n\n\nWhy it always fail at those FPU code i.e. the strcmp function? I failed to compile without those sse, any solution? How it hurt performance?\n\n\n\n\n02/07 Wed Cloudy\n\n\n20\n:\n07\n\nPushed a small patch on mremap issue. Hope it will work. mremap really makes the whole thing very interesting, will be a very good research finding on combing virtual cache and operating system. Need to go gym with a friend, will be back on debugging late tonight.\n\n\n9\n:\n30\n\nHave two meetings to do today, and an security class, won\nt have too much time coding during daytime.\n\n\n\n\n02/06 Tue Sunny\n\n\nWell. We\nve ruled out both \nsmp_call_function\n and \nworkqueue\n yesterday with Yiying\ns help. But the multi-thread word-count still fails \n:-(\n Single thread word-count just finished 4GB dataset (with 8GB pcache). So what could be still wrong with multithread one????\n\n\n\n\nchill\n\n\ncheck exit code\n\n\n(Checked)\n check pcache\ns usage of task_struct, should always use the group_leader\n\n\ncheck cpu boot code and check the switch code again\n\n\nI believe pinpoint the issue in multithread word-count can solve a lot issues, it must be some thread creation, removal, schedule things.\n\n\nHow about adding a lock for ibapi, make it sequential? Sweet, I tried, finally it is \na bug that we are able to debug\n.\n\n\n\n\n22\n:\n39\n\nDone for today. I\nm trying to patch \nmove_pte\n and \npcache_move_pte\n. Although in theory we defenitly need to patch it, I keep thinking the code before should not trigger any serious bus or memory corruption. Ugh. Maybe it is concurrent \nmremap\n that one of them remap from A to B, while another one remap from C to A. It is possible. But my dead brain can not think of this anymore. I\nm going to hit the gym and do some squats.\n\n\n17\n:\n01\n\nCriminal found: \nmremap()\n and \nvirtual cache\n did the crime. Interesting, I have not seen any research paper, tech-reports, writeup, code about this, not even the OVC paper, which, by the way, I think they must consider this case. Otherwise, a mremap will simply crash its virtual cache. Many thanks went to my smoke-and-think time.\n\n\n15\n:\n14\n\nSomething new came up! After adding a spinlock for ibapi, this showed up (I tried one more time after this, which does not show up). We are lucky to catch this. At least I know where to look at. Also, this is defenitly triggered by \nmremap\n. It is seems it is overlapped \nmremap()\n. One thing I did not know is which thread trigger this bug, the sweep thread? Cause mremap related pcache rmap functions do not use \nrmap_get_locked_pte\n.\n\n\n1\n2\n3\n4\n5\n6\n7\n[ 3826.048774] normal_p2s_open(): f_name: word_100MB.txt, mode: 04400, flags: 0\n[ 3827.891622] SYSC_mremap(cpu18): move: [0x7fffe5788000 - 0x7fffe5806000] -\n [0x7fffe531b000 - 0x7fffe5399000]\n[ 3828.178643] SYSC_mremap(cpu14): move: [0x7fffe5941000 - 0x7fffe5980000] -\n [0x7fffe57c7000 - 0x7fffe5806000]\n\n****    ERROR: mismatched PTE and rmap\n****    rmap-\nowner_process: word_count-pthr uva: 0x7fffe57c8000 ptep: ffff88107efe0e40, rmap-\npage_table: ffff88107efe0e40\n****    pcache_pfn: 0x1257c8, pte_pfn: 0x125942\n\n\n\n\n\n\n14\n:\n00\n \n\n\nword_count-pthread\n: 100MB dataset\n\npcache\n: 8GB, 8-way\n\nvictim\n: 8 entries\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n[ 1294.845313] STDOUT: ---[\nWordcount: Running...\n]---\n[ 1294.903661] STDOUT: ---[\n\no;\n]---\n[ 1294.946301] normal_p2s_open(): f_name: /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_100MB.txt, mode: 04400, flags: 0\n[ 1295.100517] SYSC_close(): [4] -\n [/sys/devices/system/cpu/online]\n[ 1295.594658] word_count-pthr[59] general protection ip:4272ea sp:7ffff1b8ed28 error:0\n[ 1295.685236] CPU: 10 PID: 59 Comm: word_count-pthr 4.0.0-lego+ #113\n[ 1295.759070] RIP: 0033:[\n00000000004272ea\n]  [\n00000000004272ea\n] 0x4272ea\n[ 1295.840184] RSP: 002b:00007ffff1b8ed28  EFLAGS: 00010283\n[ 1295.903621] RAX: 000000000000000f RBX: 00007fffe5a3d010 RCX: 0000000000000001\n[ 1295.988893] RDX: 0000000000000000 RSI: 4854005942004441 RDI: 00007ffff1c1e80f\n[ 1296.074166] RBP: 00007ffff1c1e80f R08: 0000000000000000 R09: 0000000000000010\n[ 1296.211435] R10: 0000000000427ce0 R11: 00007ffff1bbb3ba R12: 0000000000001de4\n[ 1296.296711] R13: 00000000006e4a80 R14: 0000000000001d9e R15: 0000000000001dc1\n[ 1296.433978] FS:  00007ffff1b8f700(0000) GS:ffff88107fca0000(0000) knlGS:0000000000000000\n[ 1296.582686] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[ 1296.963297] CR2: 00007ffff1c1e000 CR3: 000000207fd8a000 CR4: 00000000000406a0\n\n\n\n\nSo what is this \nip\n:\n4272\nea\n, let us objdump the binary:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n0000000000425e60 \nstrcmp\n:\n  425e60:       48 8d 05 69 14 00 00    lea    0x1469(%rip),%rax        # 4272d0 \n__strcmp_sse42\n\n  425e67:       f7 05 5f b8 2b 00 00    testl  $0x100000,0x2bb85f(%rip)        # 6e16d0 \n_dl_x86_cpu_features+0x10\n\n  425e6e:       00 10 00\n  425e71:       75 1a                   jne    425e8d \nstrcmp+0x2d\n\n  425e73:       48 8d 05 46 b0 00 00    lea    0xb046(%rip),%rax        # 430ec0 \n__strcmp_ssse3\n\n  425e7a:       f7 05 4c b8 2b 00 00    testl  $0x200,0x2bb84c(%rip)        # 6e16d0 \n_dl_x86_cpu_features+0x10\n\n  425e81:       02 00 00\n  425e84:       75 07                   jne    425e8d \nstrcmp+0x2d\n\n  425e86:       48 8d 05 03 00 00 00    lea    0x3(%rip),%rax        # 425e90 \n__GI_strcmp\n\n  425e8d:       c3                      retq\n  425e8e:       66 90                   xchg   %ax,%ax\n .. ..\n .. ..\n00000000004272d0 \n__strcmp_sse42\n:\n  4272d0:       89 f1                   mov    %esi,%ecx\n  4272d2:       89 f8                   mov    %edi,%eax\n  4272d4:       48 83 e1 3f             and    $0x3f,%rcx\n  4272d8:       48 83 e0 3f             and    $0x3f,%rax\n  4272dc:       83 f9 30                cmp    $0x30,%ecx\n  4272df:       77 3f                   ja     427320 \n__strcmp_sse42+0x50\n\n  4272e1:       83 f8 30                cmp    $0x30,%eax\n  4272e4:       77 3a                   ja     427320 \n__strcmp_sse42+0x50\n\n  4272e6:       f3 0f 6f 0f             movdqu (%rdi),%xmm1\n* 4272ea:       f3 0f 6f 16             movdqu (%rsi),%xmm2\n  4272ee:       66 0f ef c0             pxor   %xmm0,%xmm0\n\n\n\n\nYou can see \n%rsi\n has some garbage value \nRSI\n:\n \n4854005942004441\n. Something went wrong. Will it be our FPU? I\nm not quite sure. If FPU code has error, why single-thread one succeed? Why it only shows up at multithread ones?\n\n\n\n\n02/05 Mon Sunny\n\n\nFrom yesterday\ns testing of Phoenix, it looks like something is wrong in \nsmp_call_functions()\n. They are invoked through \ntlb flush\n, which was further invoked by \nmremap\n, or \nmunmap\n. The warning from smp is:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n[\n \n1260.586696\n]\n \nWARNING\n:\n \nCPU\n:\n \n0\n \nPID\n:\n \n73\n \nat\n \nkernel\n/\nsmp\n.\nc\n:\n129\n \ngeneric_smp_call_function_single_interrupt\n+\n0xb8\n/\n0x160\n\n\n[\n \n1260.705251\n]\n \nCPU\n:\n \n0\n \nPID\n:\n \n73\n \nComm\n:\n \nword_count\n-\npthr\n \n4.0.0\n-\nlego\n+\n \n#\n99\n\n\n[\n \n1260.777008\n]\n \nStack\n:\n\n\n[\n \n1260.800927\n]\n \nffff88207fdffef8\n \nffffffff8100ec67\n \nffff88107fc00000\n \nffff88107fc00000\n\n\n[\n \n1260.888283\n]\n \nffffffff8100d410\n \nffff88207fe23df0\n \nffff88207fdfff08\n \nffffffff8100ed5f\n\n\n[\n \n1260.975639\n]\n \nffff88207fdfff38\n \nffffffff8100fe68\n \n00007ff\nfe58c3010\n \n0000000000000f\n96\n\n\n[\n \n1261.062995\n]\n \n000000000000f\n960\n \n0000000000000f\n95\n \nffff88207fdfff48\n \nffffffff810020dd\n\n\n[\n \n1261.150351\n]\n \n00007ff\nff58869c1\n \nffffffff8100b2e9\n \n0000000000000f\n96\n \n0000000000000f\n95\n\n\n[\n \n1261.237707\n]\n \nCall\n \nTrace\n:\n\n\n[\n \n1261.266825\n]\n \nTSK\n\n\n[\n \n1261.289704\n]\n \n[\nffffffff8100ec76\n]\n \n__warn\n.\nconstprop\n.0\n+\n0xa6\n/\n0x100\n\n\n[\n \n1261.359381\n]\n \n[\nffffffff8100d410\n]\n \n?\n \npgd_free\n+\n0x90\n/\n0x90\n\n\n[\n \n1261.419699\n]\n \n[\nffffffff8100ed5f\n]\n \nwarn_slowpath_null\n+\n0xf\n/\n0x20\n\n\n[\n \n1261.487295\n]\n \n[\nffffffff8100fe68\n]\n \ngeneric_smp_call_function_single_interrupt\n+\n0xb8\n/\n0x160\n\n\n[\n \n1261.581931\n]\n \n[\nffffffff810020dd\n]\n \ncall_function_interrupt\n+\n0x1d\n/\n0x20\n\n\n[\n \n1261.655767\n]\n \n[\nffffffff8100b2e9\n]\n \nsmp__call_function_interrupt\n+\n0x69\n/\n0x70\n\n\n\n\n\n\n\nSo I decided to look into smp.c a little bit to find out if there is something wrong (I wrote it long time ago). The warning itself is true, it means some inconsistent behavior.. I saw \nalloc_percpu\n stuff during \ncall_function_init\n, hence probably I also need to check percpu code a little code cause I\nm not sure if I port all the functionalities.\n\n\nIn all, today\ns task, check \npercpu\n and \nsmp_call_function\n code. Esp, \npercpu\n code, they are crucial and very hard to relate real bugs to it.\n\n\nWell\n things changed. I found a more serious bug: something about \ncpuhotplug\n, even though lego is not using it. \ncpuhotplug\n is a set of implict callbacks to all different subsystems who want to do some initialization work on each \noffline-\nonline\n cpu.\n\n\nLet us dig into how secondary cpu boots:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\nTrampoline\n..\n \nsetup\n \n64\nbit\n \nmode\n\n\nstart_secondary\n()\n\n  \nsmp_callin\n()\n\n        \nnotify_cpu_starting\n()\n\n              \n...\n\n              \nwhile\n \n(\nst\n-\nstate\n \n \ntarget\n)\n \n{\n\n                      \nst\n-\nstate\n++\n;\n\n                      \ncpuhp_invoke_callback\n(\ncpu\n,\n \nst\n-\nstate\n,\n \ntrue\n,\n \nNULL\n);\n\n              \n}\n\n          \ncpuhp_invoke_callback\n()\n\n\n\n\n\n\nSee? There will be some callbacks! What are those callbacks exactly? Well, they are predefined at the \nkernel/cpu.c\n. To save the trouble of reading code, I just print what functions are executed, the log is:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n[    0.118235] cpuhp_invoke_callback(): 136  CPU:0  page_writeback_cpu_online+0x0/0x20\n\n[    0.368478] cpuhp_invoke_callback(): 136  CPU:1  smpboot_create_threads+0x0/0x90\n[    0.370196] cpuhp_invoke_callback(): 136  CPU:1  perf_event_init_cpu+0x0/0xa0\n[    0.370403] cpuhp_invoke_callback(): 136  CPU:1  workqueue_prepare_cpu+0x0/0x80\n[    0.371112] cpuhp_invoke_callback(): 136  CPU:1  hrtimers_prepare_cpu+0x0/0x60\n[    0.371339] cpuhp_invoke_callback(): 136  CPU:1  smpcfd_prepare_cpu+0x0/0x80\n[    0.371584] cpuhp_invoke_callback(): 136  CPU:1  relay_prepare_cpu+0x0/0xe0\n[    0.371794] cpuhp_invoke_callback(): 136  CPU:1  rcutree_prepare_cpu+0x0/0x170\n[    0.372333] cpuhp_invoke_callback(): 136  CPU:1  notify_prepare+0x0/0xa0\n[    0.372744] cpuhp_invoke_callback(): 136  CPU:1  bringup_cpu+0x0/0x100\n[    0.008000] cpuhp_invoke_callback(): 136  CPU:1  sched_cpu_starting+0x0/0x60\n[    0.926124] cpuhp_invoke_callback(): 136  CPU:1  smpboot_unpark_threads+0x0/0x90\n[    0.926124] cpuhp_invoke_callback(): 136  CPU:1  perf_event_init_cpu+0x0/0xa0\n[    0.927028] cpuhp_invoke_callback(): 136  CPU:1  workqueue_online_cpu+0x0/0x2a0\n[    0.927768] cpuhp_invoke_callback(): 136  CPU:1  rcutree_online_cpu+0x0/0x70\n[    0.928045] cpuhp_invoke_callback(): 136  CPU:1  notify_online+0x0/0x20\n[    0.928256] cpuhp_invoke_callback(): 136  CPU:1  page_writeback_cpu_online+0x0/0x20\n[    0.928527] cpuhp_invoke_callback(): 136  CPU:1  sched_cpu_activate+0x0/0x190\n\n[    0.929084] cpuhp_invoke_callback(): 136  CPU:2  smpboot_create_threads+0x0/0x90\n[    0.930240] cpuhp_invoke_callback(): 136  CPU:2  perf_event_init_cpu+0x0/0xa0\n[    0.930434] cpuhp_invoke_callback(): 136  CPU:2  workqueue_prepare_cpu+0x0/0x80\n[    0.931070] cpuhp_invoke_callback(): 136  CPU:2  hrtimers_prepare_cpu+0x0/0x60\n[    0.931264] cpuhp_invoke_callback(): 136  CPU:2  smpcfd_prepare_cpu+0x0/0x80\n[    0.931464] cpuhp_invoke_callback(): 136  CPU:2  relay_prepare_cpu+0x0/0xe0\n[    0.931649] cpuhp_invoke_callback(): 136  CPU:2  rcutree_prepare_cpu+0x0/0x170\n[    0.932245] cpuhp_invoke_callback(): 136  CPU:2  notify_prepare+0x0/0xa0\n[    0.932475] cpuhp_invoke_callback(): 136  CPU:2  bringup_cpu+0x0/0x100\n[    0.008000] cpuhp_invoke_callback(): 136  CPU:2  sched_cpu_starting+0x0/0x60\n[    1.005023] cpuhp_invoke_callback(): 136  CPU:2  smpboot_unpark_threads+0x0/0x90\n[    1.005065] cpuhp_invoke_callback(): 136  CPU:2  perf_event_init_cpu+0x0/0xa0\n[    1.005408] cpuhp_invoke_callback(): 136  CPU:2  workqueue_online_cpu+0x0/0x2a0\n[    1.005729] cpuhp_invoke_callback(): 136  CPU:2  rcutree_online_cpu+0x0/0x70\n[    1.006029] cpuhp_invoke_callback(): 136  CPU:2  notify_online+0x0/0x20\n[    1.006206] cpuhp_invoke_callback(): 136  CPU:2  page_writeback_cpu_online+0x0/0x20\n[    1.006549] cpuhp_invoke_callback(): 136  CPU:2  sched_cpu_activate+0x0/0x190\n\n\n\n\n\nInteresting! Currently, Lego need to add the \nsmpboot_create_threads()\n, \nworkqueue_prepare_cpu()\n, \nworkqueue_prepare_cpu()\n, \nbringup_cpu()\n, \nsmpboot_unpark_threads()\n, \nworkqueue_online_cpu()\n.\n\n\nThis hidden things is really hard to find and not easy to track during boot. Especially during boot, they should do something like \nfor_each_online_cpu\n and init one by one. But I guess, after adding support of cpu hotplug, code kind of merged. Some stuff will be executed whenever a cpu has been teardown or bought up. And bang, why not use the same set of hotplug during boot, right?\nWell.", 
            "title": "Feb 2018"
        }, 
        {
            "location": "/lego/log/log-02-2018/#feb-2018", 
            "text": "", 
            "title": "Feb 2018"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0219-mon-rainy", 
            "text": "It is another week. I can not deny I m a little tired about the bug. Tried so many possible solutions, but none of them work. Well, today I first need to test the vma changes (pgoff and anon_vma) thing. Especially the vma merge and split.  This morning I fixed a bug in kernel_init process: make kernel_init able to run all possible CPUs. Because the first user process is forked from kernel_init, it is quite important that it gets the right cpu affinity: 1\n2\n3\n4\n5\n6 static   int   kernel_init ( void   * unused )  { \n         ... \n         set_cpus_allowed_ptr ( current ,   cpu_possible_mask ); \n         ...  }    Well, interestingly, the unmodified word_count-pthread succeed with 50MB dataset  with or without any DEBUG option! Amazing! I need to find out why the cpus_allowed becomes 0 at the beginning of kernel_init. Because  init_task  actually has: 1\n2      . cpus_allowed     =   CPU_MASK_ALL , \n     . nr_cpus_allowed =   NR_CPUS ,    Things to do next:   check why the cpus_allowed changed  check why word_count-pthread open  /dev/../cpu  so many times. Anything wrong with our  copy_files , or open, close?  here is an idea, to verify if FPU code is correct, run some scientific benchmarks.   Okay, findings:   cpus_allowd is fine, it is reset inside  sched_init() , when it tries make the  init_task  as the  idle  thread. Thus it is reasonable to set cpus_allowed again at  kernel_init  thread.", 
            "title": "02/19 Mon Rainy"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0218-sun-sunny", 
            "text": "It is a nice day. Yesterday I ve changed one line of code in mmap code path: change anonymous vma s pgoff from some value to 0. The result is I got several succeed work-count-pthread(bind to one core) testing. However, it still fail with unmodified word-count-pthread.  It brings me to inspect pgoff manipulation code and all mmap.c code. We ported everything from linux without almost zero modification. That means we ported all those useless  anon_vma  and pgoff code, which is used a lot by vma_merge, vma_split code. The thing is: our memory manager, our vma code do not need such  anon_vma  structure, and do not maintain pgoff. Thus, I m a little bit worried linux code may doing some crazy behind our back: mess vma and pages, then pcache miss gets some wrong pages  Well. Lego does not use  anon_vma , and pgoff should only be used by file-backed vma. So, I decided to remove  anon_vma  from our code, and make sure pgoff is used properly. Of course, the goal is to make vma_merge, split,\ncopy, do the things we intended.  Lesson learned.", 
            "title": "02/18 Sun Sunny"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0217-sat-snowy", 
            "text": "Fixed the bss bug. It comes from loader. We did not implement the  lego_clear_user  function, so some part of bss is non-zero.  Bad news is word_count-pthread still fail at same fpu instruction. Have to look into memory code more.  This is actually a fun debugging story. We should always add TODO or XXX or some warnings to unfinished code, no matter what. Lesson learned.", 
            "title": "02/17 Sat Snowy"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0216-fri-cloudy", 
            "text": "Yilun found a major loader bug yesterday: the  .bss  section variables are not 0, in the  iozone  benchmark. I did not encounter this issue before with simple test program. This is pretty serious.", 
            "title": "02/16 Fri Cloudy"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0215-thur-rainy", 
            "text": "Today is Chinese New Year.  Line 7 and 8 show the uva belong to the same page. Need to revisit  get_arg_pages  etc functions.  1\n2\n3\n4\n5\n6\n7\n8 [  108.393991] handle_p2m_execve(): pid:22,argc:2,envc:2,file:/root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread\n[  108.395255]     argc[0] (len: 65):  /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread\n[  108.396329]     argc[1] (len: 82):  /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_100MB.txt\n[  108.397530]     envc[0] (len:  7):  HOME=/\n[  108.398069]     envc[1] (len: 11):  TERM=linux\n[  108.398640] __bprm_mm_init vma: ffff88083effe6b8 [  108.399226] faultin_page vma: ffff88083effe6b8 uva: 0x7fffffffefed [  108.399949] faultin_page vma: ffff88083effe6b8 uva: 0x7fffffffef94   Well, this is 100% fine. I wrote this loader code long time ago and need some time to pickup. So, after I read the loader code, especially the  copy_strings  function, I found this is okay. Because copy_strings will be invoked three times, so the  faultin_page  basically will be invoked at least three times. That is why it went to that pte fault handling code.  Although actually I think  copy_strings  should  not  use  faultin_page , instead, it should use  get_user_pages , which will walk through the pgtable first, then went to  handle_lego_mm_fault .", 
            "title": "02/15 Thur Rainy"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0214-wed-rainy", 
            "text": "Hmm, tried to make kmalloc behave as kzalloc, and bind all threads to one core, still gave the same old bug:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14   42731a:       f3 0f 6f 16             movdqu (%rsi),%xmm2 \n  [93182.657376] word_count-pthr[85] general protection ip:42731a sp:7fffe3ffed28 error:0\n  [93182.747959] CPU: 8 PID: 85 Comm: word_count-pthr 4.0.0-lego+ #170\n  [93182.820758] RIP: 0033:[ 000000000042731a ]  [ 000000000042731a ] 0x42731a\n  [93182.901878] RSP: 002b:00007fffe3ffed28  EFLAGS: 00010283\n  [93182.965317] RAX: 000000000000001f RBX: 00007ffff001b010 RCX: 0000000000000005\n  [93183.050596] RDX: 0000000000000000 RSI: 5345485355420045 RDI: 00007ffff294791f\n  [93183.135876] RBP: 00007ffff294791f R08: 000000000000ffff R09: 0000000000000008\n  [93183.221156] R10: fffffffffffff048 R11: 00000000004acfc0 R12: 0000000000001cde\n  [93183.306435] R13: 00000000006e4a8c R14: 0000000000001cd7 R15: 0000000000001cda\n  [93183.391716] FS:  00007fffe3fff700(0000) GS:ffff88107fc80000(0000) knlGS:0000000000000000\n  [93183.488434] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n  [93183.557075] CR2: 00007ffff27a4000 CR3: 000000107e924000 CR4: 00000000000406a0    1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14   427377:       66 0f 6f 17             movdqa (%rdi),%xmm2 \n  [93180.527248] word_count-pthr[93]: segfault at 0x0 ip 0000000000427377 sp 00007fffdfff6d28 error 4\n  [93180.630314] CPU: 8 PID: 93 Comm: word_count-pthr 4.0.0-lego+ #170\n  [93180.703114] RIP: 0033:[ 0000000000427377 ]  [ 0000000000427377 ] 0x427377\n  [93180.784234] RSP: 002b:00007fffdfff6d28  EFLAGS: 00010297\n  [93180.847674] RAX: 0000000000000000 RBX: 000000000073c4c0 RCX: 000000000000000d\n  [93180.932953] RDX: 000000000000ffff RSI: 00007ffff4999070 RDI: 0000000000000000\n  [93181.018233] RBP: 00007ffff499907d R08: 000000000000ffff R09: 0000000000000000\n  [93181.103513] R10: 0000000000427760 R11: 00007ffff49982c0 R12: 0000000000000118\n  [93181.188791] R13: 00000000006e4aac R14: 0000000000000116 R15: 0000000000000117\n  [93181.274072] FS:  00007fffdfff7700(0000) GS:ffff88107fc80000(0000) knlGS:0000000000000000\n  [93181.370790] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n  [93181.439430] CR2: 0000000000000000 CR3: 000000107e924000 CR4: 00000000000406a0   Tried several ways to ensure memory safety. It still failed even if I enabled all of them. So, I guess the memory safety is ensured? Still some other things?   force  alloc_pages  to use  __GFP_ZERO  make  kmalloc  behave as  kzalloc  make  kfree  empty   I also suspect  munmap  may free extra wrong pgtable entries. Although I ve went through all the code and checked, but in addition to the above things, I m going to:   make munmap dummy (no p2m_munmap, return 0 directly)   Failed.  Next, I m going to:   add checksum for every page transferred across network.  add warning for unnormal cases   Bang! I found something while running P+M:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31 [    115.727597 ]   Memory - component   manager   is   up   and   running .  [    116.691723 ]   handle_p2m_fork () :   nid : 0 , pid : 22 , tgid : 22 , parent_tgid : 1  [    116.697038 ]   handle_p2m_fork () :   reply :   0 : OKAY  [    116.791088 ]   handle_p2m_execve () :   pid : 22 , argc : 2 , envc : 2 , file : / root / ys / phoenix / phoenix - 2.0 / tests / word_count / word_count - pthread  [    116.792357 ]       argc [ 0 ]   ( len :   65 ) :    / root / ys / phoenix / phoenix - 2.0 / tests / word_count / word_count - pthread  [    116.793439 ]       argc [ 1 ]   ( len :   82 ) :    / root / ys / phoenix / phoenix - 2.0 / tests / word_count / word_count_datafiles / word_100MB . txt  [    116.794653 ]       envc [ 0 ]   ( len :    7 ) :    HOME =/  [    116.795196 ]       envc [ 1 ]   ( len :   11 ) :    TERM = linux  [    116.795772 ]   __bprm_mm_init   vma :   ffff88083effe6b8  [    116.796209 ]   faultin_page   vma :   ffff88083effe6b8  [    116.796729 ]   faultin_page   vma :   ffff88083effe6b8  [    116.797150 ]   handle_pte_fault   vma :   ffff88083effe6b8   entry :   0xffff88083e8c1067  [    116.798044 ]   pte : ffff88083e8c0ff0   pfn : 0x8083e8c1   flags :( present | writable | user | accessed | dirty | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 )  [    116.799462 ]   ------------ [   cut   here   ] ------------  [    116.800049 ]   WARNING :   CPU :   4   PID :   15   at   managers / memory / vm / fault . c : 148   handle_lego_mm_fault + 0x4d8 / 0x550  [    116.801148 ]   CPU :   4   PID :   15   Comm :   mc - manager   4.0.0 - lego +   # 78  [    116.801818 ]   Stack :  [    116.802179 ]   ffff88083e893c50   ffffffff8100e827   00007ff fffffef94   ffff88083effe6b8  [    116.803283 ]   ffff88083e894008   ffff88083e8c1067   ffff88083e893c60   ffffffff8100e91f  [    116.804387 ]   ffff88083e893cf0   ffffffff8102b008   0000000000000031   ffff88083e893cf0  [    116.805488 ]   00000000000002 96   00003ff fffe00000   ffff800000000067   ffff88083e893d50  [    116.806590 ]   ffff880000000001   ffffffff81066798   ffff88083effe6b8   ffff88083e893d50  [    116.807691 ]   Call   Trace :  [    116.808087 ]   TSK  [    116.808448 ]   [ ffffffff8100e836 ]   __warn . constprop .0 + 0xa6 / 0x100  [    116.809126 ]   [ ffffffff8100e91f ]   warn_slowpath_null + 0xf / 0x20  [    116.809802 ]   [ ffffffff8102b008 ]   handle_lego_mm_fault + 0x4d8 / 0x550  [    116.810505 ]   [ ffffffff8102cfe3 ]   faultin_page + 0x43 / 0xb0  [    116.811131 ]   [ ffffffff8102dab1 ]   copy_strings . isra .1 + 0xe1 / 0x130  [    116.811819 ]   [ ffffffff8102dd1e ]   exec_loader + 0x21e / 0x350  [    116.812457 ]   [ ffffffff8102680a ]   handle_p2m_execve + 0x1aa / 0x290    This is a temporary stack vma that loader created for saving argv and envp. So, this vma was created here:  1\n2\n3\n4\n5\n6 static   int   __bprm_mm_init ( struct   lego_binprm   * bprm )  { \n         ... \n         bprm - vma   =   vma   =   kzalloc ( sizeof ( * vma ),   GFP_KERNEL ); \n         ...  }    And then  copy_strings  will call  faultin_page  to populate a page for a specific user virtual adddress:  1\n2\n3\n4\n5\n6\n7 int   faultin_page ( struct   vm_area_struct   * vma ,   unsigned   long   start , \n                  unsigned   long   flags ,   unsigned   long   * kvaddr )  { \n         ... \n         ret   =   handle_lego_mm_fault ( vma ,   start ,   flags ,   kvaddr ); \n         ...  }    Eventually, the  handle_lego_mm_fault  will call  handle_pte_fault :   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14 static   int   handle_pte_fault ( struct   vm_area_struct   * vma ,   unsigned   long   address , \n                             unsigned   int   flags ,   pte_t   * pte ,   pmd_t   * pmd , \n                             unsigned   long   * mapping_flags )  { \n         ... \n         if   ( ! pte_present ( entry ))   { \n                 ... \n         } \n\n         pr_info ( %s vma: %p entry: %#lx \\n ,   FUNC ,   vma ,   entry . pte ); \n         dump_pte ( pte ,   NULL ); \n         WARN_ON_ONCE ( 1 ); \n         ...  }    Apparently, pte is wrong! But I don t have time today. Continue tomorrow.\nHmm forgot that we are saving kernel virtual addresses in the pte. Just take a quick look at the lego_pud_alloc things, seems will have some issues. I defenitly need to check all these stuff tomorrow. I ve not touch this part for too long!", 
            "title": "02/14 Wed Rainy"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0213-tue-sunny", 
            "text": "Checking our SLOB allocator today. So I found Yutong s code is using  set_page_private  when slob get a new page from buddy. This private field is only intended to be used by buddy to record the  order . This mixed usage will confuse buddy and create bug.  Even though I removed the  set_page_private ( page ,   0 )  after  free_page , word_count-pthread still fails. Damn.", 
            "title": "02/13 Tue Sunny"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0212-mon-cloudy", 
            "text": "Add this commit  4cb3a8b6a943c90714fd9bb5e5465ee315f0aa30 :  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15     memory: Use kzalloc instead of kmalloc in __bprm_mm_init (loader)\n\n    This was an potentionl bug that was not triggered previously.\n    It is simply because kmalloc ed vma contains some garbage area,\n    while later in the pgfault code, we use\n            if (vma- vm_ops   vma- vm_ops- fault)\n                    ...\n    to check if it is an file-backed fault.\n\n    Fortunately the vma- vm_ops happens to have some leftover value.\n    So this bug was triggered.\n\n    This actually reminds me that this is a series of potential bugs!\n    Even though before I ve added things like force GFP_ZERO in all\n    physical page allocation, I missed the kmalloc s case!   The story is:  I patched the stop_machine code today, and tried to run code with P+M on VM, everything works fine. However, when I tried to run the new code with P+M+S on physical machine, M crashed at a very weird point:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21 [ 7791.998168] handle_p2m_execve(): pid:81,argc:2,envc:2,file:/root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread\n[ 7792.129312] BUG: unable to handle kernel NULL pointer dereference at 0000000000000031\n[ 7792.222889] IP: [ ffffffff8102c180 ] handle_lego_mm_fault+0x160/0x4b0\n[ 7792.299842] PGD 0\n[ 7792.323760] Oops: 0000 [#1] PREEMPT SMP MEMORY\n[ 7792.376794] CPU: 4 PID: 79 Comm: mc-manager 4.0.0-lego+ #29 [ 7792.443349] RIP: .. [ ffffffff8102c180 ] handle_lego_mm_fault+0x160/0x4b0 ......\n....\n[ 7793.750506] Call Trace:\n[ 7793.779623]  TSK  [ 7793.802501] [ ffffffff810053f4 ] ? apic_timer_interrupt+0x54/0x90 [ 7793.875295] [ ffffffff8102e469 ] faultin_page+0x9/0x70 [ 7793.936649] [ ffffffff8102ef01 ] copy_strings.isra.1+0xe1/0x130 [ 7794.007362] [ ffffffff8102f11e ] exec_loader+0x1ce/0x340 [ 7794.070796] [ ffffffff81027def ] handle_p2m_execve+0x12f/0x200 [ 7794.140469] [ ffffffff810274fb ] mc_manager+0x1ab/0x2b0\n[ 7794.202864] [ ffffffff81027350 ] ? bitmap_fill+0x33/0x33\n[ 7794.266298] [ ffffffff8101c6b7 ] kthread+0x107/0x130\n[ 7794.325572] [ ffffffff8101c5b0 ] ? __kthread_parkme+0x90/0x90\n[ 7794.394205] [ ffffffff8100b462 ] ret_from_fork+0x22/0x30   So faulting source code is: 1\n2\n3\n4\n5\n6\n7\n8 static   int   handle_pte_fault ( struct   vm_area_struct   * vma ,   unsigned   long   address , \n                             unsigned   int   flags ,   pte_t   * pte ,   pmd_t   * pmd )  { \n     ....           if   ( vma - vm_ops     vma - vm_ops - fault )                   return   do_linear_fault ( vma ,   address ,   flags ,                                          pte ,   pmd ,   entry ) \n     ....    Something wrong with  vma ? At this loader stage, this vma is a temporaty stack vma created for saving  argv  and  envp . So I look back into the code that created this vma:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 managers / memory / loader / core . c :  static   int   __bprm_mm_init ( struct   lego_binprm   * bprm )  { \n         int   err ; \n         struct   vm_area_struct   * vma   =   NULL ; \n         struct   lego_mm_struct   * mm   =   bprm - mm ;           bprm - vma   =   vma   =   kmalloc ( sizeof ( * vma ),   GFP_KERNEL );           if   ( ! vma ) \n                 return   - ENOMEM ;    The code after this does NOT do necessary cleanup. The  vm_ops  happens to have some garbage value from last user. So it is not 0, so the above  vma- vm_ops  is true, and it will try to read  vma- vm_ops- fault . And that, my friend, is where garbage turns into crash.  This presents a series of potential bugs. Ugh,  memory safety !", 
            "title": "02/12 Mon Cloudy"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0209-fri-cloudy", 
            "text": "Tried to modify Phoneix code: replace  realloc  with  malloc+mempcy . Thus the  mremap  syscall is avoided, but it still has general protection fault. Same with yesterday, corrupted at  __strcmp_sse42 , with corrupted  RSI  or  RDI . So I guess it is not about  mremap  itself at all. I will follow yesterday s checking list.", 
            "title": "02/09 Fri Cloudy"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0208-thur-cloudy", 
            "text": "1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38 00000000004272d0  __strcmp_sse42 :\n\n  4272d0:       89 f1                   mov    %esi,%ecx\n  4272d2:       89 f8                   mov    %edi,%eax\n  4272d4:       48 83 e1 3f             and    $0x3f,%rcx\n  4272d8:       48 83 e0 3f             and    $0x3f,%rax\n  4272dc:       83 f9 30                cmp    $0x30,%ecx\n  4272df:       77 3f                   ja     427320  __strcmp_sse42+0x50 \n  4272e1:       83 f8 30                cmp    $0x30,%eax\n  4272e4:       77 3a                   ja     427320  __strcmp_sse42+0x50 \n  4272e6:       f3 0f 6f 0f             movdqu (%rdi),%xmm1 * 4272ea:       f3 0f 6f 16             movdqu (%rsi),%xmm2   4272ee:       66 0f ef c0             pxor   %xmm0,%xmm0\n  4272f2:       66 0f 74 c1             pcmpeqb %xmm1,%xmm0\n  4272f6:       66 0f 74 ca             pcmpeqb %xmm2,%xmm1\n  4272fa:       66 0f f8 c8             psubb  %xmm0,%xmm1\n  4272fe:       66 0f d7 d1             pmovmskb %xmm1,%edx\n  427302:       81 ea ff ff 00 00       sub    $0xffff,%edx\n  427308:       0f 85 42 0d 00 00       jne    428050  __strcmp_sse42+0xd80 \n  42730e:       48 83 c6 10             add    $0x10,%rsi\n  427312:       48 83 c7 10             add    $0x10,%rdi\n  427316:       66 2e 0f 1f 84 00 00    nopw   %cs:0x0(%rax,%rax,1)\n  42731d:       00 00 00  \n  427320:       48 83 e6 f0             and    $0xfffffffffffffff0,%rsi\n  427324:       48 83 e7 f0             and    $0xfffffffffffffff0,%rdi\n  427328:       ba ff ff 00 00          mov    $0xffff,%edx\n  42732d:       45 31 c0                xor    %r8d,%r8d\n  427330:       83 e1 0f                and    $0xf,%ecx\n  427333:       83 e0 0f                and    $0xf,%eax\n  427336:       66 0f ef c0             pxor   %xmm0,%xmm0\n  42733a:       39 c1                   cmp    %eax,%ecx\n  42733c:       74 32                   je     427370  __strcmp_sse42+0xa0 \n  42733e:       77 07                   ja     427347  __strcmp_sse42+0x77 \n  427340:       41 89 d0                mov    %edx,%r8d\n  427343:       91                      xchg   %eax,%ecx\n  427344:       48 87 f7                xchg   %rsi,%rdi * 427347:       66 0f 6f 17             movdqa (%rdi),%xmm2   (RDI: 0000000000000000)   Frustrating! What is wrong with multithread program? Because of broken FPU-switch code? of inappropriate TLB flush? of IB corrupts memory? of what? ugh?  I m done with this random guess and frustrated general protection or segfault, I need to first make sure underlying kernel is 100%  percent correct, this is a checking list:   fpu save/restore  always fail at some XMM instruction  always with corrupted RDI or RSI    switch_to_asm  %gs and %fs  switch_mm (pgd)  stack frame    set_arch_tls (%fs)  glibc s way of using per thread data    some cpu may miss tlb flush  kernel entry/exit assembly  current_task macro  stack_stratch  per-cpu data in entry.S    futex  clear_tid  set_tid  shared mm  robust list    interrupts  vector array  APIC setup  IO-APIC  timer interrupt    cpu_init and Trampoline  faked kernel version  P side pgfault handling code (SMP)  and M side pgfault handling (SMP)  mremap, munmap  check pgtable boundary    In all, check SMP implications   Is there any code, that is solely used to test if the underlying kernel has appropriate behaviors? Like glibc test code?  How to protect kernel virtual memory? Any existing solutions in Linux?  What is the implication of multiple CPU entering kernel at the same time? How can it corrupt user pages? Maybe: kernel entry code, per-cpu data in entry code, fpu code, switch_to, scheduler.  Why it always fail at those FPU code i.e. the strcmp function? I failed to compile without those sse, any solution? How it hurt performance?", 
            "title": "02/08 Thur Cloudy"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0207-wed-cloudy", 
            "text": "20 : 07 \nPushed a small patch on mremap issue. Hope it will work. mremap really makes the whole thing very interesting, will be a very good research finding on combing virtual cache and operating system. Need to go gym with a friend, will be back on debugging late tonight.  9 : 30 \nHave two meetings to do today, and an security class, won t have too much time coding during daytime.", 
            "title": "02/07 Wed Cloudy"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0206-tue-sunny", 
            "text": "Well. We ve ruled out both  smp_call_function  and  workqueue  yesterday with Yiying s help. But the multi-thread word-count still fails  :-(  Single thread word-count just finished 4GB dataset (with 8GB pcache). So what could be still wrong with multithread one????   chill  check exit code  (Checked)  check pcache s usage of task_struct, should always use the group_leader  check cpu boot code and check the switch code again  I believe pinpoint the issue in multithread word-count can solve a lot issues, it must be some thread creation, removal, schedule things.  How about adding a lock for ibapi, make it sequential? Sweet, I tried, finally it is  a bug that we are able to debug .   22 : 39 \nDone for today. I m trying to patch  move_pte  and  pcache_move_pte . Although in theory we defenitly need to patch it, I keep thinking the code before should not trigger any serious bus or memory corruption. Ugh. Maybe it is concurrent  mremap  that one of them remap from A to B, while another one remap from C to A. It is possible. But my dead brain can not think of this anymore. I m going to hit the gym and do some squats.  17 : 01 \nCriminal found:  mremap()  and  virtual cache  did the crime. Interesting, I have not seen any research paper, tech-reports, writeup, code about this, not even the OVC paper, which, by the way, I think they must consider this case. Otherwise, a mremap will simply crash its virtual cache. Many thanks went to my smoke-and-think time.  15 : 14 \nSomething new came up! After adding a spinlock for ibapi, this showed up (I tried one more time after this, which does not show up). We are lucky to catch this. At least I know where to look at. Also, this is defenitly triggered by  mremap . It is seems it is overlapped  mremap() . One thing I did not know is which thread trigger this bug, the sweep thread? Cause mremap related pcache rmap functions do not use  rmap_get_locked_pte .  1\n2\n3\n4\n5\n6\n7 [ 3826.048774] normal_p2s_open(): f_name: word_100MB.txt, mode: 04400, flags: 0\n[ 3827.891622] SYSC_mremap(cpu18): move: [0x7fffe5788000 - 0x7fffe5806000] -  [0x7fffe531b000 - 0x7fffe5399000]\n[ 3828.178643] SYSC_mremap(cpu14): move: [0x7fffe5941000 - 0x7fffe5980000] -  [0x7fffe57c7000 - 0x7fffe5806000]\n\n****    ERROR: mismatched PTE and rmap\n****    rmap- owner_process: word_count-pthr uva: 0x7fffe57c8000 ptep: ffff88107efe0e40, rmap- page_table: ffff88107efe0e40\n****    pcache_pfn: 0x1257c8, pte_pfn: 0x125942   14 : 00    word_count-pthread : 100MB dataset pcache : 8GB, 8-way victim : 8 entries  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21 [ 1294.845313] STDOUT: ---[\nWordcount: Running...\n]---\n[ 1294.903661] STDOUT: ---[\n\no;\n]---\n[ 1294.946301] normal_p2s_open(): f_name: /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_100MB.txt, mode: 04400, flags: 0\n[ 1295.100517] SYSC_close(): [4] -  [/sys/devices/system/cpu/online]\n[ 1295.594658] word_count-pthr[59] general protection ip:4272ea sp:7ffff1b8ed28 error:0\n[ 1295.685236] CPU: 10 PID: 59 Comm: word_count-pthr 4.0.0-lego+ #113\n[ 1295.759070] RIP: 0033:[ 00000000004272ea ]  [ 00000000004272ea ] 0x4272ea\n[ 1295.840184] RSP: 002b:00007ffff1b8ed28  EFLAGS: 00010283\n[ 1295.903621] RAX: 000000000000000f RBX: 00007fffe5a3d010 RCX: 0000000000000001\n[ 1295.988893] RDX: 0000000000000000 RSI: 4854005942004441 RDI: 00007ffff1c1e80f\n[ 1296.074166] RBP: 00007ffff1c1e80f R08: 0000000000000000 R09: 0000000000000010\n[ 1296.211435] R10: 0000000000427ce0 R11: 00007ffff1bbb3ba R12: 0000000000001de4\n[ 1296.296711] R13: 00000000006e4a80 R14: 0000000000001d9e R15: 0000000000001dc1\n[ 1296.433978] FS:  00007ffff1b8f700(0000) GS:ffff88107fca0000(0000) knlGS:0000000000000000\n[ 1296.582686] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[ 1296.963297] CR2: 00007ffff1c1e000 CR3: 000000207fd8a000 CR4: 00000000000406a0  \nSo what is this  ip : 4272 ea , let us objdump the binary:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26 0000000000425e60  strcmp :\n  425e60:       48 8d 05 69 14 00 00    lea    0x1469(%rip),%rax        # 4272d0  __strcmp_sse42 \n  425e67:       f7 05 5f b8 2b 00 00    testl  $0x100000,0x2bb85f(%rip)        # 6e16d0  _dl_x86_cpu_features+0x10 \n  425e6e:       00 10 00\n  425e71:       75 1a                   jne    425e8d  strcmp+0x2d \n  425e73:       48 8d 05 46 b0 00 00    lea    0xb046(%rip),%rax        # 430ec0  __strcmp_ssse3 \n  425e7a:       f7 05 4c b8 2b 00 00    testl  $0x200,0x2bb84c(%rip)        # 6e16d0  _dl_x86_cpu_features+0x10 \n  425e81:       02 00 00\n  425e84:       75 07                   jne    425e8d  strcmp+0x2d \n  425e86:       48 8d 05 03 00 00 00    lea    0x3(%rip),%rax        # 425e90  __GI_strcmp \n  425e8d:       c3                      retq\n  425e8e:       66 90                   xchg   %ax,%ax\n .. ..\n .. ..\n00000000004272d0  __strcmp_sse42 :\n  4272d0:       89 f1                   mov    %esi,%ecx\n  4272d2:       89 f8                   mov    %edi,%eax\n  4272d4:       48 83 e1 3f             and    $0x3f,%rcx\n  4272d8:       48 83 e0 3f             and    $0x3f,%rax\n  4272dc:       83 f9 30                cmp    $0x30,%ecx\n  4272df:       77 3f                   ja     427320  __strcmp_sse42+0x50 \n  4272e1:       83 f8 30                cmp    $0x30,%eax\n  4272e4:       77 3a                   ja     427320  __strcmp_sse42+0x50 \n  4272e6:       f3 0f 6f 0f             movdqu (%rdi),%xmm1\n* 4272ea:       f3 0f 6f 16             movdqu (%rsi),%xmm2\n  4272ee:       66 0f ef c0             pxor   %xmm0,%xmm0  \nYou can see  %rsi  has some garbage value  RSI :   4854005942004441 . Something went wrong. Will it be our FPU? I m not quite sure. If FPU code has error, why single-thread one succeed? Why it only shows up at multithread ones?", 
            "title": "02/06 Tue Sunny"
        }, 
        {
            "location": "/lego/log/log-02-2018/#0205-mon-sunny", 
            "text": "From yesterday s testing of Phoenix, it looks like something is wrong in  smp_call_functions() . They are invoked through  tlb flush , which was further invoked by  mremap , or  munmap . The warning from smp is:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16 [   1260.586696 ]   WARNING :   CPU :   0   PID :   73   at   kernel / smp . c : 129   generic_smp_call_function_single_interrupt + 0xb8 / 0x160  [   1260.705251 ]   CPU :   0   PID :   73   Comm :   word_count - pthr   4.0.0 - lego +   # 99  [   1260.777008 ]   Stack :  [   1260.800927 ]   ffff88207fdffef8   ffffffff8100ec67   ffff88107fc00000   ffff88107fc00000  [   1260.888283 ]   ffffffff8100d410   ffff88207fe23df0   ffff88207fdfff08   ffffffff8100ed5f  [   1260.975639 ]   ffff88207fdfff38   ffffffff8100fe68   00007ff fe58c3010   0000000000000f 96  [   1261.062995 ]   000000000000f 960   0000000000000f 95   ffff88207fdfff48   ffffffff810020dd  [   1261.150351 ]   00007ff ff58869c1   ffffffff8100b2e9   0000000000000f 96   0000000000000f 95  [   1261.237707 ]   Call   Trace :  [   1261.266825 ]   TSK  [   1261.289704 ]   [ ffffffff8100ec76 ]   __warn . constprop .0 + 0xa6 / 0x100  [   1261.359381 ]   [ ffffffff8100d410 ]   ?   pgd_free + 0x90 / 0x90  [   1261.419699 ]   [ ffffffff8100ed5f ]   warn_slowpath_null + 0xf / 0x20  [   1261.487295 ]   [ ffffffff8100fe68 ]   generic_smp_call_function_single_interrupt + 0xb8 / 0x160  [   1261.581931 ]   [ ffffffff810020dd ]   call_function_interrupt + 0x1d / 0x20  [   1261.655767 ]   [ ffffffff8100b2e9 ]   smp__call_function_interrupt + 0x69 / 0x70    So I decided to look into smp.c a little bit to find out if there is something wrong (I wrote it long time ago). The warning itself is true, it means some inconsistent behavior.. I saw  alloc_percpu  stuff during  call_function_init , hence probably I also need to check percpu code a little code cause I m not sure if I port all the functionalities.  In all, today s task, check  percpu  and  smp_call_function  code. Esp,  percpu  code, they are crucial and very hard to relate real bugs to it.  Well  things changed. I found a more serious bug: something about  cpuhotplug , even though lego is not using it.  cpuhotplug  is a set of implict callbacks to all different subsystems who want to do some initialization work on each  offline- online  cpu.  Let us dig into how secondary cpu boots:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 Trampoline ..   setup   64 bit   mode  start_secondary () \n   smp_callin () \n         notify_cpu_starting () \n               ... \n               while   ( st - state     target )   { \n                       st - state ++ ; \n                       cpuhp_invoke_callback ( cpu ,   st - state ,   true ,   NULL ); \n               } \n           cpuhp_invoke_callback ()    See? There will be some callbacks! What are those callbacks exactly? Well, they are predefined at the  kernel/cpu.c . To save the trouble of reading code, I just print what functions are executed, the log is:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37 [    0.118235] cpuhp_invoke_callback(): 136  CPU:0  page_writeback_cpu_online+0x0/0x20\n\n[    0.368478] cpuhp_invoke_callback(): 136  CPU:1  smpboot_create_threads+0x0/0x90\n[    0.370196] cpuhp_invoke_callback(): 136  CPU:1  perf_event_init_cpu+0x0/0xa0\n[    0.370403] cpuhp_invoke_callback(): 136  CPU:1  workqueue_prepare_cpu+0x0/0x80\n[    0.371112] cpuhp_invoke_callback(): 136  CPU:1  hrtimers_prepare_cpu+0x0/0x60\n[    0.371339] cpuhp_invoke_callback(): 136  CPU:1  smpcfd_prepare_cpu+0x0/0x80\n[    0.371584] cpuhp_invoke_callback(): 136  CPU:1  relay_prepare_cpu+0x0/0xe0\n[    0.371794] cpuhp_invoke_callback(): 136  CPU:1  rcutree_prepare_cpu+0x0/0x170\n[    0.372333] cpuhp_invoke_callback(): 136  CPU:1  notify_prepare+0x0/0xa0\n[    0.372744] cpuhp_invoke_callback(): 136  CPU:1  bringup_cpu+0x0/0x100\n[    0.008000] cpuhp_invoke_callback(): 136  CPU:1  sched_cpu_starting+0x0/0x60\n[    0.926124] cpuhp_invoke_callback(): 136  CPU:1  smpboot_unpark_threads+0x0/0x90\n[    0.926124] cpuhp_invoke_callback(): 136  CPU:1  perf_event_init_cpu+0x0/0xa0\n[    0.927028] cpuhp_invoke_callback(): 136  CPU:1  workqueue_online_cpu+0x0/0x2a0\n[    0.927768] cpuhp_invoke_callback(): 136  CPU:1  rcutree_online_cpu+0x0/0x70\n[    0.928045] cpuhp_invoke_callback(): 136  CPU:1  notify_online+0x0/0x20\n[    0.928256] cpuhp_invoke_callback(): 136  CPU:1  page_writeback_cpu_online+0x0/0x20\n[    0.928527] cpuhp_invoke_callback(): 136  CPU:1  sched_cpu_activate+0x0/0x190\n\n[    0.929084] cpuhp_invoke_callback(): 136  CPU:2  smpboot_create_threads+0x0/0x90\n[    0.930240] cpuhp_invoke_callback(): 136  CPU:2  perf_event_init_cpu+0x0/0xa0\n[    0.930434] cpuhp_invoke_callback(): 136  CPU:2  workqueue_prepare_cpu+0x0/0x80\n[    0.931070] cpuhp_invoke_callback(): 136  CPU:2  hrtimers_prepare_cpu+0x0/0x60\n[    0.931264] cpuhp_invoke_callback(): 136  CPU:2  smpcfd_prepare_cpu+0x0/0x80\n[    0.931464] cpuhp_invoke_callback(): 136  CPU:2  relay_prepare_cpu+0x0/0xe0\n[    0.931649] cpuhp_invoke_callback(): 136  CPU:2  rcutree_prepare_cpu+0x0/0x170\n[    0.932245] cpuhp_invoke_callback(): 136  CPU:2  notify_prepare+0x0/0xa0\n[    0.932475] cpuhp_invoke_callback(): 136  CPU:2  bringup_cpu+0x0/0x100\n[    0.008000] cpuhp_invoke_callback(): 136  CPU:2  sched_cpu_starting+0x0/0x60\n[    1.005023] cpuhp_invoke_callback(): 136  CPU:2  smpboot_unpark_threads+0x0/0x90\n[    1.005065] cpuhp_invoke_callback(): 136  CPU:2  perf_event_init_cpu+0x0/0xa0\n[    1.005408] cpuhp_invoke_callback(): 136  CPU:2  workqueue_online_cpu+0x0/0x2a0\n[    1.005729] cpuhp_invoke_callback(): 136  CPU:2  rcutree_online_cpu+0x0/0x70\n[    1.006029] cpuhp_invoke_callback(): 136  CPU:2  notify_online+0x0/0x20\n[    1.006206] cpuhp_invoke_callback(): 136  CPU:2  page_writeback_cpu_online+0x0/0x20\n[    1.006549] cpuhp_invoke_callback(): 136  CPU:2  sched_cpu_activate+0x0/0x190   Interesting! Currently, Lego need to add the  smpboot_create_threads() ,  workqueue_prepare_cpu() ,  workqueue_prepare_cpu() ,  bringup_cpu() ,  smpboot_unpark_threads() ,  workqueue_online_cpu() .  This hidden things is really hard to find and not easy to track during boot. Especially during boot, they should do something like  for_each_online_cpu  and init one by one. But I guess, after adding support of cpu hotplug, code kind of merged. Some stuff will be executed whenever a cpu has been teardown or bought up. And bang, why not use the same set of hotplug during boot, right?\nWell.", 
            "title": "02/05 Mon Sunny"
        }, 
        {
            "location": "/lego/boot/grub/", 
            "text": "Use GRUB2 to boot Lego\n\n\nLast Updated: 02/02/2018\n\n\nThis document explains: \n1)\n how Lego itself is written to pretend as a Linux kernel, \n2)\n how to boot Lego kernel with GRUB2, \n3)\n GRUB2 configurations specific to Lego.\n\n\nHow Lego pretend as a Linux kernel\n\n\nasdsad\n\n\nHow to config GRUB2 for Lego\n\n\nasdsa", 
            "title": "GRUB"
        }, 
        {
            "location": "/lego/boot/grub/#use-grub2-to-boot-lego", 
            "text": "Last Updated: 02/02/2018  This document explains:  1)  how Lego itself is written to pretend as a Linux kernel,  2)  how to boot Lego kernel with GRUB2,  3)  GRUB2 configurations specific to Lego.", 
            "title": "Use GRUB2 to boot Lego"
        }, 
        {
            "location": "/lego/boot/grub/#how-lego-pretend-as-a-linux-kernel", 
            "text": "asdsad", 
            "title": "How Lego pretend as a Linux kernel"
        }, 
        {
            "location": "/lego/boot/grub/#how-to-config-grub2-for-lego", 
            "text": "asdsa", 
            "title": "How to config GRUB2 for Lego"
        }, 
        {
            "location": "/lego/boot/trampoline/", 
            "text": "How trampoline works in Lego\n\n\nWhat is trampoline code?\n\n\nTrampoline code is used by \nBSP\n to boot other secondary CPUs.\nAt startup, \nBSP\n wakeup secondary CPUs by sending a \nAPIC INIT\n\ncommand, which carry the \n[start_ip]\n where the secondary CPUs should\nstart to run.\n\n\nThe trampoline code is the code starting from \n[start_ip]\n. Used\nby the secondary CPU to jump from \n16-bit realmode\n to \n64-bit\n code\n(the first instruction of 64-bit code will be in \narch/x86/kernel/head_64.S\n).\n\n\nWhere is the trampoline source code?\n\n\nThe source files are all in \narch/x86/realmode/\n. There are two parts: \n1)\n \narch/x86/realmode/rm/trampoline.S\n: which is the code that will run. And it is a mix of 16-bit, 32-bit, 64-bit code (ugh..). \n2)\n \narch/x86/realmode/piggy.S\n: Since the trampoline code can not to linked\ninto kernel image directly. So we have to piggyback the trampoline.bin binary\ncode into a section, which is described by \ntrampoline_start\n and \ntrampoline_end\n. So the kernel can address the trampoline code via these two symbols.\n\n\nThe compile flow is:\n\n1\n2\n3\n4\n5\n6\n    arch/x86/realmode/rm/trmapoline.S\n    -\n CC__ arch/x86/realmode/rm/trmapoline.o\n       -\n LD arch/x86/realmode/rm/trampoline\n          -\n OBJCOPY arch/x86/realmode/rm/trampoline.bin\n             -\n This bin goes into piggy.o\n            -\n piggy.o goes into vmImage\n\n\n\n\n\nWhat happened at runtime?\n\n\nThe setup code was loaded by GRUB below 1MB. Inside \narch/x86/boot/main.c\n, we\nwill save the \ncs()\n into the \nboot_params\n and pass it to kernel. In \nsetup_arch()\n, we will copy the trampoline.bin code to the \ncs()\n address reported by \nboot_param\n. This means we will override setup code, which is okay.\n\n\nAt last, we wake up the secondary CPUs inside \nsmp_init()\n.\n\n\nCompare with Linux\n\n\nI vaguely remember how Linux implement this. The only thing I remember is that Linux use some sort of structure, which is filled by BSP and then passed, or used by secondary CPUs. The mechanism has no difference, though. Linux just has more robust debugging facilities.\n\n\n\nYizhou Shan\n\nMar 3, 2017", 
            "title": "Trampoline"
        }, 
        {
            "location": "/lego/boot/trampoline/#how-trampoline-works-in-lego", 
            "text": "", 
            "title": "How trampoline works in Lego"
        }, 
        {
            "location": "/lego/boot/trampoline/#what-is-trampoline-code", 
            "text": "Trampoline code is used by  BSP  to boot other secondary CPUs.\nAt startup,  BSP  wakeup secondary CPUs by sending a  APIC INIT \ncommand, which carry the  [start_ip]  where the secondary CPUs should\nstart to run.  The trampoline code is the code starting from  [start_ip] . Used\nby the secondary CPU to jump from  16-bit realmode  to  64-bit  code\n(the first instruction of 64-bit code will be in  arch/x86/kernel/head_64.S ).", 
            "title": "What is trampoline code?"
        }, 
        {
            "location": "/lego/boot/trampoline/#where-is-the-trampoline-source-code", 
            "text": "The source files are all in  arch/x86/realmode/ . There are two parts:  1)   arch/x86/realmode/rm/trampoline.S : which is the code that will run. And it is a mix of 16-bit, 32-bit, 64-bit code (ugh..).  2)   arch/x86/realmode/piggy.S : Since the trampoline code can not to linked\ninto kernel image directly. So we have to piggyback the trampoline.bin binary\ncode into a section, which is described by  trampoline_start  and  trampoline_end . So the kernel can address the trampoline code via these two symbols.  The compile flow is: 1\n2\n3\n4\n5\n6     arch/x86/realmode/rm/trmapoline.S\n    -  CC__ arch/x86/realmode/rm/trmapoline.o\n       -  LD arch/x86/realmode/rm/trampoline\n          -  OBJCOPY arch/x86/realmode/rm/trampoline.bin\n             -  This bin goes into piggy.o\n            -  piggy.o goes into vmImage", 
            "title": "Where is the trampoline source code?"
        }, 
        {
            "location": "/lego/boot/trampoline/#what-happened-at-runtime", 
            "text": "The setup code was loaded by GRUB below 1MB. Inside  arch/x86/boot/main.c , we\nwill save the  cs()  into the  boot_params  and pass it to kernel. In  setup_arch() , we will copy the trampoline.bin code to the  cs()  address reported by  boot_param . This means we will override setup code, which is okay.  At last, we wake up the secondary CPUs inside  smp_init() .", 
            "title": "What happened at runtime?"
        }, 
        {
            "location": "/lego/boot/trampoline/#compare-with-linux", 
            "text": "I vaguely remember how Linux implement this. The only thing I remember is that Linux use some sort of structure, which is filled by BSP and then passed, or used by secondary CPUs. The mechanism has no difference, though. Linux just has more robust debugging facilities.  \nYizhou Shan \nMar 3, 2017", 
            "title": "Compare with Linux"
        }, 
        {
            "location": "/lego/kernel/kconfig/", 
            "text": "Lego Kconfig\n\n\nNetwork\n\n\n\n\nEnable \nCONFIG_INFINIBAND\n\n\nEnable \nCONFIG_FIT\n\n\nSet \nCONFIG_FIT_INITIAL_SLEEP_TIMEOUT\n: boot time connection timeout\n\n\nSet \nCONFIG_FIT_NR_NODES\n: number of Lego nodes in this run\n\n\nSet \nCONFIG_FIT_LOCAL_ID\n: current node id\n\n\n\n\nIn \nnet/lego/fit_machine.c\n, modify the \nlego_cluster_hostnames\n array to match the machines you are using.\n\n\n\n\n\n\nSet \nCONFIG_DEFAULT_MEM_NODE\n in processor manager\n\n\n\n\nSet \nCONFIG_DEFAULT_STORAGE_NODE\n if you are running with storage component.\n\n\n\n\nNetwork configuration is crucial, please make sure all Lego nodes have consistent configurations. Otherwise the system may panic or fail to connect.\n\n\nProcessor\n\n\n\n\nEnable \nCONFIG_COMP_PROCESSOR\n\n\nopen \n.config\n\n\nremove line \n# CONFIG_COMP_PROCESSOR is not set\n\n\nclose \n.config\n\n\ndo \nmake\n, you will see \nConfigure Lego as processor component (COMP_PROCESSOR) [N/y/?] (NEW)\n, select Y\n\n\nChoose default configuration for all new config options\n\n\n\n\n\n\nEnable \nCONFIG_USE_RAMFS\n if you are not using storage components\n\n\n\n\nMemory\n\n\n\n\nEnable \nCONFIG_COMP_MEMORY\n\n\nopen \n.config\n\n\nremove line \n# CONFIG_COMP_MEMORY is not set\n\n\nclose \n.config\n\n\ndo \nmake\n, you will see \nConfigure Lego as memory component manager (COMP_MEMORY) [N/y/?] (NEW)\n, select Y\n\n\nChoose default configuration for all new config options\n\n\n\n\n\n\nEnable \nCONFIG_USE_RAMFS\n if you are not using storage components\n\n\nSet \nCONFIG_RAMFS_OBJECT_FILE\n: points to \nstatic-linked\n ELF file that you want to execute.\n\n\ntips: you can put your test code under \nusr/\n directory, and a simple \nmake\n will compile everything under.\n\n\n\n\n\n\n\n\nRun without Storage Component\n\n\nTo run Lego just with one processor component and one memory component, you need to:\n\n\n\n\nEnable \nCONFIG_USE_RAMFS\n at both sides. And in memory side, you need to set the \nCONFIG_RAMFS_OBJECT_FILE\n, which points to the ELF binary you want to test.\n\n\nmake sure \nCONFIG_DEFAULT_MEM_NODE\n at processor component is pointing to memory component\ns node id.\n\n\n\n\nA typical code snippet and configuration would be:\n\n1\n2\n3\n4\nstatic\n \nconst\n \nchar\n \n*\nlego_cluster_hostnames\n[\nCONFIG_FIT_NR_NODES\n]\n \n=\n \n{\n\n        \n[\n0\n]\n     \n=\n       \nwuklab00\n,\n\n        \n[\n1\n]\n     \n=\n       \nwuklab01\n,\n\n\n};\n\n\n\n\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\nwuklab00 Processor\n\n#\n# Lego Processor Component Configurations\n#\nCONFIG_COMP_PROCESSOR=y\nCONFIG_CHECKPOINT=y\nCONFIG_MEMMAP_MEMBLOCK_RESERVED=y\n# CONFIG_PCACHE_EVICT_RANDOM is not set\n# CONFIG_PCACHE_EVICT_FIFO is not set\nCONFIG_PCACHE_EVICT_LRU=y\nCONFIG_PCACHE_EVICT_GENERIC_SWEEP=y\n# CONFIG_PCACHE_EVICTION_WRITE_PROTECT is not set\n# CONFIG_PCACHE_EVICTION_PERSET_LIST is not set\nCONFIG_PCACHE_EVICTION_VICTIM=y\nCONFIG_PCACHE_EVICTION_VICTIM_NR_ENTRIES=8\nCONFIG_PCACHE_PREFETCH=y\n\n#\n# Processor DEBUG Options\n#\n\n#\n# Lego Memory Component Configurations\n#\n# CONFIG_COMP_MEMORY is not set\n\n#\n# DRAM Cache Options\n#\nCONFIG_PCACHE_LINE_SIZE_SHIFT=12\nCONFIG_PCACHE_ASSOCIATIVITY_SHIFT=3\n\n#\n# General Manager Config/Debug Options\n#\nCONFIG_DEFAULT_MEM_NODE=1\nCONFIG_DEFAULT_STORAGE_NODE=2\nCONFIG_USE_RAMFS=y\n\n#\n# Networking\n#\n# CONFIG_LWIP is not set\nCONFIG_FIT=y\n# CONFIG_FIT_DEBUG is not set\nCONFIG_FIT_INITIAL_SLEEP_TIMEOUT=30\nCONFIG_FIT_NR_NODES=2\nCONFIG_FIT_LOCAL_ID=0\n\n\n\n\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\nwuklab01 Memory\n\n#\n# Lego Memory Component Configurations\n#\nCONFIG_COMP_MEMORY=y\n\n#\n# Memory DEBUG Options\n#\n# CONFIG_MEM_PREFETCH is not set\n\n#\n# DRAM Cache Options\n#\nCONFIG_PCACHE_LINE_SIZE_SHIFT=12\nCONFIG_PCACHE_ASSOCIATIVITY_SHIFT=3\n\n#\n# General Manager Config/Debug Options\n#\nCONFIG_DEFAULT_MEM_NODE=1\nCONFIG_DEFAULT_STORAGE_NODE=2\nCONFIG_USE_RAMFS=y\nCONFIG_RAMFS_OBJECT_FILE=\nusr/pcache_conflict.o\n\n\n#\n# Networking\n#\n# CONFIG_LWIP is not set\nCONFIG_FIT=y\n# CONFIG_FIT_DEBUG is not set\nCONFIG_FIT_INITIAL_SLEEP_TIMEOUT=30\nCONFIG_FIT_NR_NODES=2\nCONFIG_FIT_LOCAL_ID=1", 
            "title": "Kconfig"
        }, 
        {
            "location": "/lego/kernel/kconfig/#lego-kconfig", 
            "text": "", 
            "title": "Lego Kconfig"
        }, 
        {
            "location": "/lego/kernel/kconfig/#network", 
            "text": "Enable  CONFIG_INFINIBAND  Enable  CONFIG_FIT  Set  CONFIG_FIT_INITIAL_SLEEP_TIMEOUT : boot time connection timeout  Set  CONFIG_FIT_NR_NODES : number of Lego nodes in this run  Set  CONFIG_FIT_LOCAL_ID : current node id   In  net/lego/fit_machine.c , modify the  lego_cluster_hostnames  array to match the machines you are using.    Set  CONFIG_DEFAULT_MEM_NODE  in processor manager   Set  CONFIG_DEFAULT_STORAGE_NODE  if you are running with storage component.   Network configuration is crucial, please make sure all Lego nodes have consistent configurations. Otherwise the system may panic or fail to connect.", 
            "title": "Network"
        }, 
        {
            "location": "/lego/kernel/kconfig/#processor", 
            "text": "Enable  CONFIG_COMP_PROCESSOR  open  .config  remove line  # CONFIG_COMP_PROCESSOR is not set  close  .config  do  make , you will see  Configure Lego as processor component (COMP_PROCESSOR) [N/y/?] (NEW) , select Y  Choose default configuration for all new config options    Enable  CONFIG_USE_RAMFS  if you are not using storage components", 
            "title": "Processor"
        }, 
        {
            "location": "/lego/kernel/kconfig/#memory", 
            "text": "Enable  CONFIG_COMP_MEMORY  open  .config  remove line  # CONFIG_COMP_MEMORY is not set  close  .config  do  make , you will see  Configure Lego as memory component manager (COMP_MEMORY) [N/y/?] (NEW) , select Y  Choose default configuration for all new config options    Enable  CONFIG_USE_RAMFS  if you are not using storage components  Set  CONFIG_RAMFS_OBJECT_FILE : points to  static-linked  ELF file that you want to execute.  tips: you can put your test code under  usr/  directory, and a simple  make  will compile everything under.", 
            "title": "Memory"
        }, 
        {
            "location": "/lego/kernel/kconfig/#run-without-storage-component", 
            "text": "To run Lego just with one processor component and one memory component, you need to:   Enable  CONFIG_USE_RAMFS  at both sides. And in memory side, you need to set the  CONFIG_RAMFS_OBJECT_FILE , which points to the ELF binary you want to test.  make sure  CONFIG_DEFAULT_MEM_NODE  at processor component is pointing to memory component s node id.   A typical code snippet and configuration would be: 1\n2\n3\n4 static   const   char   * lego_cluster_hostnames [ CONFIG_FIT_NR_NODES ]   =   { \n         [ 0 ]       =         wuklab00 , \n         [ 1 ]       =         wuklab01 ,  };     1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49 wuklab00 Processor\n\n#\n# Lego Processor Component Configurations\n#\nCONFIG_COMP_PROCESSOR=y\nCONFIG_CHECKPOINT=y\nCONFIG_MEMMAP_MEMBLOCK_RESERVED=y\n# CONFIG_PCACHE_EVICT_RANDOM is not set\n# CONFIG_PCACHE_EVICT_FIFO is not set\nCONFIG_PCACHE_EVICT_LRU=y\nCONFIG_PCACHE_EVICT_GENERIC_SWEEP=y\n# CONFIG_PCACHE_EVICTION_WRITE_PROTECT is not set\n# CONFIG_PCACHE_EVICTION_PERSET_LIST is not set\nCONFIG_PCACHE_EVICTION_VICTIM=y\nCONFIG_PCACHE_EVICTION_VICTIM_NR_ENTRIES=8\nCONFIG_PCACHE_PREFETCH=y\n\n#\n# Processor DEBUG Options\n#\n\n#\n# Lego Memory Component Configurations\n#\n# CONFIG_COMP_MEMORY is not set\n\n#\n# DRAM Cache Options\n#\nCONFIG_PCACHE_LINE_SIZE_SHIFT=12\nCONFIG_PCACHE_ASSOCIATIVITY_SHIFT=3\n\n#\n# General Manager Config/Debug Options\n#\nCONFIG_DEFAULT_MEM_NODE=1\nCONFIG_DEFAULT_STORAGE_NODE=2\nCONFIG_USE_RAMFS=y\n\n#\n# Networking\n#\n# CONFIG_LWIP is not set\nCONFIG_FIT=y\n# CONFIG_FIT_DEBUG is not set\nCONFIG_FIT_INITIAL_SLEEP_TIMEOUT=30\nCONFIG_FIT_NR_NODES=2\nCONFIG_FIT_LOCAL_ID=0    1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35 wuklab01 Memory\n\n#\n# Lego Memory Component Configurations\n#\nCONFIG_COMP_MEMORY=y\n\n#\n# Memory DEBUG Options\n#\n# CONFIG_MEM_PREFETCH is not set\n\n#\n# DRAM Cache Options\n#\nCONFIG_PCACHE_LINE_SIZE_SHIFT=12\nCONFIG_PCACHE_ASSOCIATIVITY_SHIFT=3\n\n#\n# General Manager Config/Debug Options\n#\nCONFIG_DEFAULT_MEM_NODE=1\nCONFIG_DEFAULT_STORAGE_NODE=2\nCONFIG_USE_RAMFS=y\nCONFIG_RAMFS_OBJECT_FILE= usr/pcache_conflict.o \n\n#\n# Networking\n#\n# CONFIG_LWIP is not set\nCONFIG_FIT=y\n# CONFIG_FIT_DEBUG is not set\nCONFIG_FIT_INITIAL_SLEEP_TIMEOUT=30\nCONFIG_FIT_NR_NODES=2\nCONFIG_FIT_LOCAL_ID=1", 
            "title": "Run without Storage Component"
        }, 
        {
            "location": "/lego/kernel/debug/", 
            "text": "Debug Facility in Lego\n\n\nLego provides several handy debug helpers to ease our coding pain. We category them by layers, namely \n1)\n \nCore Kernel\n, the lowest level of Lego, which is shared by all managers. \n2)\n \nProcessor Manager\n, which controls processor components. \n3)\n \nMemory Manager\n, which controls memory components.\n\n\nCore Kernel\n\n\n1\n2\nvoid\n \ndump_pte\n(\npte_t\n \n*\nptep\n,\n \nconst\n \nchar\n \n*\nreason\n);\n\n\nvoid\n \ndump_page\n(\nstruct\n \npage\n \n*\npage\n,\n \nconst\n \nchar\n \n*\nreason\n);\n\n\n\n\n\nThese two helpers will dump a given pte entry or a page. Use this function if you are developing core related to physical memory allocation or pcache.\n\n\n\n\n1\nvoid\n \nptdump_walk_pgd_level\n(\npgd_t\n \n*\npgd\n);\n\n\n\n\n\nThis debug helper will dump the whole pgtable ranges. Contiguous page table entries that share the same property will be merged together and will be printed once. Use this function if you are developing code related to user page tables.\n\n\n\n\n1\n2\n3\nvoid\n \nshow_state_filter\n(\nunsigned\n \nlong\n \nstate_filter\n,\n \nbool\n \nprint_rq\n);\n\n\nvoid\n \nsched_show_task\n(\nstruct\n \ntask_struct\n \n*\np\n);\n\n\nvoid\n \nsysrq_sched_debug_show\n(\nvoid\n);\n\n\n\n\n\nThis set of functions are debug helpers for local scheduler. They will print all the tasks running in the system, and detailed information about percpu \nrunqueue\n. Use this set of functions if you are developing code related to scheduler.\n\n\nProcessor Manager\n\n\n1\n2\n3\n4\nvoid\n \ndump_pcache_meta\n(\nstruct\n \npcache_meta\n \n*\npcm\n,\n \nconst\n \nchar\n \n*\nreason\n);\n\n\nvoid\n \ndump_pcache_victim\n(\nstruct\n \npcache_victim_meta\n \n*\nvictim\n,\n \nconst\n \nchar\n \n*\nreason\n);\n\n\nvoid\n \ndump_pcache_rmap\n(\nstruct\n \npcache_rmap\n \n*\nrmap\n,\n \nconst\n \nchar\n \n*\nreason\n);\n\n\nvoid\n \ndump_pcache_line\n(\nstruct\n \npcache_meta\n \n*\npcm\n,\n \nconst\n \nchar\n \n*\nreason\n);\n\n\n\n\n\nThese functions dump a given pcache line, a victim line, or a given reserve mapping. The last one will print the pcache line content, which generates a lot messages, you are warned. Use these functions if you are developing pcache or victim cache code.\n\n\nMemory Manager\n\n\n1\n2\nvoid\n \ndump_lego_mm\n(\nconst\n \nstruct\n \nlego_mm_struct\n \n*\nmm\n);\n\n\nvoid\n \ndump_vma\n(\nconst\n \nstruct\n \nvm_area_struct\n \n*\nvma\n);\n\n\n\n\n\nThese two functions are used to dump the virtual address space of a process. Use these functions if you developing process VM related things.", 
            "title": "Debug"
        }, 
        {
            "location": "/lego/kernel/debug/#debug-facility-in-lego", 
            "text": "Lego provides several handy debug helpers to ease our coding pain. We category them by layers, namely  1)   Core Kernel , the lowest level of Lego, which is shared by all managers.  2)   Processor Manager , which controls processor components.  3)   Memory Manager , which controls memory components.", 
            "title": "Debug Facility in Lego"
        }, 
        {
            "location": "/lego/kernel/debug/#core-kernel", 
            "text": "1\n2 void   dump_pte ( pte_t   * ptep ,   const   char   * reason );  void   dump_page ( struct   page   * page ,   const   char   * reason );   \nThese two helpers will dump a given pte entry or a page. Use this function if you are developing core related to physical memory allocation or pcache.   1 void   ptdump_walk_pgd_level ( pgd_t   * pgd );   \nThis debug helper will dump the whole pgtable ranges. Contiguous page table entries that share the same property will be merged together and will be printed once. Use this function if you are developing code related to user page tables.   1\n2\n3 void   show_state_filter ( unsigned   long   state_filter ,   bool   print_rq );  void   sched_show_task ( struct   task_struct   * p );  void   sysrq_sched_debug_show ( void );   \nThis set of functions are debug helpers for local scheduler. They will print all the tasks running in the system, and detailed information about percpu  runqueue . Use this set of functions if you are developing code related to scheduler.", 
            "title": "Core Kernel"
        }, 
        {
            "location": "/lego/kernel/debug/#processor-manager", 
            "text": "1\n2\n3\n4 void   dump_pcache_meta ( struct   pcache_meta   * pcm ,   const   char   * reason );  void   dump_pcache_victim ( struct   pcache_victim_meta   * victim ,   const   char   * reason );  void   dump_pcache_rmap ( struct   pcache_rmap   * rmap ,   const   char   * reason );  void   dump_pcache_line ( struct   pcache_meta   * pcm ,   const   char   * reason );   \nThese functions dump a given pcache line, a victim line, or a given reserve mapping. The last one will print the pcache line content, which generates a lot messages, you are warned. Use these functions if you are developing pcache or victim cache code.", 
            "title": "Processor Manager"
        }, 
        {
            "location": "/lego/kernel/debug/#memory-manager", 
            "text": "1\n2 void   dump_lego_mm ( const   struct   lego_mm_struct   * mm );  void   dump_vma ( const   struct   vm_area_struct   * vma );   \nThese two functions are used to dump the virtual address space of a process. Use these functions if you developing process VM related things.", 
            "title": "Memory Manager"
        }, 
        {
            "location": "/lego/kernel/pagefault_disable/", 
            "text": "The story of pagefault_disable/enable\n\n\npagefault_disable()\n is not really disabling the whole pgfault handling code. It is used to disable only the handling of pgfault that landed from \nuser virtual address\n. Please note the difference between \nuser virtual address\n and \nuser mode fault\n. The first means the faulting address belongs to user virtual address space, while it can come from either user mode (CPL3) or kernel mode (CPL0). The second is a fault come from user mode (CPL3).\n\n\nIf pgfault is disabled, then \ndo_page_fault()\n function will \nNOT\n try to solve the pgfault by calling into \npcache\n, instead, it will go straight to \nfixup\n code (in no_context()).\n\n\nThis function is not intended to be used standalone. Normally, we do \n1)\n \npagefault_disable()\n, \n2)\n then use some functions that have \nfixup\n code, \n3)\n then \npagefault_enable()\n. (The \nfixup\n code is another magic inside kernel. We will cover it in another document.)\n\n\nCurrently in Lego, this is only used by \nfutex\n, which needs something like \natomic_cmpxchg()\n with an user virtual address. If pgfault happens in the middle, then this will not be atomic since kernel need to do pcache operations, which further needs to through network.\n\n\nHowever, do note the difference with \nuaccess\n family functions. Most \nuaccess\n functions will not disable pgfault handling, which means pcache will be invoked. If pcache returns a \nSEGFAULT\n, pgfault code will go into \nfixup\n code. And that, my friend, is where \nuaccess\n returns \n-EFAULT\n to caller.\n\n\n\nYizhou Shan\n\nFeb 01, 2018", 
            "title": "Disable pgfault"
        }, 
        {
            "location": "/lego/kernel/pagefault_disable/#the-story-of-pagefault_disableenable", 
            "text": "pagefault_disable()  is not really disabling the whole pgfault handling code. It is used to disable only the handling of pgfault that landed from  user virtual address . Please note the difference between  user virtual address  and  user mode fault . The first means the faulting address belongs to user virtual address space, while it can come from either user mode (CPL3) or kernel mode (CPL0). The second is a fault come from user mode (CPL3).  If pgfault is disabled, then  do_page_fault()  function will  NOT  try to solve the pgfault by calling into  pcache , instead, it will go straight to  fixup  code (in no_context()).  This function is not intended to be used standalone. Normally, we do  1)   pagefault_disable() ,  2)  then use some functions that have  fixup  code,  3)  then  pagefault_enable() . (The  fixup  code is another magic inside kernel. We will cover it in another document.)  Currently in Lego, this is only used by  futex , which needs something like  atomic_cmpxchg()  with an user virtual address. If pgfault happens in the middle, then this will not be atomic since kernel need to do pcache operations, which further needs to through network.  However, do note the difference with  uaccess  family functions. Most  uaccess  functions will not disable pgfault handling, which means pcache will be invoked. If pcache returns a  SEGFAULT , pgfault code will go into  fixup  code. And that, my friend, is where  uaccess  returns  -EFAULT  to caller.  \nYizhou Shan \nFeb 01, 2018", 
            "title": "The story of pagefault_disable/enable"
        }, 
        {
            "location": "/lego/kernel/stop_machine/", 
            "text": "The highest priority thread in kernel\n\n\nThis document is about \nmigration/N\n kernel threads, \nstop_sched\n schdueling class, and the interesting source file \nkernel/stop_machine.c\n. Background on kernel scheduler design is recommended.\n\n\nScheduler uses the following code to pick the next runnable task:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\nstatic\n \ninline\n \nstruct\n \ntask_struct\n \n*\n\n\npick_next_task\n(\nstruct\n \nrq\n \n*\nrq\n,\n \nstruct\n \ntask_struct\n \n*\nprev\n)\n\n\n{\n\n        \nstruct\n \ntask_struct\n \n*\np\n;\n\n        \nconst\n \nstruct\n \nsched_class\n \n*\nclass\n;\n\n\n\nagain\n:\n\n        \nfor_each_class\n(\nclass\n)\n \n{\n\n                \np\n \n=\n \nclass\n-\npick_next_task\n(\nrq\n,\n \nprev\n);\n\n                \nif\n \n(\np\n)\n \n{\n\n                        \nif\n \n(\nunlikely\n(\np\n \n==\n \nRETRY_TASK\n))\n\n                                \ngoto\n \nagain\n;\n\n                        \nreturn\n \np\n;\n\n                \n}\n    \n        \n}\n\n        \nBUG\n();\n\n\n}\n\n\n\n\n\n\nwhile the class is linked together as:\n\n1\n2\n3\n#define sched_class_highest     (\nstop_sched_class)                                                       \n\n\n#define for_each_class(class) \\                                                                           \n\n   \nfor\n \n(\nclass\n \n=\n \nsched_class_highest\n;\n \nclass\n;\n \nclass\n \n=\n \nclass\n-\nnext\n)\n\n\n\n\n\n\nClearly, the highest priority class is \nstop_sched_class\n. Whenever this scheduling has class runnable threads, scheduler will always run them first. So what kernel threads are using this scheduling class? Well, you must have seen something like \nmigration/0\n when you do \nps aux\n in Linux. And yes, these kernel threads are the only users.\n\n\nThese threads are sleeping most of their lifetime, they will be invoked to do some very urgent stuff. For example, when a user thread that is currently running on CPU0 calls \nsched_setaffinity()\n to bind to CPU1, kernel is not able to do this because this user thread is currently running (runqueue can not move a \nrunning\n task out, it can only move queued task out). Then, scheduler has to ask \nmigration/0\n for help. Once there is a job enqueued, \nmigration/0\n will be invoked. Since it has the highest-priority, it will start execution immediately. Thus the migration from CPU0 to CPU1 is performed safely and fast.\n\n\nmigration\n code is defined in \nkernel/stop_machine.c\n. They are created during early boot. They use the \nsmpboot_register_percpu_thread\n to create threads. They are written in this way because Linux supports cpu hotplug. To simplify we can also create them manually through \nkthread_create\n. Since Lego does not support cpu hotplug, and this \ncpu_stop_init\n is called after SMP is initialized, so Lego has slight different initialiaztion:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\nvoid\n \n__init\n \ncpu_stop_init\n(\nvoid\n)\n\n\n{\n\n        \nunsigned\n \nint\n \ncpu\n;\n\n\n        \nfor_each_possible_cpu\n(\ncpu\n)\n \n{\n\n                \nstruct\n \ncpu_stopper\n \n*\nstopper\n \n=\n \nper_cpu\n(\ncpu_stopper\n,\n \ncpu\n);\n\n\n                \nspin_lock_init\n(\nstopper\n-\nlock\n);\n\n                \nINIT_LIST_HEAD\n(\nstopper\n-\nworks\n);\n\n        \n}\n\n\n        \nBUG_ON\n(\nsmpboot_register_percpu_thread\n(\ncpu_stop_threads\n));\n\n\n        \n/*\n\n\n         * smpboot_create_threads use kthread_create_on_cpu() to\n\n\n         * create new threads. And they are parked, too.\n\n\n         * Since we call this function after smp_init(), all CPUs\n\n\n         * are already online, thus we need to unpark them manually.\n\n\n         */\n\n        \nfor_each_online_cpu\n(\ncpu\n)\n\n                \nstop_machine_unpark\n(\ncpu\n);\n\n\n\n\n\n\nInternally, it also use a list to keep enqueued jobs. Once the thread is waken up, it tries to lookup this list and dequeue jobs (similar to kthread creation, kworker etc.):\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\nstatic\n \nvoid\n \ncpu_stopper_thread\n(\nunsigned\n \nint\n \ncpu\n)\n\n\n{\n\n        \nstruct\n \ncpu_stopper\n \n*\nstopper\n \n=\n \nper_cpu\n(\ncpu_stopper\n,\n \ncpu\n);\n\n        \nstruct\n \ncpu_stop_work\n \n*\nwork\n;\n\n\n\nrepeat\n:\n\n        \nwork\n \n=\n \nNULL\n;\n\n        \nspin_lock_irq\n(\nstopper\n-\nlock\n);\n\n        \nif\n \n(\n!\nlist_empty\n(\nstopper\n-\nworks\n))\n \n{\n\n                \nwork\n \n=\n \nlist_first_entry\n(\nstopper\n-\nworks\n,\n\n                                        \nstruct\n \ncpu_stop_work\n,\n \nlist\n);\n\n                \nlist_del_init\n(\nwork\n-\nlist\n);\n\n        \n}\n   \n        \nspin_unlock_irq\n(\nstopper\n-\nlock\n);\n\n\n        \nif\n \n(\nwork\n)\n \n{\n\n                \n...\n\n                \nret\n \n=\n \nfn\n(\narg\n);\n\n                \n...\n\n                \ngoto\n \nrepeat\n;\n\n        \n}\n   \n\n}\n\n\n\n\n\n\nIt has several interesting public APIs that are quite similar to \nsmp_call_functions\n, but the difference is: this set of APIs provide a guaranteed time-to-execute waiting time, because it will simply preempt anything running on CPU.\n\n\n1\n2\n3\nint\n \nstop_one_cpu\n(\nunsigned\n \nint\n \ncpu\n,\n \ncpu_stop_fn_t\n \nfn\n,\n \nvoid\n \n*\narg\n);\n\n\nint\n \nstop_cpus\n(\nconst\n \nstruct\n \ncpumask\n \n*\ncpumask\n,\n \ncpu_stop_fn_t\n \nfn\n,\n \nvoid\n \n*\narg\n);\n\n\nint\n \ntry_stop_cpus\n(\nconst\n \nstruct\n \ncpumask\n \n*\ncpumask\n,\n \ncpu_stop_fn_t\n \nfn\n,\n \nvoid\n \n*\narg\n);\n\n\n\n\n\n\n\nThey are used only when there are some very urgent things to do. So, please use with caution.\n\n\n\nYizhou Shan\n\nFeb 12, 2018", 
            "title": "Stop machine"
        }, 
        {
            "location": "/lego/kernel/stop_machine/#the-highest-priority-thread-in-kernel", 
            "text": "This document is about  migration/N  kernel threads,  stop_sched  schdueling class, and the interesting source file  kernel/stop_machine.c . Background on kernel scheduler design is recommended.  Scheduler uses the following code to pick the next runnable task:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17 static   inline   struct   task_struct   *  pick_next_task ( struct   rq   * rq ,   struct   task_struct   * prev )  { \n         struct   task_struct   * p ; \n         const   struct   sched_class   * class ;  again : \n         for_each_class ( class )   { \n                 p   =   class - pick_next_task ( rq ,   prev ); \n                 if   ( p )   { \n                         if   ( unlikely ( p   ==   RETRY_TASK )) \n                                 goto   again ; \n                         return   p ; \n                 }     \n         } \n         BUG ();  }    while the class is linked together as: 1\n2\n3 #define sched_class_highest     ( stop_sched_class)                                                         #define for_each_class(class) \\                                                                            \n    for   ( class   =   sched_class_highest ;   class ;   class   =   class - next )    Clearly, the highest priority class is  stop_sched_class . Whenever this scheduling has class runnable threads, scheduler will always run them first. So what kernel threads are using this scheduling class? Well, you must have seen something like  migration/0  when you do  ps aux  in Linux. And yes, these kernel threads are the only users.  These threads are sleeping most of their lifetime, they will be invoked to do some very urgent stuff. For example, when a user thread that is currently running on CPU0 calls  sched_setaffinity()  to bind to CPU1, kernel is not able to do this because this user thread is currently running (runqueue can not move a  running  task out, it can only move queued task out). Then, scheduler has to ask  migration/0  for help. Once there is a job enqueued,  migration/0  will be invoked. Since it has the highest-priority, it will start execution immediately. Thus the migration from CPU0 to CPU1 is performed safely and fast.  migration  code is defined in  kernel/stop_machine.c . They are created during early boot. They use the  smpboot_register_percpu_thread  to create threads. They are written in this way because Linux supports cpu hotplug. To simplify we can also create them manually through  kthread_create . Since Lego does not support cpu hotplug, and this  cpu_stop_init  is called after SMP is initialized, so Lego has slight different initialiaztion:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21 void   __init   cpu_stop_init ( void )  { \n         unsigned   int   cpu ; \n\n         for_each_possible_cpu ( cpu )   { \n                 struct   cpu_stopper   * stopper   =   per_cpu ( cpu_stopper ,   cpu ); \n\n                 spin_lock_init ( stopper - lock ); \n                 INIT_LIST_HEAD ( stopper - works ); \n         } \n\n         BUG_ON ( smpboot_register_percpu_thread ( cpu_stop_threads )); \n\n         /*           * smpboot_create_threads use kthread_create_on_cpu() to           * create new threads. And they are parked, too.           * Since we call this function after smp_init(), all CPUs           * are already online, thus we need to unpark them manually.           */ \n         for_each_online_cpu ( cpu ) \n                 stop_machine_unpark ( cpu );    Internally, it also use a list to keep enqueued jobs. Once the thread is waken up, it tries to lookup this list and dequeue jobs (similar to kthread creation, kworker etc.):  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22 static   void   cpu_stopper_thread ( unsigned   int   cpu )  { \n         struct   cpu_stopper   * stopper   =   per_cpu ( cpu_stopper ,   cpu ); \n         struct   cpu_stop_work   * work ;  repeat : \n         work   =   NULL ; \n         spin_lock_irq ( stopper - lock ); \n         if   ( ! list_empty ( stopper - works ))   { \n                 work   =   list_first_entry ( stopper - works , \n                                         struct   cpu_stop_work ,   list ); \n                 list_del_init ( work - list ); \n         }    \n         spin_unlock_irq ( stopper - lock ); \n\n         if   ( work )   { \n                 ... \n                 ret   =   fn ( arg ); \n                 ... \n                 goto   repeat ; \n         }     }    It has several interesting public APIs that are quite similar to  smp_call_functions , but the difference is: this set of APIs provide a guaranteed time-to-execute waiting time, because it will simply preempt anything running on CPU.  1\n2\n3 int   stop_one_cpu ( unsigned   int   cpu ,   cpu_stop_fn_t   fn ,   void   * arg );  int   stop_cpus ( const   struct   cpumask   * cpumask ,   cpu_stop_fn_t   fn ,   void   * arg );  int   try_stop_cpus ( const   struct   cpumask   * cpumask ,   cpu_stop_fn_t   fn ,   void   * arg );    They are used only when there are some very urgent things to do. So, please use with caution.  \nYizhou Shan \nFeb 12, 2018", 
            "title": "The highest priority thread in kernel"
        }, 
        {
            "location": "/lego/kernel/loader/", 
            "text": "Lego Program Loader\n\n\nThis document explains the high-level workflow of Lego\ns program loader, and how we change the normal loader to fit the disaggregated operating system model. Background on linking and loading is recommended.\n\n\nStatus\n\n\n\n\n\n\n\n\nFormats\n\n\nSupported\n\n\n\n\n\n\n\n\n\n\nELF (static-linked)\n\n\n\n\n\n\n\n\nELF (dynamic-linked)\n\n\n\n\n\n\n\n\n\n\nOverall\n\n\nIn order to support different executable formats, Lego has a \nvirtual loader layer\n above all specific formats, which is quite similar to \nvirtual file system\n. In Lego, \nexecve()\n is divided into two parts: \n1)\n syscall hook at processor side, \n2)\n real loader at memory side. Combined together, they provide the same semantic of \nexecve()\n as described in Linux man page. Also for the code, we divide the Linux implementation into parts. But our emulation model introduces several interesting workarounds, which we will talk later.\n\n\nTherefore, before we dive into Lego\ns implementation, we first walk through Linux\ns code, describe the important steps, and then we will talk about how lego divide these functionalities to fit disaggregated operating system model.\n\n\nLinux\ns Loader\n\n\nThis section describes the overall code flow of \nexecve()\n within Linux. From the entry point to the return assembly part.\n\n\nEntry Point\n\n\nSo the normal entry point is \ndo_execve()\n that will do all dirty work. Above that, it can be invoked by syscall from user space, or from kernel space by calling \ndo_execve()\n directly. There are not too many places that will call \ndo_execve\n within kernel. One notable case is how kernel starts the \npid 1\n user program. This happens after kernel finished all initialization. The code is:\n\n1\n2\n3\n4\n5\nstatic\n \nint\n \nrun_init_process\n(\nconst\n \nchar\n \n*\ninit_filename\n)\n                                                    \n\n{\n\n        \nargv_init\n[\n0\n]\n \n=\n \ninit_filename\n;\n\n        \nreturn\n \ndo_execve\n(\ninit_filename\n,\n \nargv_init\n,\n \nenvp_init\n);\n\n\n}\n\n\n\n\n\n\nMain Routine\n\n\nLinux is good at making things complex, the execve main routine is no different. To accommodate different usages, the final dirty work is done by:\n\n1\n2\n3\n4\n5\n6\n7\n/*\n\n\n * sys_execve() executes a new program.\n\n\n */\n\n\nstatic\n \nint\n \ndo_execveat_common\n(\nint\n \nfd\n,\n \nstruct\n \nfilename\n \n*\nfilename\n,\n\n                              \nstruct\n \nuser_arg_ptr\n \nargv\n,\n\n                              \nstruct\n \nuser_arg_ptr\n \nenvp\n,\n\n                              \nint\n \nflags\n);\n\n\n\n\n\n\nLego\ns Loader\n\n\nFeatures\n\n\nThis section lists various features, or behaviors and Lego\ns program loader.\n\n\n\n\nVirtual Address Space Range\n\n\nUser\ns virtual address falls into this range:\n\n1\n[sysctl_mmap_min_addr, TASK_SIZE)\n\n\n\n\n\nBy default,\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\nunsigned\n \nlong\n \nsysctl_mmap_min_addr\n \n=\n \nPAGE_SIZE\n;\n\n\n\n/*\n\n\n * User space process size. 47bits minus one guard page.  The guard\n\n\n * page is necessary on Intel CPUs: if a SYSCALL instruction is at\n\n\n * the highest possible canonical userspace address, then that\n\n\n * syscall will enter the kernel with a non-canonical return\n\n\n * address, and SYSRET will explode dangerously.  We avoid this\n\n\n * particular problem by preventing anything from being mapped\n\n\n * at the maximum canonical address.\n\n\n */\n                                                                                                       \n\n#define TASK_SIZE       ((1UL \n 47) - PAGE_SIZE)\n\n\n\n\n\n\nEssentially:\n\n1\n[0x1000, 0x7ffffffff000)\n\n\n\n\n\n\n\nPre-Populated \n.bss\n and \n.brk\n\n\nThe heap vma created at loading time is a combination of \n.bss\n and \n.brk\n segments. Since brk usage is 0 (will it be non-zero?) at this moment, so the heap vma is essentially just \n.bss\n pages. Normally, Linux kernel does not populate pages for this vma during loading, but Lego does. It can save several page allocation cost for heap pcache miss. It is controlled by \nvm_brk()\n.\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\nint\n \nvm_brk\n(\nstruct\n \nlego_task_struct\n \n*\ntsk\n,\n\n           \nunsigned\n \nlong\n \nstart\n,\n \nunsigned\n \nlong\n \nlen\n)\n\n\n{\n\n        \nint\n \nret\n;\n\n        \nstruct\n \nlego_mm_struct\n \n*\nmm\n \n=\n \ntsk\n-\nmm\n;\n\n\n        \nif\n \n(\ndown_write_killable\n(\nmm\n-\nmmap_sem\n))\n\n                \nreturn\n \n-\nEINTR\n;\n\n\n        \nret\n \n=\n \ndo_brk\n(\ntsk\n,\n \nstart\n,\n \nlen\n);\n\n        \nup_write\n(\nmm\n-\nmmap_sem\n);\n\n\n        \n/* Prepopulate brk pages */\n\n        \nif\n \n(\n!\nret\n)\n\n                \nlego_mm_populate\n(\nmm\n,\n \nstart\n,\n \nlen\n);\n\n\n        \nreturn\n \nret\n;\n\n\n}\n\n\n\n\n\n\n\n\nUn-Populated stack\n\n\nStack vma is manually expanded to \n32 pages + pages for argv info\n by loader to accommodate future usage. Only pages for argv are populated by default, the extra 32 pages are not. A typical program may need 1 page for saving argv info, plus the 32 extra, the layout will be:\n\n1\n7ffffffde000-7ffffffff000 rw-p 00000000 [stack]\n\n\n\n\n\nThe code to expand stack is done when ELF loader tries to finalize the stack vma, by calling \nsetup_arg_pages()\n:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\nint\n \nsetup_arg_pages\n(\nstruct\n \nlego_task_struct\n \n*\ntsk\n,\n \nstruct\n \nlego_binprm\n \n*\nbprm\n,\n\n                    \nunsigned\n \nlong\n \nstack_top\n,\n \nint\n \nexecutable_stack\n)\n\n\n{\n\n        \n...\n\n        \n/*\n\n\n         * 32*4k (or 2*64k) pages\n\n\n         */\n\n        \nstack_expand\n \n=\n \n131072UL\n;\n\n        \nstack_size\n \n=\n \nvma\n-\nvm_end\n \n-\n \nvma\n-\nvm_start\n;\n\n        \nstack_base\n \n=\n \nvma\n-\nvm_start\n \n-\n \nstack_expand\n;\n\n\n        \nmm\n-\nstart_stack\n \n=\n \nbprm\n-\np\n;\n\n        \nret\n \n=\n \nexpand_stack\n(\nvma\n,\n \nstack_base\n);\n\n        \n...\n\n\n}\n\n\n\n\n\n\n\n\nUn-Populated \n.text\n and \n.data\n\n\nIn essence, all PT_LOAD segments of ELF image are not pre-populated. They will be fetched from storage on demand. This is the traditional on-demand paging way. If we want to reduce the overhead of code and data\ns on-demand paging, we can prefault them in the future.\n\n\n\n\nDisabled Dynamic-Linked Binary\n\n\nThe following code detects if an ELF executable is dynamic-linked. Besides, we changed several other places within ELF loader to disable the support for dynamic-linked binary.\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\nstatic\n \nint\n \nload_elf_binary\n(\nstruct\n \nlego_task_struct\n \n*\ntsk\n,\n \nstruct\n \nlego_binprm\n \n*\nbprm\n,\n\n                           \nu64\n \n*\nnew_ip\n,\n \nu64\n \n*\nnew_sp\n,\n \nunsigned\n \nlong\n \n*\nargv_len\n,\n \nunsigned\n \nlong\n \n*\nenvp_len\n)\n\n\n{\n\n        \n...\n\n        \nelf_ppnt\n \n=\n \nelf_phdata\n;\n\n        \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nloc\n-\nelf_ex\n.\ne_phnum\n;\n \ni\n++\n,\n \nelf_ppnt\n++\n)\n \n{\n\n                \nif\n \n(\nelf_ppnt\n-\np_type\n \n==\n \nPT_INTERP\n)\n \n{\n\n                        \n/*  \n\n\n                         * This is the program interpreter used for\n\n\n                         * dynamic linked elf - not supported for now\n\n\n                         */\n\n                        \nWARN\n(\n1\n,\n \nOnly static-linked elf is supported!\n\\n\n);\n\n                        \nretval\n \n=\n \n-\nENOEXEC\n;\n\n                        \ngoto\n \nout_free_ph\n;\n\n                \n}\n   \n        \n...\n\n\n}\n\n\n(\nmanagers\n/\nmemory\n/\nloader\n/\nelf\n.\nc\n)\n\n\n\n\n\n\n\n\nDisabled Randomized Top of Stack\n\n\nLego currently does not randomize the stack top. The stack vma is allocated by \nbprm_mm_init()\n at early execve time. There is no randomization at the allocation time, and this applies to all exectuable formats. The end of vma is just \nTASK_SIZE\n:\n\n1\n2\n3\n4\n5\n6\n7\nstatic\n \nint\n \n__bprm_mm_init\n(\nstruct\n \nlego_binprm\n \n*\nbprm\n)\n\n\n{\n\n        \n...\n\n        \nvma\n-\nvm_end\n \n=\n \nTASK_SIZE\n;\n\n        \n...\n\n\n}\n\n\n(\nmanagers\n/\nmemory\n/\nloader\n/\nelf\n.\nc\n)\n\n\n\n\n\n\nTop of stack randomization happens within each specific format loader. They do this by calling back to virtual loader layer\ns \nsetup_arg_pages()\n function, which is used to finalize the top of stack:\n\n1\n2\nint\n \nsetup_arg_pages\n(\nstruct\n \nlego_task_struct\n \n*\ntsk\n,\n \nstruct\n \nlego_binprm\n \n*\nbprm\n,\n\n                    \nunsigned\n \nlong\n \nstack_top\n,\n \nint\n \nexecutable_stack\n);\n\n\n\n\n\n\nSo, to actually randomize the top of stack, you can simply do the following:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\nstatic\n \nunsigned\n \nlong\n \nrandomize_stack_top\n(\nunsigned\n \nlong\n \nstack_top\n)\n\n\n{\n                                \n        \nunsigned\n \nlong\n \nrandom_variable\n \n=\n \n0\n;\n\n\n        \nif\n \n((\ncurrent\n-\nflags\n \n \nPF_RANDOMIZE\n)\n \n\n                \n!\n(\ncurrent\n-\npersonality\n \n \nADDR_NO_RANDOMIZE\n))\n \n{\n\n                \nrandom_variable\n \n=\n \nget_random_long\n();\n\n                \nrandom_variable\n \n=\n \nSTACK_RND_MASK\n;\n\n                \nrandom_variable\n \n=\n \nPAGE_SHIFT\n;\n\n        \n}\n\n\n#ifdef CONFIG_STACK_GROWSUP\n\n        \nreturn\n \nPAGE_ALIGN\n(\nstack_top\n)\n \n+\n \nrandom_variable\n;\n\n\n#else           \n\n        \nreturn\n \nPAGE_ALIGN\n(\nstack_top\n)\n \n-\n \nrandom_variable\n;\n\n\n#endif\n\n\n}\n\n\n\nstatic\n \nint\n \nload_elf_binary\n(\nstruct\n \nlego_task_struct\n \n*\ntsk\n,\n \nstruct\n \nlego_binprm\n \n*\nbprm\n,\n\n                           \nu64\n \n*\nnew_ip\n,\n \nu64\n \n*\nnew_sp\n,\n \nunsigned\n \nlong\n \n*\nargv_len\n,\n \nunsigned\n \nlong\n \n*\nenvp_len\n)\n\n\n{\n\n        \n...\n\n        \nretval\n \n=\n \nsetup_arg_pages\n(\nbprm\n,\n \nrandomize_stack_top\n(\nTASK_SIZE\n),\n\n                                 \nexecutable_stack\n);\n\n        \n...\n\n\n}\n\n\n\n\n\n\nHowever, current Lego disables randomization by passing \nTASK_SIZE\n:\n\n1\n2\n3\n4\n5\n6\n7\n8\nstatic\n \nint\n \nload_elf_binary\n(\nstruct\n \nlego_task_struct\n \n*\ntsk\n,\n \nstruct\n \nlego_binprm\n \n*\nbprm\n,\n\n                           \nu64\n \n*\nnew_ip\n,\n \nu64\n \n*\nnew_sp\n,\n \nunsigned\n \nlong\n \n*\nargv_len\n,\n \nunsigned\n \nlong\n \n*\nenvp_len\n)\n\n\n{\n\n        \n...\n\n        \nretval\n \n=\n \nsetup_arg_pages\n(\ntsk\n,\n \nbprm\n,\n \nTASK_SIZE\n,\n \nexecutable_stack\n);\n\n        \n...\n\n\n}\n\n\n(\nmanagers\n/\nmemory\n/\nloader\n/\nelf\n.\nc\n)\n\n\n\n\n\n\n\nYizhou Shan\n\nLast Updated: Feb 18, 2018", 
            "title": "Loader"
        }, 
        {
            "location": "/lego/kernel/loader/#lego-program-loader", 
            "text": "This document explains the high-level workflow of Lego s program loader, and how we change the normal loader to fit the disaggregated operating system model. Background on linking and loading is recommended.", 
            "title": "Lego Program Loader"
        }, 
        {
            "location": "/lego/kernel/loader/#status", 
            "text": "Formats  Supported      ELF (static-linked)     ELF (dynamic-linked)", 
            "title": "Status"
        }, 
        {
            "location": "/lego/kernel/loader/#overall", 
            "text": "In order to support different executable formats, Lego has a  virtual loader layer  above all specific formats, which is quite similar to  virtual file system . In Lego,  execve()  is divided into two parts:  1)  syscall hook at processor side,  2)  real loader at memory side. Combined together, they provide the same semantic of  execve()  as described in Linux man page. Also for the code, we divide the Linux implementation into parts. But our emulation model introduces several interesting workarounds, which we will talk later.  Therefore, before we dive into Lego s implementation, we first walk through Linux s code, describe the important steps, and then we will talk about how lego divide these functionalities to fit disaggregated operating system model.", 
            "title": "Overall"
        }, 
        {
            "location": "/lego/kernel/loader/#linuxs-loader", 
            "text": "This section describes the overall code flow of  execve()  within Linux. From the entry point to the return assembly part.", 
            "title": "Linux's Loader"
        }, 
        {
            "location": "/lego/kernel/loader/#entry-point", 
            "text": "So the normal entry point is  do_execve()  that will do all dirty work. Above that, it can be invoked by syscall from user space, or from kernel space by calling  do_execve()  directly. There are not too many places that will call  do_execve  within kernel. One notable case is how kernel starts the  pid 1  user program. This happens after kernel finished all initialization. The code is: 1\n2\n3\n4\n5 static   int   run_init_process ( const   char   * init_filename )                                                      { \n         argv_init [ 0 ]   =   init_filename ; \n         return   do_execve ( init_filename ,   argv_init ,   envp_init );  }", 
            "title": "Entry Point"
        }, 
        {
            "location": "/lego/kernel/loader/#main-routine", 
            "text": "Linux is good at making things complex, the execve main routine is no different. To accommodate different usages, the final dirty work is done by: 1\n2\n3\n4\n5\n6\n7 /*   * sys_execve() executes a new program.   */  static   int   do_execveat_common ( int   fd ,   struct   filename   * filename , \n                               struct   user_arg_ptr   argv , \n                               struct   user_arg_ptr   envp , \n                               int   flags );", 
            "title": "Main Routine"
        }, 
        {
            "location": "/lego/kernel/loader/#legos-loader", 
            "text": "", 
            "title": "Lego's Loader"
        }, 
        {
            "location": "/lego/kernel/loader/#features", 
            "text": "This section lists various features, or behaviors and Lego s program loader.", 
            "title": "Features"
        }, 
        {
            "location": "/lego/kernel/loader/#virtual-address-space-range", 
            "text": "User s virtual address falls into this range: 1 [sysctl_mmap_min_addr, TASK_SIZE)   By default,  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12 unsigned   long   sysctl_mmap_min_addr   =   PAGE_SIZE ;  /*   * User space process size. 47bits minus one guard page.  The guard   * page is necessary on Intel CPUs: if a SYSCALL instruction is at   * the highest possible canonical userspace address, then that   * syscall will enter the kernel with a non-canonical return   * address, and SYSRET will explode dangerously.  We avoid this   * particular problem by preventing anything from being mapped   * at the maximum canonical address.   */                                                                                                         #define TASK_SIZE       ((1UL   47) - PAGE_SIZE)    Essentially: 1 [0x1000, 0x7ffffffff000)", 
            "title": "Virtual Address Space Range"
        }, 
        {
            "location": "/lego/kernel/loader/#pre-populated-bss-and-brk", 
            "text": "The heap vma created at loading time is a combination of  .bss  and  .brk  segments. Since brk usage is 0 (will it be non-zero?) at this moment, so the heap vma is essentially just  .bss  pages. Normally, Linux kernel does not populate pages for this vma during loading, but Lego does. It can save several page allocation cost for heap pcache miss. It is controlled by  vm_brk() .  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18 int   vm_brk ( struct   lego_task_struct   * tsk , \n            unsigned   long   start ,   unsigned   long   len )  { \n         int   ret ; \n         struct   lego_mm_struct   * mm   =   tsk - mm ; \n\n         if   ( down_write_killable ( mm - mmap_sem )) \n                 return   - EINTR ; \n\n         ret   =   do_brk ( tsk ,   start ,   len ); \n         up_write ( mm - mmap_sem ); \n\n         /* Prepopulate brk pages */ \n         if   ( ! ret ) \n                 lego_mm_populate ( mm ,   start ,   len ); \n\n         return   ret ;  }", 
            "title": "Pre-Populated .bss and .brk"
        }, 
        {
            "location": "/lego/kernel/loader/#un-populated-stack", 
            "text": "Stack vma is manually expanded to  32 pages + pages for argv info  by loader to accommodate future usage. Only pages for argv are populated by default, the extra 32 pages are not. A typical program may need 1 page for saving argv info, plus the 32 extra, the layout will be: 1 7ffffffde000-7ffffffff000 rw-p 00000000 [stack]   The code to expand stack is done when ELF loader tries to finalize the stack vma, by calling  setup_arg_pages() :  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15 int   setup_arg_pages ( struct   lego_task_struct   * tsk ,   struct   lego_binprm   * bprm , \n                     unsigned   long   stack_top ,   int   executable_stack )  { \n         ... \n         /*           * 32*4k (or 2*64k) pages           */ \n         stack_expand   =   131072UL ; \n         stack_size   =   vma - vm_end   -   vma - vm_start ; \n         stack_base   =   vma - vm_start   -   stack_expand ; \n\n         mm - start_stack   =   bprm - p ; \n         ret   =   expand_stack ( vma ,   stack_base ); \n         ...  }", 
            "title": "Un-Populated stack"
        }, 
        {
            "location": "/lego/kernel/loader/#un-populated-text-and-data", 
            "text": "In essence, all PT_LOAD segments of ELF image are not pre-populated. They will be fetched from storage on demand. This is the traditional on-demand paging way. If we want to reduce the overhead of code and data s on-demand paging, we can prefault them in the future.", 
            "title": "Un-Populated .text and .data"
        }, 
        {
            "location": "/lego/kernel/loader/#disabled-dynamic-linked-binary", 
            "text": "The following code detects if an ELF executable is dynamic-linked. Besides, we changed several other places within ELF loader to disable the support for dynamic-linked binary.  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18 static   int   load_elf_binary ( struct   lego_task_struct   * tsk ,   struct   lego_binprm   * bprm , \n                            u64   * new_ip ,   u64   * new_sp ,   unsigned   long   * argv_len ,   unsigned   long   * envp_len )  { \n         ... \n         elf_ppnt   =   elf_phdata ; \n         for   ( i   =   0 ;   i     loc - elf_ex . e_phnum ;   i ++ ,   elf_ppnt ++ )   { \n                 if   ( elf_ppnt - p_type   ==   PT_INTERP )   { \n                         /*                             * This is the program interpreter used for                           * dynamic linked elf - not supported for now                           */ \n                         WARN ( 1 ,   Only static-linked elf is supported! \\n ); \n                         retval   =   - ENOEXEC ; \n                         goto   out_free_ph ; \n                 }    \n         ...  }  ( managers / memory / loader / elf . c )", 
            "title": "Disabled Dynamic-Linked Binary"
        }, 
        {
            "location": "/lego/kernel/loader/#disabled-randomized-top-of-stack", 
            "text": "Lego currently does not randomize the stack top. The stack vma is allocated by  bprm_mm_init()  at early execve time. There is no randomization at the allocation time, and this applies to all exectuable formats. The end of vma is just  TASK_SIZE : 1\n2\n3\n4\n5\n6\n7 static   int   __bprm_mm_init ( struct   lego_binprm   * bprm )  { \n         ... \n         vma - vm_end   =   TASK_SIZE ; \n         ...  }  ( managers / memory / loader / elf . c )    Top of stack randomization happens within each specific format loader. They do this by calling back to virtual loader layer s  setup_arg_pages()  function, which is used to finalize the top of stack: 1\n2 int   setup_arg_pages ( struct   lego_task_struct   * tsk ,   struct   lego_binprm   * bprm , \n                     unsigned   long   stack_top ,   int   executable_stack );    So, to actually randomize the top of stack, you can simply do the following:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25 static   unsigned   long   randomize_stack_top ( unsigned   long   stack_top )  {                                 \n         unsigned   long   random_variable   =   0 ; \n\n         if   (( current - flags     PF_RANDOMIZE )   \n                 ! ( current - personality     ADDR_NO_RANDOMIZE ))   { \n                 random_variable   =   get_random_long (); \n                 random_variable   =   STACK_RND_MASK ; \n                 random_variable   =   PAGE_SHIFT ; \n         }  #ifdef CONFIG_STACK_GROWSUP \n         return   PAGE_ALIGN ( stack_top )   +   random_variable ;  #else            \n         return   PAGE_ALIGN ( stack_top )   -   random_variable ;  #endif  }  static   int   load_elf_binary ( struct   lego_task_struct   * tsk ,   struct   lego_binprm   * bprm , \n                            u64   * new_ip ,   u64   * new_sp ,   unsigned   long   * argv_len ,   unsigned   long   * envp_len )  { \n         ... \n         retval   =   setup_arg_pages ( bprm ,   randomize_stack_top ( TASK_SIZE ), \n                                  executable_stack ); \n         ...  }    However, current Lego disables randomization by passing  TASK_SIZE : 1\n2\n3\n4\n5\n6\n7\n8 static   int   load_elf_binary ( struct   lego_task_struct   * tsk ,   struct   lego_binprm   * bprm , \n                            u64   * new_ip ,   u64   * new_sp ,   unsigned   long   * argv_len ,   unsigned   long   * envp_len )  { \n         ... \n         retval   =   setup_arg_pages ( tsk ,   bprm ,   TASK_SIZE ,   executable_stack ); \n         ...  }  ( managers / memory / loader / elf . c )    \nYizhou Shan \nLast Updated: Feb 18, 2018", 
            "title": "Disabled Randomized Top of Stack"
        }, 
        {
            "location": "/lego/kernel/vm/", 
            "text": "Process Virtual Memory\n\n\nLimits\n\n\nMax Number of VMAs\n\n\nBy default, the maximum number of VMAs is: \n65530\n. It is defined by the following variable:\n\n1\n2\n3\n4\n#define MAPCOUNT_ELF_CORE_MARGIN        (5)\n\n\n#define DEFAULT_MAX_MAP_COUNT   (USHRT_MAX - MAPCOUNT_ELF_CORE_MARGIN)\n\n\n\nint\n \nsysctl_max_map_count\n \n__read_mostly\n \n=\n \nDEFAULT_MAX_MAP_COUNT\n;\n\n\n\n\n\n\nFacts\n\n\nmunmap\n can split vma\n\n\nmunmap\n can create a hole with an existing vma, thus divide one existing vma to two new vmas. Do note that, \nmunmap\n can create hole for both anonymous vma \nand\n file-backed vma.\n\n\nmsync()\n is not atomic\n\n\nDuring \nmsync()\n, pages are being written back to disk one by one (or batched). Consider the case where few pages have been flushed back, while some other few pages are still in the memory. This premature writeback is not atomic and will be affected by failure.\u000b\u000b\n\n\nmsync()\n need concurrency control\n\n\nWith a multi-threaded application, does msync() provide the synchronization semantic? The answer is NO. Other threads within the same process are able to write to pages currently under \nmsync()\n. This implies that application need to handle concurrency by themselves, e.g., rwlocks.", 
            "title": "Process Virtual Memory"
        }, 
        {
            "location": "/lego/kernel/vm/#process-virtual-memory", 
            "text": "", 
            "title": "Process Virtual Memory"
        }, 
        {
            "location": "/lego/kernel/vm/#limits", 
            "text": "", 
            "title": "Limits"
        }, 
        {
            "location": "/lego/kernel/vm/#max-number-of-vmas", 
            "text": "By default, the maximum number of VMAs is:  65530 . It is defined by the following variable: 1\n2\n3\n4 #define MAPCOUNT_ELF_CORE_MARGIN        (5)  #define DEFAULT_MAX_MAP_COUNT   (USHRT_MAX - MAPCOUNT_ELF_CORE_MARGIN)  int   sysctl_max_map_count   __read_mostly   =   DEFAULT_MAX_MAP_COUNT ;", 
            "title": "Max Number of VMAs"
        }, 
        {
            "location": "/lego/kernel/vm/#facts", 
            "text": "", 
            "title": "Facts"
        }, 
        {
            "location": "/lego/kernel/vm/#munmap-can-split-vma", 
            "text": "munmap  can create a hole with an existing vma, thus divide one existing vma to two new vmas. Do note that,  munmap  can create hole for both anonymous vma  and  file-backed vma.", 
            "title": "munmap can split vma"
        }, 
        {
            "location": "/lego/kernel/vm/#msync-is-not-atomic", 
            "text": "During  msync() , pages are being written back to disk one by one (or batched). Consider the case where few pages have been flushed back, while some other few pages are still in the memory. This premature writeback is not atomic and will be affected by failure.", 
            "title": "msync() is not atomic"
        }, 
        {
            "location": "/lego/kernel/vm/#msync-need-concurrency-control", 
            "text": "With a multi-threaded application, does msync() provide the synchronization semantic? The answer is NO. Other threads within the same process are able to write to pages currently under  msync() . This implies that application need to handle concurrency by themselves, e.g., rwlocks.", 
            "title": "msync() need concurrency control"
        }, 
        {
            "location": "/lego/syscall/msync/", 
            "text": "msync()\n\n\nThe document is a summary I wrote after reading \nFailure-atomic msync()\n paper, which help me understand several questions related to \nmsync()\n.\n\n\n\n\n\n\nmsync() is not atomic.\n During msync(), pages are being written back to disk one by one (or batched): few pages have been flushed back, but few pages are still in the memory. This premature writeback is not atomic and will be affected by failure.\u000b\u000b\n\n\n\n\n\n\nmsync() need concurrency control\n. This actually is the issue I asked before. With a multi-threaded application, does msync() provide the synchronization semantic? The answer is no. Other threads within the same process are able to write to pages under msync(). This implies, application need to handle concurrency by themselves, e.g., rwlocks. \u000b\u000bAt the very beginning, I thought msync() provide this semantic. The only way to implement this should be: kernel make all pages\n PTE read-only, and then perform flush back. If any other threads does a write during flush, they will have a page fault. And in the pgfault function, we hold the threads until the pages are written back.\n\n\n\n\n\n\n\nYizhou Shan\n\nFeb 01, 2018", 
            "title": "msync()"
        }, 
        {
            "location": "/lego/syscall/msync/#msync", 
            "text": "The document is a summary I wrote after reading  Failure-atomic msync()  paper, which help me understand several questions related to  msync() .    msync() is not atomic.  During msync(), pages are being written back to disk one by one (or batched): few pages have been flushed back, but few pages are still in the memory. This premature writeback is not atomic and will be affected by failure.\u000b\u000b    msync() need concurrency control . This actually is the issue I asked before. With a multi-threaded application, does msync() provide the synchronization semantic? The answer is no. Other threads within the same process are able to write to pages under msync(). This implies, application need to handle concurrency by themselves, e.g., rwlocks. \u000b\u000bAt the very beginning, I thought msync() provide this semantic. The only way to implement this should be: kernel make all pages  PTE read-only, and then perform flush back. If any other threads does a write during flush, they will have a page fault. And in the pgfault function, we hold the threads until the pages are written back.    \nYizhou Shan \nFeb 01, 2018", 
            "title": "msync()"
        }, 
        {
            "location": "/lego/syscall/mremap/", 
            "text": "mremap()", 
            "title": "mremap()"
        }, 
        {
            "location": "/lego/syscall/mremap/#mremap", 
            "text": "", 
            "title": "mremap()"
        }, 
        {
            "location": "/lego/syscall/fork/", 
            "text": "fork()\n\n\nEntry Points\n\n\n\n\nfork()\n\n\nvfork()\n\n\nclone()\n\n\nkernel_thread()\n\n\n\n\nAll of them land on \ndo_fork()\n, which is Lego\ns main fork function.\n\n\ndo_fork()\n\n\nThere are mainly three parts within \ndo_fork()\n: \n1)\n \ncopy_process()\n, which duplicates a new task based on \ncurrent\n, including allocate new kernel stack, new task_struct, increase mm reference counter, etc. \n2)\n If we are creating a new process, then tell global monitor or memory manager to let them update bookkeeping and create corresponding data structures. \n3)\n \nwake_up_new_task()\n, which gives away the newly created task to local scheduler.\n\n\ncopy_process()\n\n\nThe routine is kind of boring. It do a lot dirty work to copy information from calling thread to new thread. The most important data structures of course are \ntask_struct\n, \nmm_sturct\n, \nsighand\n, and so on. This section only talks about few of them, and leave others to readers who are interested.\n\n\nSanity Checking\n\n\nMainly check if \nclone_flags\n are passed properly. For example, if user is creating a new thread, that implies certain data structures are shared, cause new thread belongs to the same process with the calling thread. If \nCLONE_THREAD\n is passed, then \nCLONE_SIGHAND\n, \nCLONE_VM\n, and so on must be set as well.\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n    \n/*\n\n\n     * Thread groups must share signals as well, and detached threads\n\n\n     * can only be started up within the thread group.\n\n\n     */\n\n    \nif\n \n((\nclone_flags\n \n \nCLONE_THREAD\n)\n \n \n!\n(\nclone_flags\n \n \nCLONE_SIGHAND\n))\n\n        \nreturn\n \nERR_PTR\n(\n-\nEINVAL\n);\n\n\n    \n/*\n\n\n     * Shared signal handlers imply shared VM. By way of the above,\n\n\n     * thread groups also imply shared VM. Blocking this case allows\n\n\n     * for various simplifications in other code.\n\n\n     */\n\n    \nif\n \n((\nclone_flags\n \n \nCLONE_SIGHAND\n)\n \n \n!\n(\nclone_flags\n \n \nCLONE_VM\n))\n\n        \nreturn\n \nERR_PTR\n(\n-\nEINVAL\n);\n\n\n\n\n\n\ndup_task_struct()\n\n\nTwo main things: 1) duplicate a new \ntask_struct\n, 2) duplicate a new kernel stack. x86 is just a weird architecture, the size of \ntask_struct\n depends on the size of fpu. So the allocation and duplication need to callback to x86-specific code to duplicate the task_struct and fpu info.\n\n1\n2\n3\n4\n5\n6\nint\n \narch_dup_task_struct\n(\nstruct\n \ntask_struct\n \n*\ndst\n,\n \nstruct\n \ntask_struct\n \n*\nsrc\n)\n\n\n{\n\n    \nmemcpy\n(\ndst\n,\n \nsrc\n,\n \narch_task_struct_size\n);\n\n\n    \nreturn\n \nfpu__copy\n(\ndst\n-\nthread\n.\nfpu\n,\n \nsrc\n-\nthread\n.\nfpu\n);\n\n\n}\n\n\n\n\n\nThe stack duplication is fairly simple, just copy everything from the old stack to new stack. Of course, it needs to setup the \nthread_info\n to points to this new thread, so the \ncurrent\n macro will work.\n\n1\n2\n3\n4\n5\n6\n7\n8\nstatic\n \nvoid\n \nsetup_thread_stack\n(\nstruct\n \ntask_struct\n \n*\np\n,\n \nstruct\n \ntask_struct\n \n*\norg\n)\n\n\n{\n\n        \n/* Duplicate whole stack! */\n\n        \n*\ntask_thread_info\n(\np\n)\n \n=\n \n*\ntask_thread_info\n(\norg\n);\n\n\n        \n/* Make the `current\n macro work */\n\n        \ntask_thread_info\n(\np\n)\n-\ntask\n \n=\n \np\n;\n\n\n}\n\n\n\n\n\n\ncopy_mm()\n\n\nThis is where threads within a process will share the virtual address space happens. If we are creating a new process, then this function will create a new \nmm_struct\n, and also a new \npgd\n:\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n/*\n\n\n * pgd_alloc() will duplicate the identity kernel mapping\n\n\n * but leaves other entries empty:\n\n\n */\n\n\nmm\n-\npgd\n \n=\n \npgd_alloc\n(\nmm\n);\n\n\nif\n \n(\nunlikely\n(\n!\nmm\n-\npgd\n))\n \n{\n\n        \nkfree\n(\nmm\n);\n\n        \nreturn\n \nNULL\n;\n\n\n}\n\n\n\n\n\n\nTODO: hook with pcache\nWe need to duplicate the pcache vm_range array, once Yutong finished the code.\nsetup_sched_fork()\n\n\nCallback to scheduler to setup this new task. It may reset all scheduler related information. Here we also have a chance to change this task\ns scheduler class:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\nint\n \nsetup_sched_fork\n(\nunsigned\n \nlong\n \nclone_flags\n,\n \nstruct\n \ntask_struct\n \n*\np\n)\n\n\n{\n\n        \nint\n \ncpu\n \n=\n \nget_cpu\n();\n\n\n        \n__sched_fork\n(\nclone_flags\n,\n \np\n);\n\n\n        \np\n-\nstate\n \n=\n \nTASK_NEW\n;\n\n        \n...\n\n        \nif\n \n(\nunlikely\n(\np\n-\nsched_reset_on_fork\n))\n \n{\n\n                \nif\n \n(\ntask_has_rt_policy\n(\np\n))\n \n{\n\n                        \np\n-\npolicy\n \n=\n \nSCHED_NORMAL\n;\n\n                        \np\n-\nstatic_prio\n \n=\n \nNICE_TO_PRIO\n(\n0\n);\n\n                        \np\n-\nrt_priority\n \n=\n \n0\n;\n\n                \n}\n \nelse\n \nif\n \n(\nPRIO_TO_NICE\n(\np\n-\nstatic_prio\n)\n \n \n0\n)\n\n                        \np\n-\nstatic_prio\n \n=\n \nNICE_TO_PRIO\n(\n0\n);\n\n\n                \np\n-\nprio\n \n=\n \np\n-\nnormal_prio\n \n=\n \n__normal_prio\n(\np\n);\n\n                \nset_load_weight\n(\np\n);\n\n                \n...\n\n        \n}\n    \n\n        \nif\n \n(\nrt_prio\n(\np\n-\nprio\n))\n\n                \np\n-\nsched_class\n \n=\n \nrt_sched_class\n;\n\n        \nelse\n \n{\n\n                \np\n-\nsched_class\n \n=\n \nfair_sched_class\n;\n\n                \nset_load_weight\n(\np\n);\n\n        \n}\n    \n\n        \n__set_task_cpu\n(\np\n,\n \ncpu\n);\n\n        \nif\n \n(\np\n-\nsched_class\n-\ntask_fork\n)\n\n                \np\n-\nsched_class\n-\ntask_fork\n(\np\n);\n\n\n        \n...\n\n\n}\n\n\n\n\n\n\n\nAllocate new pid\n\n\nIn both Lego and Linux, we don\nt allocate new pid for a new thread, if that thread is an \nidle thread\n. So callers of \ndo_fork\n needs to pass something to let \ndo_fork\n know. In Linux, they use \nstruct pid, init_struct_pid\n to check. In Lego, we introduce an new clone_flag \nCLONE_IDLE_THREAD\n. If that flag is set, \ndo_fork()\n will try to allocate a new pid for the new thread. Otherwise, it will be 0:\n\n1\n2\n3\n4\n5\n6\n/* clone idle thread, whose pid is 0 */\n\n\nif\n \n(\n!\n(\nclone_flags\n \n \nCLONE_IDLE_THREAD\n))\n \n{\n\n        \npid\n \n=\n \nalloc_pid\n(\np\n);\n\n        \nif\n \n(\n!\npid\n)\n\n                \ngoto\n \nout_cleanup_thread\n;\n\n\n}\n\n\n\n\n\n\nSo, only the \ninit_idle()\n function can pass this \nCLONE_IDLE_THREAD\n down. All other usages are wrong and should be reported.\n\n\nIn order to avoid conflict with Linux clone_flag, we define it as:\n\n1\n#define CLONE_IDLE_THREAD       0x100000000\n\n\n\n\n\n\nSETTID/CLEARTID\n\n\nThese are some futex related stuff. I will cover these stuff in futex document:\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\np\n-\nset_child_tid\n \n=\n \n(\nclone_flags\n \n \nCLONE_CHILD_SETTID\n)\n \n?\n \nchild_tidptr\n \n:\n \nNULL\n;\n\n\n/*  \n\n\n * Clear TID on mm_release()?\n\n\n */\n\n\np\n-\nclear_child_tid\n \n=\n \n(\nclone_flags\n \n \nCLONE_CHILD_CLEARTID\n)\n \n?\n \nchild_tidptr\n \n:\n \nNULL\n;\n\n\n\n#ifdef CONFIG_FUTEX\n\n\np\n-\nrobust_list\n \n=\n \nNULL\n;\n\n\n#endif\n\n\n\n\n\n\ncopy_thread_tls()\n\n\nThis is the most interesting function. Cover later.\n\n\np2m_fork()\n\n\nIn order to track user activities, we need to know when user are going to create new process. Fork is the best time and the only time we kernel know. So, Lego adds this special hook to tell remote global monitor or memory manager that there is a new process going to be created. Upon receiving this message, remote monitor will update its bookkeeping for this specific user/vNode.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n/* Tell remote memory component */\n\n\n#ifdef CONFIG_COMP_PROCESSOR\n\n\nif\n \n(\nclone_flags\n \n \nCLONE_GLOBAL_THREAD\n)\n \n{\n\n        \n...\n\n        \np2m_fork\n(\np\n,\n \nclone_flags\n);\n\n        \n...\n\n\n}\n   \n\n#endif\n\n\n\n\n\n\n\nThe \nCLONE_GLOBAL_THREAD\n should only be set, if the following cases happen:\n\n\n\n\nfork()\n\n\nvfork()\n\n\nclone(), without \nCLONE_THREAD\n being set\n\n\n\n\nIn order to avoid conflict with Linux clone_flag, we define it as:\n\n1\n#define CLONE_GLOBAL_THREAD     0x200000000\n\n\n\n\n\n\nwake_up_new_task()\n\n\nThe last step of \ndo_fork\n is waking up the new thread or process, which is performed by \nwake_up_new_task()\n function. The first question this function will ask is: \nwhich cpu to land?\n The answer comes from \nselect_task_rq()\n:\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\nstatic\n \ninline\n\n\nint\n \nselect_task_rq\n(\nstruct\n \ntask_struct\n \n*\np\n,\n \nint\n \ncpu\n,\n \nint\n \nsd_flags\n,\n \nint\n \nwake_flags\n)\n\n\n{\n\n        \nif\n \n(\np\n-\nnr_cpus_allowed\n \n \n1\n)\n\n                \ncpu\n \n=\n \np\n-\nsched_class\n-\nselect_task_rq\n(\np\n,\n \ncpu\n,\n \nsd_flags\n,\n \nwake_flags\n);\n\n        \nelse\n\n                \ncpu\n \n=\n \ncpumask_any\n(\np\n-\ncpus_allowed\n);\n\n        \n...\n\n\n}\n\n\n\n\n\n\n\nClearly, this is determined by \ncpus_allowed\n, which is the same with its parent at this point. That being said, if the parent is only able to run on one specific CPU, then all its children will end up running on the same CPU when they wake up (they could change their affinity later). This is also the default on Linux: \nA child created via fork(2) inherits its parent\ns CPU affinity mask. The affinity mask is preserved across an execve(2).\n\n\nAfter landing CPU is selected, following operation is simple: just enqueue this task into landing CPU\ns runqueue, and we are done:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\nvoid\n \nwake_up_new_task\n(\nstruct\n \ntask_struct\n \n*\np\n)\n\n\n{\n\n        \n...\n\n\n/* Select a CPU for new thread to run */\n\n\n#ifdef CONFIG_SMP\n\n        \n/*   \n\n\n         * Fork balancing, do it here and not earlier because:\n\n\n         *  - cpus_allowed can change in the fork path\n\n\n         *  - any previously selected cpu might disappear through hotplug\n\n\n         */\n\n        \nset_task_cpu\n(\np\n,\n \nselect_task_rq\n(\np\n,\n \ntask_cpu\n(\np\n),\n \nSD_BALANCE_FORK\n,\n \n0\n));\n\n\n#endif\n\n\n        \nrq\n \n=\n \n__task_rq_lock\n(\np\n);\n\n        \nactivate_task\n(\nrq\n,\n \np\n,\n \n0\n);\n\n        \np\n-\non_rq\n \n=\n \nTASK_ON_RQ_QUEUED\n;\n\n        \n...\n\n\n}\n\n\n\n\n\n\n\n\nYizhou Shan\n\nCreated: Feb 11, 2018\n\nLast Updated: Feb 19, 2018", 
            "title": "fork()"
        }, 
        {
            "location": "/lego/syscall/fork/#fork", 
            "text": "", 
            "title": "fork()"
        }, 
        {
            "location": "/lego/syscall/fork/#entry-points", 
            "text": "fork()  vfork()  clone()  kernel_thread()   All of them land on  do_fork() , which is Lego s main fork function.", 
            "title": "Entry Points"
        }, 
        {
            "location": "/lego/syscall/fork/#do_fork", 
            "text": "There are mainly three parts within  do_fork() :  1)   copy_process() , which duplicates a new task based on  current , including allocate new kernel stack, new task_struct, increase mm reference counter, etc.  2)  If we are creating a new process, then tell global monitor or memory manager to let them update bookkeeping and create corresponding data structures.  3)   wake_up_new_task() , which gives away the newly created task to local scheduler.", 
            "title": "do_fork()"
        }, 
        {
            "location": "/lego/syscall/fork/#copy_process", 
            "text": "The routine is kind of boring. It do a lot dirty work to copy information from calling thread to new thread. The most important data structures of course are  task_struct ,  mm_sturct ,  sighand , and so on. This section only talks about few of them, and leave others to readers who are interested.", 
            "title": "copy_process()"
        }, 
        {
            "location": "/lego/syscall/fork/#sanity-checking", 
            "text": "Mainly check if  clone_flags  are passed properly. For example, if user is creating a new thread, that implies certain data structures are shared, cause new thread belongs to the same process with the calling thread. If  CLONE_THREAD  is passed, then  CLONE_SIGHAND ,  CLONE_VM , and so on must be set as well.  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14      /*       * Thread groups must share signals as well, and detached threads       * can only be started up within the thread group.       */ \n     if   (( clone_flags     CLONE_THREAD )     ! ( clone_flags     CLONE_SIGHAND )) \n         return   ERR_PTR ( - EINVAL ); \n\n     /*       * Shared signal handlers imply shared VM. By way of the above,       * thread groups also imply shared VM. Blocking this case allows       * for various simplifications in other code.       */ \n     if   (( clone_flags     CLONE_SIGHAND )     ! ( clone_flags     CLONE_VM )) \n         return   ERR_PTR ( - EINVAL );", 
            "title": "Sanity Checking"
        }, 
        {
            "location": "/lego/syscall/fork/#dup_task_struct", 
            "text": "Two main things: 1) duplicate a new  task_struct , 2) duplicate a new kernel stack. x86 is just a weird architecture, the size of  task_struct  depends on the size of fpu. So the allocation and duplication need to callback to x86-specific code to duplicate the task_struct and fpu info. 1\n2\n3\n4\n5\n6 int   arch_dup_task_struct ( struct   task_struct   * dst ,   struct   task_struct   * src )  { \n     memcpy ( dst ,   src ,   arch_task_struct_size ); \n\n     return   fpu__copy ( dst - thread . fpu ,   src - thread . fpu );  }   \nThe stack duplication is fairly simple, just copy everything from the old stack to new stack. Of course, it needs to setup the  thread_info  to points to this new thread, so the  current  macro will work. 1\n2\n3\n4\n5\n6\n7\n8 static   void   setup_thread_stack ( struct   task_struct   * p ,   struct   task_struct   * org )  { \n         /* Duplicate whole stack! */ \n         * task_thread_info ( p )   =   * task_thread_info ( org ); \n\n         /* Make the `current  macro work */ \n         task_thread_info ( p ) - task   =   p ;  }", 
            "title": "dup_task_struct()"
        }, 
        {
            "location": "/lego/syscall/fork/#copy_mm", 
            "text": "This is where threads within a process will share the virtual address space happens. If we are creating a new process, then this function will create a new  mm_struct , and also a new  pgd : 1\n2\n3\n4\n5\n6\n7\n8\n9 /*   * pgd_alloc() will duplicate the identity kernel mapping   * but leaves other entries empty:   */  mm - pgd   =   pgd_alloc ( mm );  if   ( unlikely ( ! mm - pgd ))   { \n         kfree ( mm ); \n         return   NULL ;  }    TODO: hook with pcache We need to duplicate the pcache vm_range array, once Yutong finished the code.", 
            "title": "copy_mm()"
        }, 
        {
            "location": "/lego/syscall/fork/#setup_sched_fork", 
            "text": "Callback to scheduler to setup this new task. It may reset all scheduler related information. Here we also have a chance to change this task s scheduler class:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34 int   setup_sched_fork ( unsigned   long   clone_flags ,   struct   task_struct   * p )  { \n         int   cpu   =   get_cpu (); \n\n         __sched_fork ( clone_flags ,   p ); \n\n         p - state   =   TASK_NEW ; \n         ... \n         if   ( unlikely ( p - sched_reset_on_fork ))   { \n                 if   ( task_has_rt_policy ( p ))   { \n                         p - policy   =   SCHED_NORMAL ; \n                         p - static_prio   =   NICE_TO_PRIO ( 0 ); \n                         p - rt_priority   =   0 ; \n                 }   else   if   ( PRIO_TO_NICE ( p - static_prio )     0 ) \n                         p - static_prio   =   NICE_TO_PRIO ( 0 ); \n\n                 p - prio   =   p - normal_prio   =   __normal_prio ( p ); \n                 set_load_weight ( p ); \n                 ... \n         }     \n\n         if   ( rt_prio ( p - prio )) \n                 p - sched_class   =   rt_sched_class ; \n         else   { \n                 p - sched_class   =   fair_sched_class ; \n                 set_load_weight ( p ); \n         }     \n\n         __set_task_cpu ( p ,   cpu ); \n         if   ( p - sched_class - task_fork ) \n                 p - sched_class - task_fork ( p ); \n\n         ...  }", 
            "title": "setup_sched_fork()"
        }, 
        {
            "location": "/lego/syscall/fork/#allocate-new-pid", 
            "text": "In both Lego and Linux, we don t allocate new pid for a new thread, if that thread is an  idle thread . So callers of  do_fork  needs to pass something to let  do_fork  know. In Linux, they use  struct pid, init_struct_pid  to check. In Lego, we introduce an new clone_flag  CLONE_IDLE_THREAD . If that flag is set,  do_fork()  will try to allocate a new pid for the new thread. Otherwise, it will be 0: 1\n2\n3\n4\n5\n6 /* clone idle thread, whose pid is 0 */  if   ( ! ( clone_flags     CLONE_IDLE_THREAD ))   { \n         pid   =   alloc_pid ( p ); \n         if   ( ! pid ) \n                 goto   out_cleanup_thread ;  }    So, only the  init_idle()  function can pass this  CLONE_IDLE_THREAD  down. All other usages are wrong and should be reported.  In order to avoid conflict with Linux clone_flag, we define it as: 1 #define CLONE_IDLE_THREAD       0x100000000", 
            "title": "Allocate new pid"
        }, 
        {
            "location": "/lego/syscall/fork/#settidcleartid", 
            "text": "These are some futex related stuff. I will cover these stuff in futex document: 1\n2\n3\n4\n5\n6\n7\n8\n9 p - set_child_tid   =   ( clone_flags     CLONE_CHILD_SETTID )   ?   child_tidptr   :   NULL ;  /*     * Clear TID on mm_release()?   */  p - clear_child_tid   =   ( clone_flags     CLONE_CHILD_CLEARTID )   ?   child_tidptr   :   NULL ;  #ifdef CONFIG_FUTEX  p - robust_list   =   NULL ;  #endif", 
            "title": "SETTID/CLEARTID"
        }, 
        {
            "location": "/lego/syscall/fork/#copy_thread_tls", 
            "text": "This is the most interesting function. Cover later.", 
            "title": "copy_thread_tls()"
        }, 
        {
            "location": "/lego/syscall/fork/#p2m_fork", 
            "text": "In order to track user activities, we need to know when user are going to create new process. Fork is the best time and the only time we kernel know. So, Lego adds this special hook to tell remote global monitor or memory manager that there is a new process going to be created. Upon receiving this message, remote monitor will update its bookkeeping for this specific user/vNode.  1\n2\n3\n4\n5\n6\n7\n8 /* Tell remote memory component */  #ifdef CONFIG_COMP_PROCESSOR  if   ( clone_flags     CLONE_GLOBAL_THREAD )   { \n         ... \n         p2m_fork ( p ,   clone_flags ); \n         ...  }     #endif    The  CLONE_GLOBAL_THREAD  should only be set, if the following cases happen:   fork()  vfork()  clone(), without  CLONE_THREAD  being set   In order to avoid conflict with Linux clone_flag, we define it as: 1 #define CLONE_GLOBAL_THREAD     0x200000000", 
            "title": "p2m_fork()"
        }, 
        {
            "location": "/lego/syscall/fork/#wake_up_new_task", 
            "text": "The last step of  do_fork  is waking up the new thread or process, which is performed by  wake_up_new_task()  function. The first question this function will ask is:  which cpu to land?  The answer comes from  select_task_rq() :  1\n2\n3\n4\n5\n6\n7\n8\n9 static   inline  int   select_task_rq ( struct   task_struct   * p ,   int   cpu ,   int   sd_flags ,   int   wake_flags )  { \n         if   ( p - nr_cpus_allowed     1 ) \n                 cpu   =   p - sched_class - select_task_rq ( p ,   cpu ,   sd_flags ,   wake_flags ); \n         else \n                 cpu   =   cpumask_any ( p - cpus_allowed ); \n         ...  }    Clearly, this is determined by  cpus_allowed , which is the same with its parent at this point. That being said, if the parent is only able to run on one specific CPU, then all its children will end up running on the same CPU when they wake up (they could change their affinity later). This is also the default on Linux:  A child created via fork(2) inherits its parent s CPU affinity mask. The affinity mask is preserved across an execve(2).  After landing CPU is selected, following operation is simple: just enqueue this task into landing CPU s runqueue, and we are done:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18 void   wake_up_new_task ( struct   task_struct   * p )  { \n         ...  /* Select a CPU for new thread to run */  #ifdef CONFIG_SMP \n         /*              * Fork balancing, do it here and not earlier because:           *  - cpus_allowed can change in the fork path           *  - any previously selected cpu might disappear through hotplug           */ \n         set_task_cpu ( p ,   select_task_rq ( p ,   task_cpu ( p ),   SD_BALANCE_FORK ,   0 ));  #endif \n\n         rq   =   __task_rq_lock ( p ); \n         activate_task ( rq ,   p ,   0 ); \n         p - on_rq   =   TASK_ON_RQ_QUEUED ; \n         ...  }    \nYizhou Shan \nCreated: Feb 11, 2018 \nLast Updated: Feb 19, 2018", 
            "title": "wake_up_new_task()"
        }, 
        {
            "location": "/lego/pcache/config/", 
            "text": "Pcache Configuration\n\n\nLast Updated: 02/01/18\n\n\nThis doc explains what configuration options pcache has, and how to config them properly. Pcache is only enabled in Lego\ns processor manager and currently it uses DRAM to emulate the last-level cache (or, L4).\n\n\nKconfig\n\n\nCONFIG_MEMMAP_MEMBLOCK_RESERVED\n\n\nDEFAULT: Y\n\n\nBy default, boot command line option \nmemmap $\n will reserve a range of physical memory.\nThis reserved memory will be marked reserved in e820 table, which\nmeans this range will not be registered into \nmemblock\n. Only memory that has been\nregistered into \nmemblock\n will be assigned \nstruct page\n with it (both \nmemblock.memory\n and \nmemblock.reserve\n will have). And do note that this part of reserved memory can be mapped as 1GB page at boot time.\n\n\nIn other words, by default (the linux semantic), users need to \nioremap\n\nthe \nmemmap $\n reserved physical memory, and use the returned kernel virtual address afterwards.\nAnd do note that the \nioremap()\n only support 4KB mapping.\n\n\nIn Lego, if this option is enabled, the memory marked by \nmemmap $\n will \nNOT\n be marked\nreserved into e820 table, instead, it will be pushed into \nmemblock\n, which means\nit is mapped into kernel direct mapping and has \nstruct page\n.\n\n\nFor those who have done DAX, or NVM related stuff, you must have struggled with\n\nmemmap $\n, and complained why it does not have \nstruct page\n, I guess? So here is\nthe simple code to do so:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\nif\n \n(\n*\np\n \n==\n \n@\n)\n \n{\n\n        \nstart_at\n \n=\n \nmemparse\n(\np\n+\n1\n,\n \np\n);\n\n        \ne820_add_region\n(\nstart_at\n,\n \nmem_size\n,\n \nE820_RAM\n);\n\n\n}\n \nelse\n \nif\n \n(\n*\np\n \n==\n \n#\n)\n \n{\n\n        \nstart_at\n \n=\n \nmemparse\n(\np\n+\n1\n,\n \np\n);\n\n        \ne820_add_region\n(\nstart_at\n,\n \nmem_size\n,\n \nE820_ACPI\n);\n\n\n}\n \nelse\n \nif\n \n(\n*\np\n \n==\n \n$\n)\n \n{\n\n        \nstart_at\n \n=\n \nmemparse\n(\np\n+\n1\n,\n \np\n);\n\n\n\n#ifdef CONFIG_MEMMAP_MEMBLOCK_RESERVED\n\n        \nmemblock_reserve\n(\nstart_at\n,\n \nmem_size\n);\n\n\n#else\n\n        \ne820_add_region\n(\nstart_at\n,\n \nmem_size\n,\n \nE820_RESERVED\n);\n\n\n#endif\n\n\n\n\n\n\nBut why we are having this? Because I think the \ndirect 1GB mapping\n may have\nbetter performance: huge page mapping can truly save us a lot TLB misses. However, the real performance number is unknown.\n\n\nIf unsure, say \nY\n.", 
            "title": "Config"
        }, 
        {
            "location": "/lego/pcache/config/#pcache-configuration", 
            "text": "Last Updated: 02/01/18  This doc explains what configuration options pcache has, and how to config them properly. Pcache is only enabled in Lego s processor manager and currently it uses DRAM to emulate the last-level cache (or, L4).", 
            "title": "Pcache Configuration"
        }, 
        {
            "location": "/lego/pcache/config/#kconfig", 
            "text": "", 
            "title": "Kconfig"
        }, 
        {
            "location": "/lego/pcache/config/#config_memmap_memblock_reserved", 
            "text": "DEFAULT: Y  By default, boot command line option  memmap $  will reserve a range of physical memory.\nThis reserved memory will be marked reserved in e820 table, which\nmeans this range will not be registered into  memblock . Only memory that has been\nregistered into  memblock  will be assigned  struct page  with it (both  memblock.memory  and  memblock.reserve  will have). And do note that this part of reserved memory can be mapped as 1GB page at boot time.  In other words, by default (the linux semantic), users need to  ioremap \nthe  memmap $  reserved physical memory, and use the returned kernel virtual address afterwards.\nAnd do note that the  ioremap()  only support 4KB mapping.  In Lego, if this option is enabled, the memory marked by  memmap $  will  NOT  be marked\nreserved into e820 table, instead, it will be pushed into  memblock , which means\nit is mapped into kernel direct mapping and has  struct page .  For those who have done DAX, or NVM related stuff, you must have struggled with memmap $ , and complained why it does not have  struct page , I guess? So here is\nthe simple code to do so:  1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14 if   ( * p   ==   @ )   { \n         start_at   =   memparse ( p + 1 ,   p ); \n         e820_add_region ( start_at ,   mem_size ,   E820_RAM );  }   else   if   ( * p   ==   # )   { \n         start_at   =   memparse ( p + 1 ,   p ); \n         e820_add_region ( start_at ,   mem_size ,   E820_ACPI );  }   else   if   ( * p   ==   $ )   { \n         start_at   =   memparse ( p + 1 ,   p );  #ifdef CONFIG_MEMMAP_MEMBLOCK_RESERVED \n         memblock_reserve ( start_at ,   mem_size );  #else \n         e820_add_region ( start_at ,   mem_size ,   E820_RESERVED );  #endif    But why we are having this? Because I think the  direct 1GB mapping  may have\nbetter performance: huge page mapping can truly save us a lot TLB misses. However, the real performance number is unknown.  If unsure, say  Y .", 
            "title": "CONFIG_MEMMAP_MEMBLOCK_RESERVED"
        }, 
        {
            "location": "/lego/pcache/rmap/", 
            "text": "Reverse Mapping of Pcache\n\n\nThis document explains Lego\ns reverse mapping design for pcache. We also present Lego internal functions that eventually manipulate rmap data structures.\nFor readers who are not familiar with reverse mapping, I recommend you search \nwhat is rmap in Linux\n first.\n\n\nDesign\n\n\nThe reverse mapping, or rmap, of our pcache is implemented in a very basic and\nstraightforward way: pointing back to all page table entries (ptes) directly.\nShared pcache lines will have a list of ptes that point to this pcache line.\nWe also did this way in Hotpot.\n\n\nrmap is used by \n1)\n a bunch of syscalls, such as \nfork()\n, \nexecv()\n, \nmmap()\n,\n\nmunmap()\n, \nmremap()\n, \nbrk()\n. \n2)\n page reclaim, which needs to unmap all ptes for a\ngiven swapped page. Other than \nfork()\n and \nexecv()\n, other vm related syscalls\nare invoked very frequently for a typical datacenter application. Moreover, page\nreclaim and swap also run concurrently to gain exclusive access to rmap.\n\n\nSo, rmap operations have to be fast. Directly pointing to pte seems the best\nsolution here. However, this fine-granularity design will consume a lot memory\nfor the per-pte list.\nFurthermore, vma creation, deletion, split and merge happen frequently, the overhead\nto manage rmap is quite high. No wonder Linux choses another object-based way to do so,\nwhich leverages vma itself to take a longer path towards pte.\n\n\nThe important question is: \ndoes this naive solution fit \ncurrent\n Lego?\n\n\nYes, it fits, for several reasons. \n1)\n Current Lego run static-linked ELF binary only,\nthus there will not be any shared hot library pages, which implies rmap list maintenance\nis simplified. \n2)\n Our targeted applications\nmostly are single process. Even for multiple process ones, the number of processes\nstay stable and \nfork()\n happen at early init time. \n3)\n major users of rmap such\nas \nmremap()\n and \nmunmap()\n  perform rmap operation explicitly, \nmmap()\n perform\nrmap implicitly via pgfault (or pcache miss), \npcache reclaim\n perform sweep async.\nAll of them, combined with 1) and 2), most of the time will perform rmap operation\non a single pte.\n\n\nInternal\n\n\nThe following table describes different contexts that manipulate rmap data structures. Currently, rmap only has four possible operations. The context field describes the large context that trigger such rmap operation. The related functions and pcache callback field lists functions that actually did the dirty work.\n\n\n\n\n\n\n\n\nrmap operation\n\n\nContext\n\n\nRelated functions and pcache callback\n\n\n\n\n\n\n\n\n\n\nAdd\n\n\nfork()\n \npgfault\n\n\ncopy_pte_range()\n -\n \npcache_copy_pte()\n \n \npcache_add_rmap()\n\n\n\n\n\n\nRemove\n\n\nmunmap()\n \n \nexit_mmap()\n\n\nzap_pte_range()\n -\n \npcache_zap_pte()\n\n\n\n\n\n\nUpdate\n\n\nmremap()\n\n\nmove_ptes()\n -\n \npcache_move_pte()\n\n\n\n\n\n\nLookup\n\n\npcache eviction sweep, etc.\n\n\npcache_referenced()\n, \npcache_wrprotect()\n \n \npcache_try_to_unmap()\n\n\n\n\n\n\n\n\nThought\n\n\nOne function I personally love the most is \nrmap_walk()\n, whose name pretty much tells the story. To use \nrmap_walk()\n, caller passes a \nstruct rmap_walk_control\n, which including caller specific callback for each rmap. This function also isolates the specific data structures used by rmap from various callers. In Lego, a lot pcache functions are built upon \nrmap_walk()\n.\n\n\nstruct rmap_walk_control\n, or \nstruct scan_control\n, or \nstruct something_control\n are used a lot by Linux kernel. Personally I do love this way of doing data structure walk, or reuse functions. However, even this way can greatly reduce duplicated code size, it will make the code unnecessary complex. As a system developer, no more expects to see a function longer than 100 lines. People love saying: \nDo one thing and do it better\n, while it not always works that perfectly. Coding is nothing different life, it is all about trade-off.\n\n\n\nYizhou Shan\n\nFeb 02, 2018", 
            "title": "Reverse Mapping"
        }, 
        {
            "location": "/lego/pcache/rmap/#reverse-mapping-of-pcache", 
            "text": "This document explains Lego s reverse mapping design for pcache. We also present Lego internal functions that eventually manipulate rmap data structures.\nFor readers who are not familiar with reverse mapping, I recommend you search  what is rmap in Linux  first.", 
            "title": "Reverse Mapping of Pcache"
        }, 
        {
            "location": "/lego/pcache/rmap/#design", 
            "text": "The reverse mapping, or rmap, of our pcache is implemented in a very basic and\nstraightforward way: pointing back to all page table entries (ptes) directly.\nShared pcache lines will have a list of ptes that point to this pcache line.\nWe also did this way in Hotpot.  rmap is used by  1)  a bunch of syscalls, such as  fork() ,  execv() ,  mmap() , munmap() ,  mremap() ,  brk() .  2)  page reclaim, which needs to unmap all ptes for a\ngiven swapped page. Other than  fork()  and  execv() , other vm related syscalls\nare invoked very frequently for a typical datacenter application. Moreover, page\nreclaim and swap also run concurrently to gain exclusive access to rmap.  So, rmap operations have to be fast. Directly pointing to pte seems the best\nsolution here. However, this fine-granularity design will consume a lot memory\nfor the per-pte list.\nFurthermore, vma creation, deletion, split and merge happen frequently, the overhead\nto manage rmap is quite high. No wonder Linux choses another object-based way to do so,\nwhich leverages vma itself to take a longer path towards pte.  The important question is:  does this naive solution fit  current  Lego?  Yes, it fits, for several reasons.  1)  Current Lego run static-linked ELF binary only,\nthus there will not be any shared hot library pages, which implies rmap list maintenance\nis simplified.  2)  Our targeted applications\nmostly are single process. Even for multiple process ones, the number of processes\nstay stable and  fork()  happen at early init time.  3)  major users of rmap such\nas  mremap()  and  munmap()   perform rmap operation explicitly,  mmap()  perform\nrmap implicitly via pgfault (or pcache miss),  pcache reclaim  perform sweep async.\nAll of them, combined with 1) and 2), most of the time will perform rmap operation\non a single pte.", 
            "title": "Design"
        }, 
        {
            "location": "/lego/pcache/rmap/#internal", 
            "text": "The following table describes different contexts that manipulate rmap data structures. Currently, rmap only has four possible operations. The context field describes the large context that trigger such rmap operation. The related functions and pcache callback field lists functions that actually did the dirty work.     rmap operation  Context  Related functions and pcache callback      Add  fork()   pgfault  copy_pte_range()  -   pcache_copy_pte()     pcache_add_rmap()    Remove  munmap()     exit_mmap()  zap_pte_range()  -   pcache_zap_pte()    Update  mremap()  move_ptes()  -   pcache_move_pte()    Lookup  pcache eviction sweep, etc.  pcache_referenced() ,  pcache_wrprotect()     pcache_try_to_unmap()", 
            "title": "Internal"
        }, 
        {
            "location": "/lego/pcache/rmap/#thought", 
            "text": "One function I personally love the most is  rmap_walk() , whose name pretty much tells the story. To use  rmap_walk() , caller passes a  struct rmap_walk_control , which including caller specific callback for each rmap. This function also isolates the specific data structures used by rmap from various callers. In Lego, a lot pcache functions are built upon  rmap_walk() .  struct rmap_walk_control , or  struct scan_control , or  struct something_control  are used a lot by Linux kernel. Personally I do love this way of doing data structure walk, or reuse functions. However, even this way can greatly reduce duplicated code size, it will make the code unnecessary complex. As a system developer, no more expects to see a function longer than 100 lines. People love saying:  Do one thing and do it better , while it not always works that perfectly. Coding is nothing different life, it is all about trade-off.  \nYizhou Shan \nFeb 02, 2018", 
            "title": "Thought"
        }, 
        {
            "location": "/lego/pcache/smp_design/", 
            "text": "SMP Design Thought\n\n\nCoding pcache is nothing different from coding mm code. It is the same with your familiar mixed pgfault, LRU, page cache and writeback code. Each pcache line can be involved with multiple activities at the same time. We have to use different states to synchronize among them. If you have ever read linux mm code, you will know that sometimes, comment is literally more than code. SMP pain in ass.\n\n\nI don\nt think this document is well written. It is just some random thoughts I wrote down while coding. Some of them might be wrong. But it is still worth looking back.\n\n\nPcache and Victim Cache Organization\n\n\nOur pcache and victim cache are allocated and arranged as a big array. As for\npcache we look at it in a \ncache set view\n, which means consecutive pcache lines\nare not relevant in natual. As for victim cache, we simply treat it as a big array\nand walk through it one by one.\n\n\nAllocation/Eviction SMP Consideration\n\n\nThe alloc/free of both pcache and victim cache are simple: each pcache line or\nvictim cache line has a \nAllocated\n bit to indicate if this line is free or not.\nThe \nAllocated\n bit is manipulated by atomic bit operations, thus SMP safe. This\nfurther implies that we do not need another spinlock to guard allocation.\n\n\nHowever, other activities such as explict eviction, background sweep may walk\nthrough the cache lines at the same time of cache allocation, a single \nAllocated\n\nbit is not enough. Because an allocated cache line will need some initial setup,\nsuch as reset refcount, clear flags (prep_new_pcache),\nthus there is a small time gap between Allocated bit being set and the cache line\nbeing truly safe to use. Other activities must wait the cache line to be usable,\nand then they can do further operations on this cache line.\n\n\nTo solve this race condition, there two possible solutions:\n1) Add another bit: \nUsable\n, which is set once initial setup is done.\n   In this case, functions excluding alloction code should always check if the \nUsable\n\n   bit is set or not. a) If it is set, this means the cache line is safe for further operations\n   b) If not, and \nAllocated\n bit is set, this means the cache line is under setup in another core,\n   We should skip it.\n   c) If not, and \nAllocated\n bit is not set, this means this cache line is simply free.\n   We should skip it.\n\n\n2) Add allocated cache lines to a list (such as LRU list), and functions excluding allocation\n   code will only look into cache lines within this list. In other words, others will only\n   look into surely usable cache lines.\n\n\nBoth solutions try to avoid others looking into \nun-mature\n cache lines in SMP envorinment.\nThe rule is simple: function should \nNOT\n look into data that is not supposed to be seen.\nThe cache line that has Allocated bit set but under setup is a typical case.\n\n\nAs an example, the physical page allocator, page reclaim, page cache in Linux are implemented with\nthe second solution. Pages freshly allocated will be added a LRU list or page cache own list.\nAnd page reclaim code will only look into pages within the LRU list, it will not go through all\nphysical pages to do so. The reason for Linux to do so is simple: kernel can not scan the whole\nphysical pages to find out pages to operate.\n\n\nPcache:\n When it comes to pcache, we use both.\nIn our envision, pcache will have high-associativity such as 64 or 128.\nIt will have very bad performance if our eviction algorithm or sweep thread need to go through every\ncache lines within a set to find out candidates, while there might be only 1 or 2 allocated lines.\nHowever, additional \nUsable\n bit is added for debug purpose.\n\n\nVictim Cache:\n When it comes to victim cache, the first solution seems a better choice.\nBecause victim cache only a few cache lines, e.g., 8 or 16. This means a whole victim cache line\nwalk is fast. While the list deletion and addition seem may introduce some unnecessary overhead.\nIt is all about trade-off.\n\n\nThese choices affect the usage of pcache and victim cache, mostly the eviction code.\n\n\nMore on above two solutions\n\n\nThe first solution is used if evict_random is configured. The second solution is used when\nevict_lru is configured.\n\n\nI do not have any doubt about second solution, it works, though with a lot SMP pain in ass.\nBut I do have more to say about the first solution, which is adding another usable bit.\nThe \nUsable\n bit \nonly\n ensures other threads will not use unmature pcache, but it can not\nprevent other threads seeing a going-to-be-freed pcache.\n\n\nWhat is this going-to-be-freed asshole? Let us consider this case: CPU0 is doing eviction\nand checked the \nUsable\n bit, which is set. Then CPU0 thought this cache line is all set,\nready to be torqued. Before doing all the dirty work, CPU0 will \nget_pcache_unless_zero()\n\nfirst to make sure the pcache will not go away in the middle. However, meanwhile, CPU1 did\na \nput_pcache()\n \nand\n a consecutive \npcache_alloc()\n right before CPU0 did called\n\nget_pcache_unless_zero()\n. Bang! CPU0 may use an mature pcache line, cause CPU1\ns \npcache_init_ref_count()\n\nmay come before CPU1\ns \nget_pcache_unless_zero()\n! How to solve this? CPU0 need to add\nadditional checking after \nget_pcache_unless_zero()\n.\n\n\nFor more details, please check the code in \npcache/evcit_random.c\n, which has more pretty explanation.\n\n\n\nYizhou Shan\n\nJan 31, 2018", 
            "title": "SMP Design"
        }, 
        {
            "location": "/lego/pcache/smp_design/#smp-design-thought", 
            "text": "Coding pcache is nothing different from coding mm code. It is the same with your familiar mixed pgfault, LRU, page cache and writeback code. Each pcache line can be involved with multiple activities at the same time. We have to use different states to synchronize among them. If you have ever read linux mm code, you will know that sometimes, comment is literally more than code. SMP pain in ass.  I don t think this document is well written. It is just some random thoughts I wrote down while coding. Some of them might be wrong. But it is still worth looking back.", 
            "title": "SMP Design Thought"
        }, 
        {
            "location": "/lego/pcache/smp_design/#pcache-and-victim-cache-organization", 
            "text": "Our pcache and victim cache are allocated and arranged as a big array. As for\npcache we look at it in a  cache set view , which means consecutive pcache lines\nare not relevant in natual. As for victim cache, we simply treat it as a big array\nand walk through it one by one.", 
            "title": "Pcache and Victim Cache Organization"
        }, 
        {
            "location": "/lego/pcache/smp_design/#allocationeviction-smp-consideration", 
            "text": "The alloc/free of both pcache and victim cache are simple: each pcache line or\nvictim cache line has a  Allocated  bit to indicate if this line is free or not.\nThe  Allocated  bit is manipulated by atomic bit operations, thus SMP safe. This\nfurther implies that we do not need another spinlock to guard allocation.  However, other activities such as explict eviction, background sweep may walk\nthrough the cache lines at the same time of cache allocation, a single  Allocated \nbit is not enough. Because an allocated cache line will need some initial setup,\nsuch as reset refcount, clear flags (prep_new_pcache),\nthus there is a small time gap between Allocated bit being set and the cache line\nbeing truly safe to use. Other activities must wait the cache line to be usable,\nand then they can do further operations on this cache line.  To solve this race condition, there two possible solutions:\n1) Add another bit:  Usable , which is set once initial setup is done.\n   In this case, functions excluding alloction code should always check if the  Usable \n   bit is set or not. a) If it is set, this means the cache line is safe for further operations\n   b) If not, and  Allocated  bit is set, this means the cache line is under setup in another core,\n   We should skip it.\n   c) If not, and  Allocated  bit is not set, this means this cache line is simply free.\n   We should skip it.  2) Add allocated cache lines to a list (such as LRU list), and functions excluding allocation\n   code will only look into cache lines within this list. In other words, others will only\n   look into surely usable cache lines.  Both solutions try to avoid others looking into  un-mature  cache lines in SMP envorinment.\nThe rule is simple: function should  NOT  look into data that is not supposed to be seen.\nThe cache line that has Allocated bit set but under setup is a typical case.  As an example, the physical page allocator, page reclaim, page cache in Linux are implemented with\nthe second solution. Pages freshly allocated will be added a LRU list or page cache own list.\nAnd page reclaim code will only look into pages within the LRU list, it will not go through all\nphysical pages to do so. The reason for Linux to do so is simple: kernel can not scan the whole\nphysical pages to find out pages to operate.  Pcache:  When it comes to pcache, we use both.\nIn our envision, pcache will have high-associativity such as 64 or 128.\nIt will have very bad performance if our eviction algorithm or sweep thread need to go through every\ncache lines within a set to find out candidates, while there might be only 1 or 2 allocated lines.\nHowever, additional  Usable  bit is added for debug purpose.  Victim Cache:  When it comes to victim cache, the first solution seems a better choice.\nBecause victim cache only a few cache lines, e.g., 8 or 16. This means a whole victim cache line\nwalk is fast. While the list deletion and addition seem may introduce some unnecessary overhead.\nIt is all about trade-off.  These choices affect the usage of pcache and victim cache, mostly the eviction code.", 
            "title": "Allocation/Eviction SMP Consideration"
        }, 
        {
            "location": "/lego/pcache/smp_design/#more-on-above-two-solutions", 
            "text": "The first solution is used if evict_random is configured. The second solution is used when\nevict_lru is configured.  I do not have any doubt about second solution, it works, though with a lot SMP pain in ass.\nBut I do have more to say about the first solution, which is adding another usable bit.\nThe  Usable  bit  only  ensures other threads will not use unmature pcache, but it can not\nprevent other threads seeing a going-to-be-freed pcache.  What is this going-to-be-freed asshole? Let us consider this case: CPU0 is doing eviction\nand checked the  Usable  bit, which is set. Then CPU0 thought this cache line is all set,\nready to be torqued. Before doing all the dirty work, CPU0 will  get_pcache_unless_zero() \nfirst to make sure the pcache will not go away in the middle. However, meanwhile, CPU1 did\na  put_pcache()   and  a consecutive  pcache_alloc()  right before CPU0 did called get_pcache_unless_zero() . Bang! CPU0 may use an mature pcache line, cause CPU1 s  pcache_init_ref_count() \nmay come before CPU1 s  get_pcache_unless_zero() ! How to solve this? CPU0 need to add\nadditional checking after  get_pcache_unless_zero() .  For more details, please check the code in  pcache/evcit_random.c , which has more pretty explanation.  \nYizhou Shan \nJan 31, 2018", 
            "title": "More on above two solutions"
        }, 
        {
            "location": "/lego/paper/nmp/", 
            "text": "Near Memory Processing\n\n\n\n\nNMP: Near Memory Processing\n\n\n\n\nNDC: Near Data Computing\n\n\n\n\n\n\nPRIME\n:\n \nA\n \nNovel\n \nProcessing\n-\nin\n-\nmemory\n \nArchitecture\n \nfor\n \nNeural\n \nNetwork\nComputation\n \nin\n \nReRAM\n-\nbased\n \nMain\n \nMemory\n,\n \nISCA\n16\n\n\n\n\nHigh-performance\nacceleration of NN requires high memory bandwidth since\nthe \nPUs are hungry for fetching the synaptic weights [17]\n. To\naddress this challenge, recent special-purpose chip designs\nhave adopted large on-chip memory to store the synaptic\nweights. For example, DaDianNao [18] employed a large\non-chip eDRAM for both high bandwidth and data locality;\nTrueNorth utilized an SRAM crossbar memory for synapses\nin each core [19].\n\n\n\n\n\n\nDianNao\n and \nDaDianNao\n\n\n \nmemory bandwidth requirements\n of two important\nlayer types: convolutional layers with private kernels\n(used in DNNs) and classifier layers used in both CNNs and\nDNNs. For these types of layers, the total number of required\nsynapses can be massive, in the millions of parameters, or\neven tens or hundreds thereof.\n\n\nproviding sufficient eDRAM capacity to hold\nall \nsynapse\n on the combined eDRAM of all chips will\nsave on \noff-chip DRAM accesses\n, which are particularly\ncostly energy-wise\n\n\nSynapses\n. In a perceptron layer, all synapses are usually\nunique, and thus there is no reuse within the layer. On the\nother hand, the synapses are reused across network invocations,\ni.e., for each new input data (also called \u201cinput row\u201d)\npresented to the neural network. So a sufficiently large L2\ncould store all network synapses and take advantage of that\nlocality. For DNNs with private kernels, this is not possible\nas the total number of synapses are in the tens or hundreds\nof millions (the largest network to date has a billion\nsynapses [26]). However, for both CNNs and DNNs with\nshared kernels, the total number of synapses range in the\nmillions, which is within the reach of an L2 cache. In Figure\n6, see CLASS1 - Tiled+L2, we emulate the case where reuse\nacross network invocations is possible by considering only\nthe perceptron layer; as a result, the total bandwidth requirements\nare now drastically reduced.\n\n\nSo, ML workloads do need large memory bandwidth, and need a lot memory. But how about \ntemporary working set size\n? It\ns the best if it has a reasonable working set size that can fit the cache.\n\n\n\n\n\n\nTPU\n\n\nEach model needs between 5M and 100M weights (9\nth\n\ncolumn of Table 1), which can take a lot of time and energy to\naccess. To amortize the access costs, \nthe same weights are reused\nacross a batch of independent examples during inference or\ntraining\n, which improves performance.\n\n\nThe weights for the matrix unit are staged through an onchip\n\nWeight FIFO\n that reads from an \noff-chip 8 GiB DRAM\ncalled Weight Memory\n (for inference, weights are read-only; 8\nGiB supports many simultaneously active models). The weight\nFIFO is four tiles deep. The intermediate results are held in the \n24\nMiB on-chip Unified Buffer\n, which can serve as inputs to the Matrix Unit.\n\n\nIn virtual cache model, we actually can assign those weights to some designated sets, thus avoid conflicting with other data, which means we can sustain those weights in cache!\n\n\n\n\n\n\n\n\nTo conclude:\n\n\na)\n ML needs to use weight/synapses during computation, and those data will be reused repeatly across different stages. Besides, output from last stage serves the input of next stage, so buffering the \nintermediate data\n is important. Most ML accelerators use some kind of \non-chip memory\n (\nWeighted FIFO, Unified Cache in TPU\n) to buffer those data. This fits the \nHBM+Disaggregated Memory\n model: HBM is the on-chip memory, while disaggregated memory is the off-chip memory. \nb)\n Combined with virtual cache, we could assign special virtual addresses to weight data, so they stay in some designated cache sets. Kernel can avoid allocating conflict virtual addresses later. Thus we can retain these weight data in virtual cache easily.", 
            "title": "NMP"
        }, 
        {
            "location": "/lego/paper/nmp/#near-memory-processing", 
            "text": "NMP: Near Memory Processing   NDC: Near Data Computing    PRIME :   A   Novel   Processing - in - memory   Architecture   for   Neural   Network Computation   in   ReRAM - based   Main   Memory ,   ISCA 16   High-performance\nacceleration of NN requires high memory bandwidth since\nthe  PUs are hungry for fetching the synaptic weights [17] . To\naddress this challenge, recent special-purpose chip designs\nhave adopted large on-chip memory to store the synaptic\nweights. For example, DaDianNao [18] employed a large\non-chip eDRAM for both high bandwidth and data locality;\nTrueNorth utilized an SRAM crossbar memory for synapses\nin each core [19].    DianNao  and  DaDianNao    memory bandwidth requirements  of two important\nlayer types: convolutional layers with private kernels\n(used in DNNs) and classifier layers used in both CNNs and\nDNNs. For these types of layers, the total number of required\nsynapses can be massive, in the millions of parameters, or\neven tens or hundreds thereof.  providing sufficient eDRAM capacity to hold\nall  synapse  on the combined eDRAM of all chips will\nsave on  off-chip DRAM accesses , which are particularly\ncostly energy-wise  Synapses . In a perceptron layer, all synapses are usually\nunique, and thus there is no reuse within the layer. On the\nother hand, the synapses are reused across network invocations,\ni.e., for each new input data (also called \u201cinput row\u201d)\npresented to the neural network. So a sufficiently large L2\ncould store all network synapses and take advantage of that\nlocality. For DNNs with private kernels, this is not possible\nas the total number of synapses are in the tens or hundreds\nof millions (the largest network to date has a billion\nsynapses [26]). However, for both CNNs and DNNs with\nshared kernels, the total number of synapses range in the\nmillions, which is within the reach of an L2 cache. In Figure\n6, see CLASS1 - Tiled+L2, we emulate the case where reuse\nacross network invocations is possible by considering only\nthe perceptron layer; as a result, the total bandwidth requirements\nare now drastically reduced.  So, ML workloads do need large memory bandwidth, and need a lot memory. But how about  temporary working set size ? It s the best if it has a reasonable working set size that can fit the cache.    TPU  Each model needs between 5M and 100M weights (9 th \ncolumn of Table 1), which can take a lot of time and energy to\naccess. To amortize the access costs,  the same weights are reused\nacross a batch of independent examples during inference or\ntraining , which improves performance.  The weights for the matrix unit are staged through an onchip Weight FIFO  that reads from an  off-chip 8 GiB DRAM\ncalled Weight Memory  (for inference, weights are read-only; 8\nGiB supports many simultaneously active models). The weight\nFIFO is four tiles deep. The intermediate results are held in the  24\nMiB on-chip Unified Buffer , which can serve as inputs to the Matrix Unit.  In virtual cache model, we actually can assign those weights to some designated sets, thus avoid conflicting with other data, which means we can sustain those weights in cache!     To conclude:  a)  ML needs to use weight/synapses during computation, and those data will be reused repeatly across different stages. Besides, output from last stage serves the input of next stage, so buffering the  intermediate data  is important. Most ML accelerators use some kind of  on-chip memory  ( Weighted FIFO, Unified Cache in TPU ) to buffer those data. This fits the  HBM+Disaggregated Memory  model: HBM is the on-chip memory, while disaggregated memory is the off-chip memory.  b)  Combined with virtual cache, we could assign special virtual addresses to weight data, so they stay in some designated cache sets. Kernel can avoid allocating conflict virtual addresses later. Thus we can retain these weight data in virtual cache easily.", 
            "title": "Near Memory Processing"
        }, 
        {
            "location": "/lego/paper/processor_oom/", 
            "text": "Process/Memory Kernel Memory\n\n\nThis document is based on discussion with Yiying, about how to deal with processor or memory component\ns out-of-kernel-memory situation. It mainly bothers processor component, which has a small kernel memory while needs to support all running user threads.\n\n\nProcess\ns local kernel memory is limited by design. There are several major users:\n\n\n\n\n1) pcache\ns rmap, which is propotional to pcache size.\n\n\n2) IB, which depends on concurrent outgoing messages.\n\n\n3) running threads. For each thread at processor, Lego needs to allocate some kernel memory for it, e.g, \nkernel stack\n, \ntask_strcut\n, and so on.\n\n\n\n\nBoth 1) and 2) are fine, they can be easily controlled. However we can not limit how many threads user can create, thus 3) becomes the critical criminal of oom.\n\n\nWhen processor is running out of kernel memory, Lego needs to deal with it. Currently, we propose three different solutions:\n\n\n\n\ns1) \nSwap\n kernel memory to remote memory component\n\n\ns2) \nKill\n some threads to have some usable memory (OOM killer)\n\n\ns3) \nMigrate\n, or \ncheckpoint\n, threads to processors that have usable kernel memory\n\n\n\n\nFor solution 3), there is a case where \nall\n processors are running out of memory. Then we have to use solution 1) or 2).\n\n\n\nYizhou Shan\n\nFeb 17, 2018", 
            "title": "processor_oom"
        }, 
        {
            "location": "/lego/paper/processor_oom/#processmemory-kernel-memory", 
            "text": "This document is based on discussion with Yiying, about how to deal with processor or memory component s out-of-kernel-memory situation. It mainly bothers processor component, which has a small kernel memory while needs to support all running user threads.  Process s local kernel memory is limited by design. There are several major users:   1) pcache s rmap, which is propotional to pcache size.  2) IB, which depends on concurrent outgoing messages.  3) running threads. For each thread at processor, Lego needs to allocate some kernel memory for it, e.g,  kernel stack ,  task_strcut , and so on.   Both 1) and 2) are fine, they can be easily controlled. However we can not limit how many threads user can create, thus 3) becomes the critical criminal of oom.  When processor is running out of kernel memory, Lego needs to deal with it. Currently, we propose three different solutions:   s1)  Swap  kernel memory to remote memory component  s2)  Kill  some threads to have some usable memory (OOM killer)  s3)  Migrate , or  checkpoint , threads to processors that have usable kernel memory   For solution 3), there is a case where  all  processors are running out of memory. Then we have to use solution 1) or 2).  \nYizhou Shan \nFeb 17, 2018", 
            "title": "Process/Memory Kernel Memory"
        }
    ]
}