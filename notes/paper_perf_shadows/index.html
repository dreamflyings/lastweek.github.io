<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="Yizhou Shan">
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Performance-Shadows - Yizhou Shan's Home Page</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>
  <link href='https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../../css/highlight.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Performance-Shadows";
    var mkdocs_page_input_path = "notes/paper_perf_shadows.md";
    var mkdocs_page_url = "/notes/paper_perf_shadows/";
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js"></script>
  <script src="../../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../../js/highlight.pack.js"></script> 
  
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-143772066-1', 'auto');
      ga('send', 'pageview');
  </script>
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> Yizhou Shan's Home Page</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	  
          
		  
  <ul class="" href="../..">
    <li class="toctree-l1">
  <a class="" href="../..">Home</a>
  </li></ul>
          
		  
  <p class="caption">Notes</p>
  <ul class="current">
          <li class="toctree-l1">
            
  <a class="" href="../source_code/">Open-Source-Code-Study</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../program_advice/">Programming-Guidelines-and-Advice</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../virt/">Virtualization-Software</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../cache_coherence/">Practical-Cache-Coherence</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../xperf/">Measure-x86-Ring-Switch-Overhead</a>
        </li>
          <li class="toctree-l1 current">
            
  <a class="current" href="./">Performance-Shadows</a>
  <ul class="subnav">
      
  <li class="toctree-l2 current">
  
    <a class="current"  href="#hiding-in-the-shadows">Hiding In The Shadows</a>
  
  
    <ul class="">
    
        <li class="toctree-l3 toc-item" >
          <a class="toctree-l3" href="#nanoseconds">Nanoseconds</a>
        </li>
    
        <li class="toctree-l3 toc-item" >
          <a class="toctree-l3" href="#microseconds">Microseconds</a>
        </li>
    
        <li class="toctree-l3 toc-item" >
          <a class="toctree-l3" href="#milliseconds">Milliseconds</a>
        </li>
    
    </ul>
  
  </li>

  </ul>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../rmap/">Linux Reverse Map (rmap)</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../userfaultfd/">Linux Userfaultfd</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../trace/">Linux Trace/Profile</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../cgroup-swap/">Linux Cgroup and Swap</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../proc/">Linux Special Files</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../linux-articles/">Linux Articles</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../kvm-basic/">Linux KVM</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../misc/essential/">Essential</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../benchmark/">Benchmarks</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../misc/cheatsheet/">Cheatsheet</a>
        </li>
  </ul>

          
		  
  <p class="caption">FPGA</p>
  <ul class="">
          <li class="toctree-l1">
            
  <a class="" href="../paper_fpga/">Papers</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../fpga/bitstream/">Bitstream Explained</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../fpga/pr/">Morphous PR</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../fpga/vivado/">Vivado Practice</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../fpga/hls_axi/">Efficient AXI-MM</a>
        </li>
  </ul>

          
		  
  <p class="caption">LegoOS</p>
  <ul class="">
          <li class="toctree-l1">
            
  <a class="" href="/lego/kernel/kconfig">Kernel</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="/lego/syscall/facts">Syscall</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="/lego/pcache/config">Pcache</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="/lego/driver/pci">Driver</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="/lego/paper/nmp">Paper</a>
        </li>
  </ul>

          
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">Yizhou Shan's Home Page</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Notes &raquo;</li>
        
      
    
    <li>Performance-Shadows</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="hiding-in-the-shadows">Hiding In The Shadows<a class="headerlink" href="#hiding-in-the-shadows" title="Permanent link">&para;</a></h1>
<details class="note"><summary>Version History</summary><table><thead><tr><th align="left">Date</th><th>Description</th></tr></thead><tbody><tr><td align="left">Jul 11, 2019</td><td>Initial draft</td></tr></tbody></table></details><p><img alt="ðŸš¦" class="emojione" src="https://cdn.jsdelivr.net/emojione/assets/svg/1f6a6.svg" title=":vertical_traffic_light:" /></p>
<p>There are shadows under the sun.<br />
There are shadows in your life.<br />
There are shadows in your computer.  </p>
<p>This note is about <mark>latency tolerance techniques</mark>.<br />
This note is about how to get the most out of the otherwise-wasted resource.</p>
<h2 id="nanoseconds">Nanoseconds<a class="headerlink" href="#nanoseconds" title="Permanent link">&para;</a></h2>
<p>Architecture solutions to attack nanosecond-level performance shadows
that are mostly created by lower level data and instruction cache misses.
OoO and SMT are the base to hide these latencies, but they fall short
when ROB is full (or some other reasons).
When that happens, these academic ideas come in rescue.</p>
<h3 id="runahead">Runahead<a class="headerlink" href="#runahead" title="Permanent link">&para;</a></h3>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>In runahead, once the processor stalls, it uses the instruction window to
continue to fetch and execute operations. The goal of runahead is to generate
new cache misses, thereby turning subsequent demand requests into cache hits
instead of cache misses.[5]</p>
</div>
<p><strong>Papers</strong></p>
<ol>
<li>Improving Data Cache Performance by Pre-executing Instructions Under a Cache Miss, ICSâ€™97</li>
<li>Runahead Execution: An Alternative to Very Large Instruction Windows for Out-of-order Processors, HPCAâ€™03</li>
<li>Efficient Runahead Execution: Power-Efficient Memory Latency Tolerance, IEEE Microâ€™06<ul>
<li>Good timeline graphs show the benefit of Runahead.</li>
</ul>
</li>
<li>Runahead Threads to Improve SMT Performance, HPCAâ€™08<ul>
<li>QoS control policy.</li>
</ul>
</li>
<li>Continuous Runahead: Transparent Hardware Acceleration for Memory Intensive Workloads, MICROâ€™16<ul>
<li>Nice idea to tackle the issue that runahead does not get enough time to run.</li>
<li>Also has the notion of ideal runahead coverage.</li>
</ul>
</li>
</ol>
<p><strong>Comments</strong></p>
<ul>
<li>We should separate mechanism and policy.</li>
<li>Runahead is the mechanism. It includes:<ul>
<li>Enter runahead</li>
<li>Execution in runahead context (most important thing is to maintain those INV bits and pseudo-retires)</li>
<li>Exit runahead</li>
</ul>
</li>
<li>Prefetch is one of the policy, a major one. It&rsquo;s the side effect of running instructions in the execution phase of runahead mode.</li>
<li>QoS control is another policy. This means adding specific rules to the execution phase. More specifically: limit the core resource usage of the runahead thread, thus reduce the impact on the co-running HW thread.</li>
</ul>
<h3 id="helper-threads-or-precomputation">Helper Threads (or Precomputation)<a class="headerlink" href="#helper-threads-or-precomputation" title="Permanent link">&para;</a></h3>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>A helper thread is a stripped down version of the main thread that
only includes the necessary instructions to generate memory accesses,
including control flow instructions [10].</p>
</div>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Precomputation uses idle thread contexts in a multithreaded architecture
to improve performance of single-threaded applications.
It attacks program stalls from data cache misses by
pre-computing future memory accesses in available thread
contexts, and prefetching these data.[1]</p>
</div>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Such pre-execution threads are
purely speculative, and their instructions are never committed
into the main computation. Instead, the pre-execution
threads run code designed to trigger cache misses. As long
as the pre-execution threads execute far enough in front of
the main thread, they effectively hide the latency of the
cache misses so that the main thread experiences signicantly fewer memory stalls.[5]</p>
</div>
<p><strong>Papers</strong></p>
<ol>
<li>Speculative Precomputation: Long-range Prefetching of Delinquent Loads, ISCA&lsquo;01</li>
<li><em>Dynamic</em> Speculative Precomputation, Micro&lsquo;01<ul>
<li>Take a step further by using HW to construct the offloaded code slice automatically.</li>
</ul>
</li>
<li>Execution-based Prediction Using Speculative Slices, ISCA&lsquo;01</li>
<li>Tolerating Memory Latency through <em>Software-Controlled</em> Pre-Execution in Simultaneous Multithreading Processors, ISCA&lsquo;01<ul>
<li>What&rsquo;s up with ISCA&lsquo;01? This paper proposed to use software to control
when to start running precomputation and when to exit. It uses compiler&rsquo;s
help to generate those code slices, and insert special start/end instructions.
On the contrast, hardware-controller precomputation relies on hints such
as cache misses.</li>
</ul>
</li>
<li>Design and Evaluation of Compiler Algorithms for PreExecution, ASPLOS&lsquo;02<ul>
<li>5.1 A Study of Source-Level Compiler Algorithms for Automatic Construction of Pre-Execution Code, TOCS&lsquo;04</li>
</ul>
</li>
<li>Dynamic Helper Threaded Prefetching on the Sun UltraSPARCÂ® CMP Processor, Micro&lsquo;05<ul>
<li>The <strong>function table</strong> at helper thread seems nice and useful.</li>
</ul>
</li>
<li>Accelerating and Adapting Precomputation Threads for Effcient Prefetching, HPCA&lsquo;07<ul>
<li>Dynamically construct precomputation code, called p-slices. They can adapt
the same program differently depending on the program&rsquo;s data input and the underlying
hardware architecture.</li>
</ul>
</li>
<li>Inter-core Prefetching for Multicore Processors Using <em>Migrating Helper Threads</em>, ASPLOS&lsquo;11<ul>
<li>Pure software solution. I like the idea. But I don&rsquo;t think it will
work for realistic applications.</li>
<li>Learned <code class="codehilite">setcontext(), getcontext(), and swapcontext()</code>.</li>
</ul>
</li>
<li>Bootstrapping: Using SMT Hardware to Improve Single-Thread Performance, ASPLOS&lsquo;19</li>
<li>Freeway: Maximizing MLP for slice-out-of-order execution, HPCA&lsquo;19<ul>
<li>Strictly speaking this is not in this catogory. But it is this paper
  that lead me to Runahead and Helper thread topic. I was doing
  something similar so those techniques caught my eye.</li>
</ul>
</li>
</ol>
<p><strong>Comments</strong></p>
<ul>
<li>The catch about precomputation is that it must create lightweight threads
  that can actually proceed faster than the main thread, so that they
  stay out in front.</li>
<li>Other catch is: you also need to create the code slice that will
  run on another core context. First of all, how is this code slice different
  from the original code? The extracted code will be simplified in the sense
  that it will only access memory without doing other computations.
  The second question is how this code slice is extracted and then constructed?
  There are many ways. You can handwrite, or use a static compiler to pre-generate
  them (by using techniques in above papers), or use hardware to dynamically
  generate them during runtime, or use software to dynamically generate them during runtime.
  There are ways to it, but I don&rsquo;t think this is the core of precomputation.</li>
<li>Also, same thing here, we should separate mechanism and policies.
  Helper thread (or precomputation) is mainly used as a vehicle
  for speculatively generating data addresses and prefetching.</li>
</ul>
<h3 id="thread-level-speculation">Thread-Level Speculation<a class="headerlink" href="#thread-level-speculation" title="Permanent link">&para;</a></h3>
<p>Fill me in.</p>
<h3 id="locks">Locks<a class="headerlink" href="#locks" title="Permanent link">&para;</a></h3>
<p>Applying the insight of &ldquo;get the most out of the otherwise-wasted resource&rdquo;
to the lock area. I will wait for Sanidhya&rsquo;s SOSP&lsquo;19 paper. :-)</p>
<h3 id="misc">Misc<a class="headerlink" href="#misc" title="Permanent link">&para;</a></h3>
<ul>
<li>Stretch: Balancing QoS and throughput for colocated server workloads on SMT cores (Best Paper), HPCA&lsquo;19<ul>
<li>Keyword: <code class="codehilite">ROB</code>, <code class="codehilite">Co-location QoS</code>.</li>
<li>This paper tackles the perf interference when running co-running two SMT threads
  on a single physical core, which is the common case in datacenters.
  However co-running latency-sensitive jobs and batch jobs will
  have huge impact on the perf of both.</li>
<li>This paper found: <em>&ldquo;Latency-sensitive workloads show little benefit
  from large ROB capacities in modern server processors .. because frequent
  cache misses and data-dependent computation limit both instruction
  and memory-level parallelisms (ILP and MLP). In contrast, many batch
  workloads benefit from a large ROB that helps unlock higher ILP and MLP.&rdquo;</em></li>
<li>So they propose to have a ROB partition scheme rather than static equal
  partition. Of course they also did some very extensive studies before
  deciding to scale ROB. They first found shared ROB has the biggest
  impact on perf interference than any other resources such as branch
  predictor, cache, and so on. They further found that latency-sensitive
  workload can tolerate some perf slack, which means they will not
  violate their QoS even with a smaller ROB.</li>
<li>Anyway, I think this is a very nice paper. Good reasoning, simple solution,
  but works effectively.</li>
</ul>
</li>
</ul>
<h3 id="put-it-all-together">Put it all together<a class="headerlink" href="#put-it-all-together" title="Permanent link">&para;</a></h3>
<ul>
<li>Both runahead and helper thread were proposed to do prefetch.
  But they have a key difference. Runahead is invoked in the <em>same core</em>,
  and is invoked when ROB is full (not always though). Helper thread is
  invoked at <em>another core</em>. Besides, runahead can just fetch the
  instructions and run, no need to cook another code slice. But for
  helper thread, it needs to extract a code slice that will run on another core.</li>
<li>I think the most important thing is to realize their insight.
  In the most straightforward and plain way: they are trying to
  get the most out of the otherwise-wasted resource. For example,
  in runahead, they realize that with some help, the CPU is still
  able to generate cache misses even if the instruction table is full.
  For precomputation, obviously it is using the other idle cores.
  The simple insight itself is not interesting enough, usually
  where it&rsquo;s applied make things quite interesting.</li>
</ul>
<h2 id="microseconds">Microseconds<a class="headerlink" href="#microseconds" title="Permanent link">&para;</a></h2>
<p>Fill me in</p>
<h2 id="milliseconds">Milliseconds<a class="headerlink" href="#milliseconds" title="Permanent link">&para;</a></h2>
<p>Sleep. And wake me up when september ends. And this seems to be enough. ;-)
This is true for OS to handle slow HDD and slow network.</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../rmap/" class="btn btn-neutral float-right" title="Linux Reverse Map (rmap)">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../xperf/" class="btn btn-neutral" title="Measure-x86-Ring-Switch-Overhead"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../xperf/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../rmap/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js"></script>
      <script src="../../search/require.js"></script>
      <script src="../../search/search.js"></script>

</body>
</html>
